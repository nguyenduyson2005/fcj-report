[{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Mở rộng quy mô sản xuất hình ảnh bằng Stability AI Image Services trong Amazon Bedrock Bởi Alex Gnibus, Isha Dua, Fabio Branco và Suleman Patel | ngày 18 tháng 9 năm 2025| Amazon Bedrock, Amazon Machine Learning, Amazon SageMaker AI, Announcements, Artificial Intelligence, Foundation models, Generative AI, Launch\nBài viết này được viết cùng với Alex Gnibus của Stability AI.\nStability AI Image Services hiện đã có sẵn trong Amazon Bedrock, mang đến khả năng chỉnh sửa phương tiện sẵn sàng sử dụng thông qua Amazon Bedrock API. Các công cụ chỉnh sửa hình ảnh này mở rộng khả năng của các mô hình Stable Diffusion 3.5 (SD3.5) và Stable Image Core và Ultra của Stability AI, vốn đã có trong Amazon Bedrock và đang thiết lập tiêu chuẩn mới trong việc tạo sinh hình ảnh.\nQuy trình sản xuất sáng tạo chuyên nghiệp bao gồm nhiều bước chỉnh sửa để tạo ra kết quả chính xác như mong muốn. Với Dịch vụ Hình ảnh Stability AI trong Amazon Bedrock, bạn có thể chỉnh sửa, nâng cấp và biến đổi các hình ảnh hiện có mà không cần phải chuyển đổi giữa nhiều hệ thống hay gửi tệp đến các dịch vụ bên ngoài. Mọi thao tác đều được thực hiện trong cùng một môi trường Amazon Bedrock mà bạn đang sử dụng. Tác động kinh doanh có thể diễn ra ngay lập tức đối với các nhóm sản xuất nội dung hình ảnh quy mô lớn. Trong bài viết này, chúng ta sẽ cùng tìm hiểu các ví dụ về cách những công cụ này mang lại khả năng kiểm soát sáng tạo chính xác giúp tăng tốc việc tạo ra nội dung hình ảnh đạt chất lượng chuyên nghiệp.\nTrong bài viết này, chúng ta sẽ cùng tìm hiểu các ví dụ về cách những công cụ này mang lại khả năng kiểm soát sáng tạo chính xác giúp tăng tốc việc tạo ra nội dung hình ảnh đạt chất lượng chuyên nghiệp.\nCác công cụ chỉnh sửa hiện đã có mặt trong Amazon Bedrock Stability AI Image Services bao gồm 13 công cụ thuộc ba nhóm: Chỉnh sửa (Edit), Nâng cấp (Upscale) và Kiểm soát (Control). Mỗi công cụ xử lý một tác vụ chỉnh sửa cụ thể, vốn thường đòi hỏi phần mềm chuyên dụng hoặc thao tác thủ công.\nEdit: Các khả năng nâng cao cho các bước chỉnh sửa chi tiết Những công cụ trong nhóm Edit giúp cho các tác vụ chỉnh sửa phức tạp trở nên dễ tiếp cận và hiệu quả hơn.\nBộ công cụ này bắt đầu với những công cụ chỉnh sửa cơ bản nhưng mạnh mẽ. Ví dụ, công cụ Erase Object có thể loại bỏ các chi tiết không mong muốn khỏi hình ảnh đồng thời tự động giữ nguyên sự nhất quán của phông nền. Hình minh họa dưới đây cho thấy công cụ Erase Object loại bỏ một ma-nơ-canh khỏi ảnh chụp sản phẩm trong khi vẫn giữ nguyên nền. Công cụ này có thể biến đổi một hình ảnh gốc dựa trên ảnh mặt nạ (mask image), hoặc tự động tạo mặt nạ từ kênh alpha của ảnh gốc.\nCông cụ Remove Background tự động tách chủ thể với độ chính xác cao. Điều này cho phép tạo ra các danh sách sản phẩm sạch sẽ, chuyên nghiệp với nền đồng nhất hoặc nhiều bối cảnh phong cách sống khác nhau, mang tính đột phá cho thương mại điện tử.\nVí dụ dưới đây minh họa việc xóa nền của một hình ảnh, trong khi vẫn giữ nguyên chi tiết của sản phẩm nội thất ở tiền cảnh.\nCác công cụ Search and Recolor và Search and Replace tập trung vào việc chỉnh sửa các yếu tố cụ thể trong hình ảnh. Search and Recolor thay đổi màu sắc của đối tượng, ví dụ như thể hiện các phiên bản màu khác nhau của một chiếc váy mà không cần thực hiện buổi chụp ảnh mới. Trong minh họa dưới đây, công cụ Search and Recolor được sử dụng để thay đổi màu của một món đồ nội thất.\nCông cụ Search and Replace có thể thay thế hoàn toàn các đối tượng trong hình ảnh, rất hữu ích khi cần cập nhật các yếu tố theo mùa trong tài liệu tiếp thị hoặc thay thế sản phẩm. Ví dụ dưới đây minh họa việc ứng dụng Search and Replace trong các trải nghiệm thử đồ ảo.\nCông cụ Inpaint chỉnh sửa hình ảnh một cách thông minh bằng cách lấp đầy hoặc thay thế các vùng được chỉ định bằng nội dung mới dựa trên ảnh mặt nạ (mask image). Ngược lại, công cụ Outpaint tạo thêm nội dung để mở rộng hình ảnh theo bất kỳ hướng nào. So với các phương pháp mở rộng hình ảnh tự động hoặc thủ công khác, Outpaint giảm thiểu tối đa các tạo tác (artifacts) và dấu vết cho thấy hình ảnh gốc đã bị chỉnh sửa.\nUpscale: Nâng cấp hình ảnh đạt chất lượng chuyên nghiệp Nâng độ phân giải (Upscale): Nâng cấp hình ảnh đạt chất lượng chuyên nghiệp Ba trong số các Dịch vụ Hình ảnh Stability AI (Stability AI Image Services) mới cung cấp các phương pháp tiếp cận khác nhau để nâng độ phân giải (upscale) và cải thiện chất lượng hình ảnh, mỗi công cụ được thiết kế cho các trường hợp sử dụng (use cases) cụ thể.\nCông cụ Creative Upscale nâng cao độ phân giải đồng thời bổ sung các chi tiết được cải thiện bằng AI. Công cụ này làm tăng cả số lượng điểm ảnh (pixel) và sức hấp dẫn thị giác, khiến nó phù hợp cho các tài liệu tiếp thị có tác động cao. Những bức ảnh chụp sản phẩm tiêu chuẩn có thể trở thành hình ảnh sẵn sàng cho quảng cáo ngoài trời (billboard) thông qua việc bổ sung chi tiết thông minh và tăng cường độ sống động.\nĐối với những tình huống mà việc duy trì tính toàn vẹn của hình ảnh gốc là rất quan trọng, công cụ Conservative Upscale mang đến một cách tiếp cận tinh tế hơn. Nó tăng độ phân giải trong khi vẫn giữ nguyên chi tiết và đặc trưng của hình ảnh ban đầu. Dịch vụ này có thể phóng to (upscale) hình ảnh lên gấp 20 đến 40 lần, tạo ra hình ảnh đầu ra lên đến 4 triệu điểm ảnh (4-megapixel) với sự thay đổi tối thiểu so với hình ảnh gốc.\nHoàn thiện bộ ba công cụ là Fast Upscale. Công cụ này nhanh hơn hai công cụ trước và lý tưởng để nâng cao chất lượng của các hình ảnh bị nén (compress), khiến nó phù hợp cho các bài đăng mạng xã hội (social media posts) và các ứng dụng khác.\nControl: Độ chính xác về cấu trúc và phong cách Nhóm công cụ này cung cấp khả năng thao tác chính xác về cấu trúc và phong cách của hình ảnh thông qua ba công cụ chuyên biệt.\nCông cụ Sketch chuyển đổi các bản vẽ phác thảo thành hình ảnh mang tính chân thực cao. Các công ty kiến trúc có thể sử dụng công cụ này để biến các bản thiết kế ý tưởng thành hình ảnh mô phỏng thực tế, trong khi các thương hiệu thời trang có thể dùng để chuyển bản phác thảo thiết kế thành mô hình sản phẩm. Công cụ này giúp tăng tốc quy trình sáng tạo, từ giai đoạn ý tưởng ban đầu đến hình ảnh hoàn chỉnh.\nTrong ví dụ này, công cụ Sketch chuyển đổi bản vẽ kiến trúc của một tòa nhà thành hình ảnh giúp các nhà phát triển bất động sản hình dung ý tưởng trong bối cảnh đô thị.\nTrong một ví dụ khác, công cụ Sketch chuyển đổi bản vẽ ma-nơ-canh thành hình ảnh chụp người mẫu mang tính chân thực cao.\nCông cụ Structure giữ nguyên các yếu tố cấu trúc của hình ảnh đầu vào trong khi vẫn cho phép thay đổi nội dung. Công cụ này giúp bảo toàn bố cục, cách sắp xếp và mối quan hệ không gian giữa các thành phần khi thay đổi chủ thể hoặc phong cách. Các nhóm sáng tạo có thể sử dụng công cụ Structure để tái tạo lại khung cảnh với các chủ thể khác, hoặc tạo ra nhân vật mới mà vẫn giữ nguyên bố cục và khung hình nhất quán.\nVí dụ dưới đây minh họa công cụ Structure chuyển đổi một khung cảnh xưởng làm việc thành một khung cảnh mới trong khi vẫn duy trì bố cục và mối quan hệ không gian ban đầu.\nCác công cụ Style Guide và Style Transfer giúp các nhóm tiếp thị tạo ra hình ảnh mới phù hợp với phong cách và hướng dẫn nhận diện thương hiệu. Công cụ Style Guide lấy phong cách nghệ thuật và tông màu từ một hình ảnh tham chiếu, sau đó tạo ra các hình ảnh mới dựa trên mô tả văn bản.\nTrong ví dụ dưới đây, công cụ Style Guide sử dụng bảng màu và chất liệu đặc trưng của thương hiệu để tạo ra các hình ảnh mới phù hợp với bản sắc thương hiệu.\nCông cụ Style Transfer sử dụng các đặc điểm thị giác từ hình ảnh tham chiếu để biến đổi những hình ảnh hiện có, đồng thời vẫn giữ nguyên bố cục gốc. Ví dụ, một nhà bán lẻ đồ trang trí nội thất có thể chuyển đổi hình ảnh sản phẩm từ phong cách tối giản hiện đại sang phong cách truyền thống mà không cần chụp ảnh mới. Các nhóm tiếp thị cũng có thể tạo ra các phiên bản theo mùa bằng cách áp dụng những phong cách thị giác khác nhau lên danh mục sản phẩm sẵn có.\nTổng quan về giải pháp Để minh họa cho Dịch vụ Hình ảnh Stability AI trong Amazon Bedrock, chúng ta sẽ cùng xem qua một ví dụ sử dụng Jupyter notebook có sẵn trong kho mã GitHub.\nYêu cầu trước khi thực hiện Để làm theo ví dụ này, bạn cần có các điều kiện sau:\nMột tài khoản AWS. Thông tin AWS credentials đã được cấu hình để tạo và truy cập tài nguyên Amazon Bedrock và Amazon SageMaker AI. Một vai trò thực thi của AWS Identity and Access Management (IAM) dành cho SageMaker AI, được gắn với hai chính sách quản lý là AmazonSageMakerFullAccess và AmazonBedrockLimitedAccess. Để biết thêm chi tiết, xem mục How to use SageMaker AI execution roles. Một SageMaker notebook instance. Quyền truy cập mô hình Stability AI Image Services, có thể được yêu cầu thông qua bảng điều khiển Amazon Bedrock. Tham khảo thêm tại Access Amazon Bedrock foundation models để biết chi tiết. Tạo một notebook instance trong SageMaker AI Thực hiện các bước sau để tạo một SageMaker AI notebook instance, dùng để chạy notebook mẫu:\nTrong bảng điều khiển SageMaker AI, ở thanh điều hướng bên trái, trong phần Applications and IDEs, chọn Notebooks. Chọn Create notebook instance. Ở mục Notebook instance name, nhập tên cho notebook instance của bạn (ví dụ: ai-images-notebook-instance). Ở mục Notebook instance type, chọn ml.t2.medium. Ở mục Platform identifier, chọn Amazon Linux 2. Ở mục IAM role, chọn một vai trò IAM đã có sẵn với hai chính sách AmazonSageMakerFullAccess và AmazonBedrockLimitedAccess, hoặc chọn Create a new role để tạo vai trò mới. Ghi lại tên của IAM role mà bạn đã chọn. Giữ nguyên các thiết lập khác ở giá trị mặc định và chọn Create notebook instance. Sau vài phút, SageMaker AI sẽ tạo notebook instance, và trạng thái của nó sẽ chuyển từ Pending sang InService.\nXác nhận vai trò IAM của notebook instance có đủ quyền cần thiết Thực hiện các bước sau để kiểm tra xem vai trò thực thi của SageMaker AI được gán cho notebook instance đã có đầy đủ quyền hay chưa:\nTrong bảng điều khiển IAM, ở thanh điều hướng bên trái, trong phần Access management, chọn Roles.\nTrong thanh tìm kiếm Roles, nhập tên của SageMaker AI execution role mà bạn đã sử dụng khi tạo notebook instance.\nChọn vai trò IAM đó.\nTrong phần Permissions policies, kiểm tra xem hai chính sách do AWS quản lý là AmazonSageMakerFullAccess và AmazonBedrockLimitedAccess có xuất hiện hay không.\n(Tùy chọn) Nếu thiếu một trong hai chính sách, chọn Add permissions, sau đó chọn Attach policies để gắn thêm chính sách bị thiếu.\na. Trong thanh tìm kiếm Other permissions policies, nhập tên của chính sách cần thêm.\nb. Chọn chính sách đó, rồi chọn Add permissions để hoàn tất.\nChạy notebook Thực hiện các bước sau để chạy notebook:\nTrong bảng điều khiển SageMaker AI, ở thanh điều hướng bên trái, trong phần Applications and IDEs, chọn Notebooks. Chọn notebook instance mà bạn vừa tạo — ai-images-notebook-instance. Chờ đến khi notebook có trạng thái InService. Chọn liên kết Open JupyterLab để mở JupyterLab trong một tab trình duyệt mới. Trong menu Git, chọn Clone a Repository. Nhập đường dẫn https://github.com/aws-samples/stabilityai-sample-notebooks.git và chọn Include submodules và Download the repository. Chọn Clone. Trong menu File, chọn Open from path. Nhập đường dẫn sau: stabilityai-sample-notebooks/stability-ai-image-services/stability-ai-image-services-sample-notebook.ipynb Chọn Open. Khi được hỏi, chọn kernel là conda_python3, sau đó chọn Select. Chạy lần lượt từng ô trong notebook để trải nghiệm Stability AI Image Services in Amazon Bedrock. Dọn dẹp tài nguyên Để tránh phát sinh chi phí, hãy dừng SageMaker AI notebook instance có tên ai-images-notebook-instance mà bạn đã tạo trong hướng dẫn này:\nTrong bảng điều khiển SageMaker AI, ở thanh điều hướng bên trái, trong phần Applications and IDEs, chọn Notebooks Chọn SageMaker AI notebook instance có tên ai-images-notebook-instance mà bạn đã tạo. Chọn Actions, sau đó chọn Stop. Sau vài phút, notebook instance sẽ chuyển trạng thái từ Stopping sang Stopped.\nTiếp theo, chọn Actions, rồi chọn Delete. Sau vài giây, SageMaker AI sẽ xóa notebook instance đó.\nĐể biết thêm chi tiết, tham khảo mục Clean up Amazon SageMaker notebook instance resources.\nKết luận Việc Stability AI Image Services có mặt trong Amazon Bedrock là một bước tiến đầy hứa hẹn trong lĩnh vực tạo và chỉnh sửa nội dung hình ảnh, đặc biệt mang lại lợi ích tiết kiệm thời gian cho các nhóm sáng tạo chuyên nghiệp trong doanh nghiệp.\nVí dụ, trong lĩnh vực truyền thông và giải trí, các nhà sáng tạo có thể nhanh chóng nâng cấp cảnh quay và tạo hiệu ứng đặc biệt, trong khi các nhóm tiếp thị có thể dễ dàng tạo ra nhiều biến thể chiến dịch khác nhau. Ngành bán lẻ và thương mại điện tử có thể tối ưu quy trình chụp ảnh sản phẩm và xây dựng danh mục kỹ thuật số, còn nhà phát triển trò chơi có thể tạo mẫu môi trường nhanh hơn. Các công ty kiến trúc có thể trực quan hóa ý tưởng thiết kế ngay lập tức, và các tổ chức giáo dục có thể tạo ra nội dung trực quan hấp dẫn hơn.\nVới các công cụ này, doanh nghiệp ở mọi quy mô đều có thể sản xuất nội dung hình ảnh chuyên nghiệp, sinh động và sáng tạo một cách hiệu quả. Chúng giúp đơn giản hóa quy trình, giảm chi phí và mở ra nhiều khả năng sáng tạo mới — hỗ trợ thương hiệu kể câu chuyện của mình rõ nét hơn và thu hút khách hàng tốt hơn.\nĐể bắt đầu, hãy khám phá các mô hình Stability AI trong Amazon Bedrock và AWS Samples trên kho GitHub.\nVề các tác giả Alex Gnibus là Quản lý Tiếp thị Sản phẩm tại Stability AI, người kết nối giữa những đột phá nghiên cứu tiên tiến và các trường hợp ứng dụng thực tiễn. Với kinh nghiệm làm việc từ các công ty sáng tạo đến công nghệ doanh nghiệp chuyên sâu, Alex mang đến cả kiến thức kỹ thuật lẫn sự thấu hiểu về những thách thức mà các nhóm sáng tạo chuyên nghiệp có thể giải quyết bằng công nghệ generative AI.\nIsha Dua là Kiến trúc sư Giải pháp Cấp cao (Senior Solutions Architect) tại khu vực Vịnh San Francisco. Cô giúp các khách hàng doanh nghiệp của AWS phát triển bằng cách hiểu rõ mục tiêu và thách thức của họ, đồng thời hướng dẫn cách xây dựng ứng dụng trên nền tảng đám mây sao cho vừa có khả năng mở rộng, vừa đảm bảo tính ổn định. Isha đặc biệt đam mê các công nghệ học máy và phát triển bền vững môi trường.\nFabio Branco là Quản lý Giải pháp Khách hàng Cấp cao (Senior Customer Solutions Manager) tại Amazon Web Services (AWS) và là cố vấn chiến lược giúp khách hàng đạt được chuyển đổi doanh nghiệp, thúc đẩy đổi mới thông qua các giải pháp dữ liệu và AI tạo sinh, đồng thời định hướng hành trình lên đám mây thành công. Trước khi gia nhập AWS, ông từng đảm nhận các vai trò trong Quản lý Sản phẩm, Kỹ thuật, Tư vấn và Triển khai Công nghệ tại nhiều công ty Fortune 500 trong các lĩnh vực như bán lẻ, hàng tiêu dùng, dầu khí, dịch vụ tài chính, bảo hiểm và hàng không vũ trụ.\nSuleman Patel là Kiến trúc sư Giải pháp Cấp cao (Senior Solutions Architect) tại Amazon Web Services (AWS), tập trung vào lĩnh vực học máy và hiện đại hóa hạ tầng. Với chuyên môn kết hợp giữa kinh doanh và công nghệ, Suleman giúp khách hàng thiết kế và xây dựng các giải pháp giải quyết những vấn đề thực tiễn trong doanh nghiệp. Ngoài công việc, anh yêu thích khám phá thiên nhiên, đi du lịch bằng xe đường dài và nấu ăn những món ngon trong bếp.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"DeepSeek-V3.1 Model Đã Có Mặt Trong Amazon Bedrock bởi Channy Yun (윤석찬) | ngày 18 tháng 9 năm 2025 | Amazon Bedrock, Amazon Machine Learning, Announcements, Artificial Intelligence, Featured, Launch, News, Open Source, Serverless\n▶️ Nghe bản audio Lồng tiếng bởi Amazon Polly\nVào tháng 3, Amazon Web Services (AWS) đã trở thành nhà cung cấp dịch vụ đám mây đầu tiên triển khai DeepSeek-R1 theo cách không máy chủ bằng cách ra mắt nó dưới dạng một mô hình được quản lý hoàn toàn và có sẵn rộng rãi trong Amazon Bedrock. Kể từ đó, khách hàng đã sử dụng khả năng của DeepSeek-R1 thông qua Amazon Bedrock để xây dựng các ứng dụng generative AI, hưởng lợi từ các biện pháp bảo vệ mạnh mẽ và công cụ toàn diện của Bedrock để triển khai AI an toàn.\nHôm nay, tôi rất vui được thông báo rằng DeepSeek-V3.1 hiện đã có mặt như một mô hình nền tảng được quản lý hoàn toàn trong Amazon Bedrock. DeepSeek-V3.1 là một mô hình hybrid open weight chuyển đổi giữa chế độ suy nghĩ (chain-of-thought reasoning) để phân tích từng bước chi tiết và chế độ không suy nghĩ (direct answers) để có phản hồi nhanh hơn.\nTheo DeepSeek, chế độ suy nghĩ của DeepSeek-V3.1 đạt được chất lượng câu trả lời tương đương với kết quả tốt hơn, khả năng lập luận đa bước mạnh mẽ hơn cho các tác vụ tìm kiếm phức tạp và cải thiện lớn về hiệu quả suy nghĩ so với DeepSeek-R1-0528.\nBenchmarks DeepSeek-V3.1 DeepSeek-R1-0528 Browsecomp 30.0 8.9 Browsecomp_zh 49.2 35.7 HLE 29.8 24.8 xbench-DeepSearch 71.2 55.0 Frames 83.7 82.0 SimpleQA 93.4 92.3 Seal0 42.6 29.7 SWE-bench Verified 66.0 44.6 SWE-bench Multilingual 54.5 30.5 Terminal-Bench 31.3 5.7 (c) https://api-docs.deepseek.com/news/news250821\nHiệu suất của model DeepSeek-V3.1 trong việc sử dụng công cụ và các tác vụ tác nhân đã được cải thiện đáng kể thông qua tối ưu hóa sau đào tạo so với các model DeepSeek trước đây. DeepSeek-V3.1 cũng hỗ trợ hơn 100 ngôn ngữ với trình độ gần như bản địa, bao gồm cải thiện đáng kể trong các ngôn ngữ ít tài nguyên thiếu các kho ngữ liệu đơn ngữ hoặc song ngữ lớn. Bạn có thể xây dựng các ứng dụng toàn cầu để mang lại độ chính xác cao hơn và giảm ảo giác so với các model DeepSeek trước đó, đồng thời duy trì khả năng quan sát quá trình ra quyết định của nó.\nĐây là các công dụng chính khi sử dụng model này:\nTạo mã – DeepSeek-V3.1 xuất sắc trong các tác vụ mã hóa với những cải tiến trong benchmark của kỹ thuật phần mềm và khả năng của tác nhân, làm cho nó lý tưởng cho việc tạo mã tự động, gỡ lỗi và quy trình kỹ thuật phần mềm. Nó hoạt động tốt trên các benchmark về lập trình trong khi mang lại kết quả chất lượng cao một cách hiệu quả. Công cụ AI agent – Mô hình này có tính năng gọi công cụ được cải thiện thông qua tối ưu hậu huấn luyện, giúp nó thể hiện ưu thế trong việc sử dụng công cụ và quy trình làm việc tác nhân. Nó hỗ trợ gọi công cụ có cấu trúc, tác nhân mã và tác nhân tìm kiếm, đưa nó thành một lựa chọn vững chắc để xây dựng các hệ thống AI tự trị. Ứng dụng doanh nghiệp – Các model DeepSeek được tích hợp vào nhiều nền tảng trò chuyện và công cụ năng suất, nâng cao tương tác người dùng và hỗ trợ quy trình của dịch vụ chăm sóc khách hàng. Nhờ khả năng đa ngôn ngữ và nhạy cảm văn hóa, mô hình phù hợp cho các ứng dụng doanh nghiệp toàn cầu. Như tôi đã đề cập trong bài viết trước, khi triển khai các mô hình có sẵn công khai, hãy cân nhắc cẩn thận các yêu cầu về quyền riêng tư dữ liệu khi triển khai trong môi trường sản xuất của bạn, kiểm tra sự thiên vị trong đầu ra và giám sát kết quả của bạn về bảo mật dữ liệu, AI có trách nhiệm và đánh giá mô hình.\nBạn có thể truy cập các tính năng bảo mật cấp doanh nghiệp của Amazon Bedrock và triển khai các biện pháp bảo vệ được tùy chỉnh theo yêu cầu ứng dụng cũng như chính sách AI có trách nhiệm của bạn bằng Amazon Bedrock Guardrails. Bạn cũng có thể đánh giá và so sánh các mô hình để xác định mô hình tối ưu cho các trường hợp sử dụng của mình bằng cách sử dụng các công cụ đánh giá mô hình Amazon Bedrock.\nBắt đầu với mô hình DeepSeek-V3.1 trong Amazon Bedrock Để thử nghiệm mô hình DeepSeek-V3.1 trong bảng điều khiển Amazon Bedrock, chọn Chat/Text trong mục Playgrounds ở thanh menu bên trái. Sau đó chọn Select model ở góc trên bên trái, chọn DeepSeek làm danh mục và DeepSeek-V3.1 làm mô hình. Cuối cùng bấm Apply.\nSử dụng mô hình DeepSeek-V3.1 đã chọn, tôi chạy ví dụ prompt sau về quyết định kiến trúc kỹ thuật:\nPhác thảo kiến trúc tổng thể cho một dịch vụ rút gọn URL có khả năng mở rộng như bit.ly. Thảo luận các thành phần chính như thiết kế API, lựa chọn cơ sở dữ liệu (SQL vs. NoSQL), cơ chế chuyển hướng hoạt động ra sao, và cách bạn sẽ tạo các mã rút gọn duy nhất.\nBạn có thể bật/tắt chế độ Model Reasoning để sinh chuỗi suy luận trước khi đưa ra kết luận cuối cùng.\nBạn cũng có thể truy cập mô hình qua AWS Command Line Interface (AWS CLI) và AWS SDK. Mô hình hỗ trợ cả InvokeModel và Converse API. Có nhiều ví dụ mã nguồn cho nhiều trường hợp sử dụng và ngôn ngữ lập trình khác nhau.\nĐể tìm hiểu thêm, xem DeepSeek model inference parameters and responses trong tài liệu AWS.\nHiện đã có DeepSeek-V3.1 hiện đã có ở các vùng AWS: US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Mumbai), Europe (London) và Europe (Stockholm). Kiểm tra danh sách đầy đủ các vùng để cập nhật trong tương lai. Để biết thêm, xem trang sản phẩm DeepSeek in Amazon Bedrock product page và trang giá cả Amazon Bedrock pricing page.\nHãy thử mô hình DeepSeek-V3.1 trong bảng điều khiển Amazon Bedrock hôm nay và gửi phản hồi lên AWS re:Post for Amazon Bedrock hoặc qua các kênh hỗ trợ AWS bạn thường dùng.\n— Channy\nCập nhật ngày 19 tháng 9 năm 2025 — Đã xóa phần truy cập mô hình. Amazon Bedrock sẽ đơn giản hóa truy cập tới tất cả các mô hình nền tảng không máy chủ và các mô hình mới bằng cách tự động bật quyền truy cập cho mọi tài khoản AWS, loại bỏ việc phải kích hoạt thủ công trong bảng điều khiển Bedrock. Trang truy cập mô hình sẽ bị ngừng vào ngày 8 tháng 10 năm 2025. Quản trị viên tài khoản vẫn giữ toàn quyền kiểm soát truy cập mô hình thông qua chính sách AWS IAM và Chính Sách Kiểm Soát Dịch Vụ (SCPs) để giới hạn truy cập khi cần.\nChanny Yun (윤석찬)\nChanny là Lead Blogger của AWS News Blog và Principal Developer Advocate cho AWS Cloud. Là một người đam mê web mở và viết blog, anh yêu thích việc học hỏi và chia sẻ công nghệ dựa trên cộng đồng.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Các mô hình Qwen hiện đã có mặt trên Amazon Bedrock bởi Danilo Poccia vào 18 THG 9 2025 trong Amazon Bedrock, Amazon Machine Learning, Thông báo, Trí tuệ nhân tạo, Nổi bật, Ra mắt, Tin tức, Mã nguồn mở, Serverless\n▶️ Nghe bản audio Lồng tiếng bởi Amazon Polly\nHôm nay, chúng tôi bổ sung các mô hình Qwen từ Alibaba vào Amazon Bedrock. Với việc ra mắt này, Amazon Bedrock tiếp tục mở rộng lựa chọn mô hình bằng cách bổ sung quyền truy cập vào các mô hình nền tảng (FMs) mã nguồn mở Qwen3 theo cách thức được quản lý hoàn toàn và không máy chủ. Bản phát hành này bao gồm bốn mô hình: Qwen3-Coder-480B-A35B-Instruct, Qwen3-Coder-30B-A3B-Instruct, Qwen3-235B-A22B-Instruct-2507 và Qwen3-32B (Dense). Cùng nhau, các mô hình này có cả kiến trúc hỗn hợp chuyên gia (MoE) và kiến trúc dày đặc, cung cấp các lựa chọn linh hoạt cho các yêu cầu ứng dụng khác nhau.\nAmazon Bedrock cung cấp quyền truy cập vào các FM dẫn đầu ngành thông qua một API thống nhất mà không yêu cầu quản lý cơ sở hạ tầng. Bạn có thể truy cập các mô hình từ nhiều nhà cung cấp, tích hợp các mô hình vào ứng dụng của mình và mở rộng quy mô sử dụng dựa trên yêu cầu khối lượng công việc. Với Amazon Bedrock, dữ liệu khách hàng không bao giờ được sử dụng để đào tạo các mô hình cơ bản. Với sự bổ sung của các mô hình Qwen3, Amazon Bedrock mang đến nhiều lựa chọn hơn cho các trường hợp sử dụng như:\nTạo mã và phân tích kho lưu trữ với khả năng hiểu ngữ cảnh mở rộng Xây dựng quy trình làm việc dạng tác nhân có khả năng phối hợp nhiều công cụ và API cho tự động hóa kinh doanh Cân bằng chi phí và hiệu suất AI bằng cách sử dụng các chế độ tư duy lai để suy luận thích ứng Các mô hình Qwen3 trong Amazon Bedrock Bốn mô hình Qwen3 này hiện đã có mặt trên Amazon Bedrock, mỗi mô hình được tối ưu hóa cho các yêu cầu về hiệu suất và chi phí khác nhau:\nQwen3-Coder-480B-A35B-Instruct – Đây là mô hình hỗn hợp chuyên gia (MoE) với 480B tham số tổng và 35B tham số hoạt động. Nó được tối ưu hóa cho các tác vụ viết mã và tác nhân, đạt kết quả mạnh mẽ trong các điểm chuẩn như mã hóa tác nhân, sử dụng trình duyệt và sử dụng công cụ. Những khả năng này làm cho nó phù hợp để phân tích mã ở quy mô kho lưu trữ và tự động hóa quy trình làm việc nhiều bước. Qwen3-Coder-30B-A3B-Instruct – Đây là mô hình MoE với 30B tham số tổng và 3B tham số hoạt động. Được tối ưu hóa đặc biệt cho các tác vụ viết mã và các tình huống tuân theo hướng dẫn, mô hình này thể hiện hiệu suất mạnh mẽ trong việc tạo mã, phân tích và gỡ lỗi trên nhiều ngôn ngữ lập trình. Qwen3-235B-A22B-Instruct-2507 – Đây là mô hình MoE được điều chỉnh theo hướng dẫn với 235B tham số tổng và 22B tham số hoạt động. Nó mang lại hiệu suất cạnh tranh trên các tác vụ về mã hóa, toán học và suy luận chung, cân bằng giữa khả năng và hiệu quả. Qwen3-32B (Dense) – Đây là mô hình dày đặc với 32B tham số. Nó phù hợp với các môi trường thời gian thực hoặc bị hạn chế tài nguyên như thiết bị di động và các triển khai điện toán biên nơi hiệu suất ổn định là quan trọng. Các tính năng kiến trúc và chức năng trong Qwen3 Các mô hình Qwen3 giới thiệu một số tính năng kiến trúc và chức năng:\nKiến trúc MoE so với kiến trúc dày đặc – Các mô hình MoE như Qwen3-Coder-480B-A35B, Qwen3-Coder-30B-A3B-Instruct và Qwen3-235B-A22B-Instruct-2507 chỉ kích hoạt một phần tham số cho mỗi yêu cầu, cung cấp hiệu suất cao với suy luận hiệu quả. Mô hình dày đặc Qwen3-32B kích hoạt tất cả các tham số, mang lại hiệu suất ổn định và dễ dự đoán hơn.\nKhả năng tác nhân – Các mô hình Qwen3 có thể xử lý lập luận nhiều bước và lập kế hoạch có cấu trúc trong một lần gọi mô hình. Chúng có thể tạo đầu ra để gọi các công cụ hoặc API bên ngoài khi được tích hợp vào một khuôn khổ tác nhân. Các mô hình cũng duy trì ngữ cảnh mở rộng trong các phiên làm việc dài. Ngoài ra, chúng hỗ trợ gọi công cụ để cho phép giao tiếp tiêu chuẩn hóa với môi trường bên ngoài.\nChế độ tư duy lai – Qwen3 giới thiệu một cách tiếp cận lai để giải quyết vấn đề, hỗ trợ hai chế độ: tư duy và không tư duy. Chế độ tư duy áp dụng lập luận từng bước trước khi đưa ra câu trả lời cuối cùng. Điều này lý tưởng cho các vấn đề phức tạp đòi hỏi suy nghĩ sâu hơn. Trong khi chế độ không tư duy cung cấp phản hồi nhanh và gần như tức thì cho các tác vụ ít phức tạp hơn, nơi tốc độ quan trọng hơn chiều sâu. Điều này giúp các nhà phát triển quản lý sự đánh đổi giữa hiệu suất và chi phí hiệu quả hơn.\nXử lý ngữ cảnh dài – Các mô hình Qwen3-Coder hỗ trợ cửa sổ ngữ cảnh mở rộng, lên đến 256K token một cách tự nhiên và lên đến 1 triệu token với các phương pháp ngoại suy. Điều này cho phép mô hình xử lý toàn bộ kho lưu trữ, tài liệu kỹ thuật lớn hoặc lịch sử hội thoại dài trong một tác vụ duy nhất.\nKhi nào nên sử dụng mỗi mô hình Bốn mô hình Qwen3 phục vụ các trường hợp sử dụng riêng biệt. Qwen3-Coder-480B-A35B-Instruct được thiết kế cho các tình huống kỹ thuật phần mềm phức tạp. Nó phù hợp để tạo mã nâng cao, xử lý ngữ cảnh dài như phân tích ở cấp độ kho lưu trữ và tích hợp với các công cụ bên ngoài. Qwen3-Coder-30B-A3B-Instruct đặc biệt hiệu quả cho các tác vụ như hoàn thiện mã, tái cấu trúc và trả lời các truy vấn liên quan đến lập trình. Nếu bạn cần hiệu suất linh hoạt trên nhiều lĩnh vực, Qwen3-235B-A22B-Instruct-2507 cung cấp sự cân bằng, mang lại khả năng suy luận đa mục đích và tuân theo hướng dẫn mạnh mẽ trong khi tận dụng các lợi thế hiệu quả của kiến trúc MoE. Qwen3-32B (Dense) phù hợp cho các tình huống mà hiệu suất ổn định, độ trễ thấp và tối ưu hóa chi phí là quan trọng.\nBắt đầu với các mô hình Qwen trong Amazon Bedrock Để bắt đầu sử dụng các mô hình Qwen, trong bảng điều khiển Amazon Bedrock, tôi có thể sử dụng phần Chat/Text Playground ở thanh điều hướng để nhanh chóng thử nghiệm các mô hình Qwen mới với một vài prompt.\nĐể tích hợp các mô hình Qwen3 vào ứng dụng của mình, tôi có thể sử dụng bất kỳ AWS SDKs nào. Các AWS SDK bao gồm quyền truy cập vào API InvokeModel và Converse của Amazon Bedrock. Tôi cũng có thể sử dụng các mô hình này với bất kỳ khuôn khổ tác nhân nào hỗ trợ Amazon Bedrock và triển khai các tác nhân bằng Amazon Bedrock AgentCore. Ví dụ: đây là mã Python của một tác nhân đơn giản với quyền truy cập công cụ được xây dựng bằng Strands Agents:\nfrom strands import Agent from strands_tools import calculator agent = Agent( model=\u0026#34;qwen.qwen3-coder-480b-a35b-v1:0\u0026#34;, tools=[calculator] ) agent(\u0026#34;Tell me the square root of 42 ^ 9\u0026#34;) with open(\u0026#34;function.py\u0026#34;, \u0026#39;r\u0026#39;) as f: my_function_code = f.read() agent(f\u0026#34;Help me optimize this Python function for better performance:\\n\\n{my_function_code}\u0026#34;) Hiện có sẵn Các mô hình Qwen hiện đã được cung cấp tại các Khu vực AWS sau:\nQwen3-Coder-480B-A35B-Instruct có sẵn ở các khu vực: US West (Oregon), Asia Pacific (Mumbai, Tokyo) và Europe (London, Stockholm).\nQwen3-Coder-30B-A3B-Instruct, Qwen3-235B-A22B-Instruct-2507 và Qwen3-32B có sẵn ở các khu vực: US East (N. Virginia), US West (Oregon), Asia Pacific (Mumbai, Tokyo), Europe (Ireland, London, Milan, Stockholm) và South America (São Paulo).\nHãy kiểm tra danh sách Khu vực đầy đủ để cập nhật trong tương lai. Bạn có thể bắt đầu thử nghiệm và xây dựng ngay lập tức mà không cần thiết lập cơ sở hạ tầng hoặc lập kế hoạch công suất. Để tìm hiểu thêm, hãy truy cập trang sản phẩm Qwen trong Amazon Bedrock và trang giá cả Amazon Bedrock.\nHãy thử ngay các mô hình Qwen trên bảng điều khiển Amazon Bedrock, và đưa ra phản hồi thông qua AWS re:Post for Amazon Bedrock hoặc các kênh Hỗ trợ AWS thông thường của bạn.\n— Danilo\nCập nhật vào ngày 18 tháng 9 năm 2025 – Đã loại bỏ phần quyền truy cập mô hình. Amazon Bedrock sẽ đơn giản hóa quyền truy cập vào tất cả các mô hình nền không máy chủ, và bất kỳ mô hình mới nào, bằng cách tự động kích hoạt chúng cho mọi tài khoản AWS, loại bỏ việc cần kích hoạt thủ công thông qua bảng điều khiển Bedrock. Trang quyền truy cập mô hình sẽ ngừng hoạt động vào ngày 8 tháng 10 năm 2025. Quản trị viên tài khoản vẫn giữ toàn quyền kiểm soát quyền truy cập mô hình thông qua các chính sách AWS IAM và Chính Sách Kiểm Soát Dịch Vụ (SCPs) để hạn chế quyền truy cập mô hình khi cần.\nDanilo Poccia\nDanilo làm việc với các công ty khởi nghiệp và công ty thuộc mọi quy mô để hỗ trợ sự đổi mới của họ. Trong vai trò Chief Evangelist (EMEA) tại Amazon Web Services, anh ấy tận dụng kinh nghiệm của mình để giúp mọi người hiện thực hóa ý tưởng, tập trung vào kiến trúc không máy chủ và lập trình hướng sự kiện, cũng như tác động kỹ thuật và kinh doanh của máy học và điện toán biên. Ông là tác giả của AWS Lambda in Action từ Manning.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition dành cho Builders” Mục Đích Của Sự Kiện Nhấn mạnh hợp tác công nghệ Việt Nam–Hoa Kỳ và tăng trưởng kinh tế dựa trên điện toán đám mây Giới thiệu các đổi mới về AI và blockchain định hình tương lai số của Việt Nam Trình bày các sáng kiến của AWS hỗ trợ builders, giáo dục và chuyển đổi lực lượng lao động Nhấn mạnh văn hóa, kỹ năng và AI có trách nhiệm là nền tảng cho đổi mới bền vững Danh Sách Diễn Giả Đại sứ Hoa Kỳ – Chia sẻ về 30 năm hợp tác Hoa Kỳ–Việt Nam thông qua công nghệ Eric Elock – CEO, AWS VN–Lào–Campuchia–Myanmar Chloe Phung – CEO, U2U Erick – CEO, AWS Jaime Valless – Lãnh đạo AWS Nội Dung Nổi Bật Củng cố Hợp tác Việt Nam–Hoa Kỳ Đại sứ Hoa Kỳ nhấn mạnh mối quan hệ bền chặt giữa Việt Nam và Hoa Kỳ. Làm nổi bật 30 năm tăng trưởng song phương được thúc đẩy nhờ các công ty công nghệ Hoa Kỳ như AWS. Tầm nhìn từ Eric Elock (CEO Khu vực AWS) Các ngân hàng đóng vai trò quan trọng trong hỗ trợ hiện đại hóa CNTT. Hệ sinh thái U2U: Cho phép tương tác giữa doanh nghiệp và người dùng thông qua blockchain. Góc nhìn từ Chloe Phung (CEO U2U) Hai năm trước, các đối tác nói ý tưởng của họ là không thể. Ngày nay, Việt Nam không chỉ bắt kịp các cuộc cách mạng toàn cầu mà còn đang định hình chúng. AI Định hình Tương lai Việt Nam Giáo dục: 60% học sinh Việt Nam sử dụng ứng dụng EdTech; AI giúp phá vỡ rào cản ngôn ngữ và tạo trải nghiệm học tập hấp dẫn. Kinh tế: Hơn 765 startup AI, đứng thứ 2 tại ASEAN. Đóng góp tác động 120–130 tỷ USD vào GDP. Tác động xã hội: Chăm sóc sức khỏe dễ tiếp cận và chi phí hợp lý hơn. Các bác sĩ tại Bệnh viện 10A giảm thời gian khám xuống còn 5 phút mỗi ca bằng AI. AI cải thiện hệ thống giao thông, hiệu quả năng lượng và thậm chí bảo vệ đường bờ biển. Đà phát triển Công nghệ Thực tế Nubila: Công dụng liên quan đến thời tiết được hỗ trợ bởi AI. Staex: Triển khai thành công hơn 1.000 thiết bị IoT khắp châu Á và châu Âu. GenAI giảm hàng giờ tìm kiếm tài liệu; nhà phát triển hoàn thành dự án trong vài giờ/ngày thay vì nhiều tuần. GenAI đơn giản hóa blockchain cho người mới bắt đầu, cải thiện khả năng tiếp cận. AI cải thiện việc ra quyết định cho doanh nghiệp, nhà hoạch định chính sách và quy trình làm việc hàng ngày. Đặc biệt cảm ơn AWS đã tạo điều kiện cho các đột phá. Phát biểu của CEO AWS Erick AWS đã đào tạo hơn 100.000 builders tại Việt Nam. Mở rộng khả năng tiếp cận dịch vụ đám mây trên cả nước. Chương trình FJC: Sáng kiến 6 tháng cung cấp cơ hội việc làm an toàn. Nhấn mạnh văn hóa AWS là điểm khác biệt chính. Góc nhìn từ Jaime Valless Định hình lại thông điệp với trọng tâm là văn hóa và kỹ năng. \u0026ldquo;Chúng ta đang ở một thời khắc độc nhất trong lịch sử nơi AI sẽ biến đổi mọi thứ.\u0026rdquo; Không chỉ là công nghệ — kỹ năng, con người, văn hóa và trách nhiệm mới quan trọng. Nhân loại giờ đang ở vị thế tốt nhất để xây dựng một tương lai tốt đẹp hơn, bền vững. Chuyển từ đào tạo mô hình sang suy luận an toàn, có trách nhiệm. AWS cung cấp quyền truy cập vào các mô hình đa dạng, an toàn. Ví dụ: Nearmap sử dụng AI để giúp khách hàng đưa ra quyết định nhanh hơn. Hãy để công nghệ xử lý các tác vụ nhàm chán; con người tập trung vào sáng tạo và tư duy. Cuối cùng, Erik đã gửi gắm thông điệp về hạnh phúc, sức khỏe và thành công.\nVòng đời Phát triển được AI Hỗ trợ Ngay cả khi giao nhiều nhiệm vụ hơn cho AI, quyền kiểm soát phải luôn thuộc về con người:\nXác nhận Làm rõ Rà soát Ba giai đoạn:\nKhởi tạo: Tạo ý tưởng, xác định tác vụ Xây dựng: Mô hình hóa miền, tạo mã, kiểm thử, triển khai IaC Vận hành: Triển khai hoàn chỉnh, quản lý sự cố Bảo mật cho Ứng dụng AI Quản lý rủi ro AI:\nChính sách quản trị AI Giảm thiểu ảo giác AI Ngăn ngừa nhiễm độc dữ liệu Bảo mật prompt Kiểm soát truy cập và phân quyền Các biện pháp bảo vệ kiến trúc:\nCon người trong vòng lặp Prompt được bảo mật Xác minh chuỗi cung ứng Đánh giá dữ liệu Hệ thống RAG để đảm bảo độ chính xác Amazon Q / QuickSight Đơn giản hóa việc tạo dashboard Cho phép phân tích nhanh với thiết lập tối thiểu Những Gì Học Được Tư duy Thiết kế \u0026amp; Đổi mới Việt Nam đang tích cực định hình đổi mới AI toàn cầu. Văn hóa, kỹ năng và trách nhiệm là yếu tố then chốt. GenAI đẩy nhanh tốc độ phát triển và hạ thấp rào cản gia nhập. Tác động Kỹ thuật AI cải thiện chăm sóc sức khỏe, giáo dục, kinh tế và hậu cần. AI an toàn và có trách nhiệm là điều cần thiết. Công cụ AWS trao quyền cho builders với hiệu quả và khả năng mở rộng. Cảm hứng Thực tế Các câu chuyện thành công (U2U, Staex, Nearmap) cho thấy ảnh hưởng ngày càng tăng của Việt Nam. Sự kết hợp AI–Blockchain đang thúc đẩy các hệ sinh thái kinh doanh mới. Trải nghiệm trong event Tham dự Vietnam Cloud Day 2025 mang lại cái nhìn sâu sắc về cách AI, điện toán đám mây và blockchain đang định hình tương lai công nghệ của Việt Nam.\n1. Học hỏi từ Chuyên gia Toàn cầu Đại sứ Hoa Kỳ, các CEO của AWS và lãnh đạo ngành chia sẻ góc nhìn cấp cao 2. Nghiên cứu Điển hình Thực tế AI trong chăm sóc sức khỏe, giáo dục, giao thông và năng lượng Triển khai IoT và blockchain quy mô lớn tại châu Á và châu Âu 3. Đổi mới Lấy Con người làm Trung tâm Phát triển văn hóa và kỹ năng là cốt lõi của đổi mới bền vững AI cho phép con người tập trung vào sáng tạo thay vì các tác vụ lặp đi lặp lại Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"WEBSITE TRỰC TUYẾN THEO DÕI VÀ DỰ BÁO QUỸ ĐẠO BÃO Trong workshop này, nhóm chúng em trình bày cách xây dựng một nền tảng trực tuyến cho phép người dùng truy cập Internet có thể tự do kiểm tra, theo dõi và thậm chí dự đoán đường đi của các cơn bão đang hoạt động tại khu vực Tây Thái Bình Dương. Nền tảng này giúp người dùng chủ động chuẩn bị cho các thảm họa tự nhiên sắp xảy ra và giảm thiểu thiệt hại tiềm tàng.\nNền tảng cung cấp hai chức năng chính:\nHiển thị các cơn bão gần nhất – Cho phép người dùng xem đường đi, cường độ, tốc độ gió và các đặc điểm khác của bão gần đây trong khu vực Tây Thái Bình Dương.\nDự đoán quỹ đạo bão – Cho phép người dùng nhập dữ liệu vị trí bão trong quá khứ (vĩ độ và kinh độ; tối thiểu 9 điểm dữ liệu) để hệ thống dự đoán hướng di chuyển trong tương lai.\nPhân chia theo tiến độ, chúng em sẽ lần lượt trình bày về bộ dữ liệu, quá trình tiền xử lý, pipeline huấn luyện mô hình, và quá trình xây dựng nền tảng trực tuyến bằng các dịch vụ AWS. Chúng em cũng sẽ perform kỹ thuật tăng cường dữ liệu được đề xuất — Stepwise Temporal Fading Augmentation (STFA) cùng với việc ứng dụng machine learning dựa trên các quy tắc vật lý (physics-informed ML). Những phương pháp này giúp dữ liệu huấn luyện trở nên chân thực hơn và cải thiện đáng kể độ chính xác trong dự đoán đường đi bão, tuổi thọ bão và tổng quãng đường di chuyển.\nHình 1 : Pipeline mô hình Sau khi hoàn thành quá trình huấn luyện mô hình, chúng em triển khai xây dựng nền tảng trực tuyến bằng kiến trúc serverless. Đây là kiến trúc tiết kiệm chi phí, có khả năng mở rộng tốt, và dễ dàng bảo trì/triển khai — rất phù hợp cho mục tiêu dự án. Dưới đây là các dịch vụ AWS chính được sử dụng:\nAWS Lambda – Chạy các mô hình ML và xử lý logic phía backend Amazon S3 – Lưu trữ file tĩnh, mô hình ML và dữ liệu bão Amazon API Gateway – Định tuyến và phần luồng các yêu cầu của người dùng đến Lambda phù hợp, tùy theo việc họ xem dữ liệu bão gần đây hay chạy dự đoán Amazon CloudFront – Tăng tốc phân phối nội dung thông qua các edge location AWS Secrets Manager – Lưu trữ khóa API và các thông tin nhạy cảm … – Các dịch vụ hỗ trợ bổ sung khác khi cần Hình 2 : Kiến trúc nền tảng "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Duy Sơn\nSố điện thoại: 0818400453\nEmail: yama27032005@gmail.com\nTrường: FPTU - Tp.HCM\nNgành: Trí tuệ nhân tạo\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 09/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Nắm các kỹ năng AWS cơ bản bằng cách tạo tài khoản, học quản lý chi phí và hỗ trợ, thực hành cấu hình IAM, hoàn thành các bài tập EC2/RDS/Lambda/Bedrock và xây dựng toàn bộ môi trường VPC.\nTuần 2: Triển khai và quản lý EC2, cấu hình NAT Gateway và giám sát, thiết lập VPN Site-to-Site hoàn chỉnh, xử lý sự cố VPN và tham dự sự kiện Vietnam Cloud Day 2025.\nTuần 3: Nâng cao kỹ năng quản trị EC2, triển khai ứng dụng trên Amazon Linux 2, tạo AMI tùy chỉnh, luyện sao lưu/khôi phục và áp dụng IAM để quản lý chi phí và giới hạn dịch vụ.\nTuần 4: Cấu hình IAM cho ứng dụng, sử dụng Cloud9, xây dựng website tĩnh với S3, tăng tốc bằng CloudFront và triển khai các tính năng nâng cao của S3\nTuần 5: Triển khai hạ tầng ứng dụng với EC2 và RDS, cài đặt WordPress trên Lightsail, chuẩn bị dữ liệu và tài liệu cho dự án nhóm, đồng thời hoàn thành dịch thuật kỹ thuật về các cập nhật AWS Bedrock.\nTuần 6: Triển khai ứng dụng doanh nghiệp trên Lightsail, xây dựng và quản lý container với Docker, và triển khai hạ tầng Auto Scaling đầy đủ với Load Balancer để đảm bảo tính sẵn sàng cao.\nTuần 7: Thành thạo giám sát với AWS CloudWatch, triển khai DNS lai với Route 53 Resolver và Active Directory, và nâng cao năng lực AWS CLI để tự động hóa hoạt động trên đám mây.\nTuần 8: Thành thạo các thao tác DynamoDB qua Console, CLI và SDK; tích hợp Python với DynamoDB; và hoàn thành Kỳ thi Giữa kỳ OJT với phạm vi bao quát tốt các nguyên tắc kiến trúc AWS.\nTuần 9: Thành thạo vận hành cụm ElastiCache, triển khai mạng VPC nâng cao với VPN, TGW, Endpoints và Peering, và củng cố quản lý DNS và kết nối xuyên suốt các dịch vụ AWS.\nTuần 10: Thành thạo sử dụng CloudFront và Lambda@Edge cho CDN và điện toán biên, triển khai máy tính ảo Amazon WorkSpaces, và tham gia sự kiện AWS Cloud Mastery Series #1.\nTuần 11: Triển khai AWS Managed Microsoft AD, xây dựng kiến trúc WordPress có tính sẵn sàng cao với Auto Scaling và Load Balancing, và tham gia các sự kiện cộng đồng và Game Day.\nTuần 12: Hoàn thành di chuyển máy ảo thông qua VM Import/Export, thực hiện di chuyển cơ sở dữ liệu với DMS và SCT, dịch thuật tài liệu workshop của nhóm, và tham gia AWS Cloud Mastery Series #3.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và ghi chú các quy tắc và quy định của đơn vị thực tập - Làm quen với các thành viên khác trong nhóm - Đã tạo một tài khoản AWS 09/08/2025 09/08/2025 https://000001.awsstudygroup.com/ 3 - Tìm hiểu cách quản lý chi phí với AWS Budget + Tạo ngân sách bằng mẫu + Tạo ngân sách chi phí + Tạo ngân sách sử dụng + Tìm hiểu cách tạo ngân sách RI + Cách tạo ngân sách kế hoạch tiết kiệm - Hoc cách sử dụng AWS Support + Các gói Hỗ trợ AWS + Các loại Yêu cầu Hỗ trợ và cách thay đổi gói hỗ trợ + Cách tạo một yêu cầu hỗ trợ và chọn mức độ nghiêm trọng của nó 09/09/2025 09/09/2025 https://000007.awsstudygroup.com/ https://000009.awsstudygroup.com/ 4 - Kiếm được 100 điểm tín dụng thông qua việc hoàn thành các hoạt động trên bảng điều khiển AWS: + Khởi chạy một máy ảo sử dụng EC2 + Tạo Cơ sở dữ liệu Amazon RDS + Tạo một ứng dụng web sử dụng AWS Lambda + Sử dụng một mô hình nền tảng trong khu vực chơi Amazon Bedrock + Thiết lập ngân sách chi phí sử dụng AWS Budgets 09/10/2025 09/10/2025 5 - Tìm hiểu về quản lý quyền truy cập với AWS Identity and Access Management (IAM): + Tạo Nhóm IAM và Người dùng IAM + Tạo Vai trò IAM và Người dùng IAM + Cách chuyển đổi vai trò 09/11/2025 09/11/2025 https://000002.awsstudygroup.com/ 6 - Tìm hiểu về Tường lửa trong VPC + Security Group + Network ACLs + Bản đồ tài nguyên VPC - Tìm hiểu cách xây dựng một môi trường Amazon VPC hoàn chỉnh + Tạo VPC + Tạo Subnet + Tạo Internet Gateway + Tạo Bảng định tuyến + Tạo Security Group + Bật VPC Flow Logs 09/12/2025 09/13/2025 https://000003.awsstudygroup.com/ Kết quả đạt được tuần 1: Tạo và thiết lập thành công tài khoản AWS Free Tier. Làm quen với AWS Management Console và học cách tìm kiếm, truy cập, sử dụng các dịch vụ thông qua giao diện web. Thành thạo việc Quản lý Chi phí và Hỗ trợ của AWS: Học cách tạo và quản lý các Ngân sách AWS khác nhau (Chi phí, Sử dụng, RI, Kế hoạch Tiết kiệm) để duy trì quyền kiểm soát tài chính. Hiểu rõ các gói Hỗ trợ AWS khác nhau và cách tạo và quản lý các yêu cầu hỗ trợ dựa trên mức độ nghiêm trọng. Có được kinh nghiệm thực hành với các dịch vụ cốt lõi của AWS thông qua các hoạt động trên bảng điều khiển: Khởi chạy một máy chủ ảo sử dụng Amazon EC2. Tạo và cấu hình một cơ sở dữ liệu quan hệ với Amazon RDS. Xây dựng một ứng dụng web serverless sử dụng AWS Lambda. Thử nghiệm AI generative sử dụng một mô hình nền tảng trong Amazon Bedrock. Áp dụng kiến thức kiểm soát chi phí bằng cách thiết lập ngân sách với AWS Budgets. Thiết lập nền tảng về bảo mật và quản lý quyền truy cập AWS bằng IAM: Học và áp dụng các nguyên tắc cấp quyền truy cập tối thiểu. Có được kinh nghiệm thực tế trong việc tạo và quản lý Người dùng, Nhóm và Vai trò IAM. Hiểu được quy trình chuyển đổi vai trò để đảm nhận các quyền khác nhau. Xây dựng và bảo mật một môi trường mạng tùy chỉnh với Amazon VPC: Thiết kế và triển khai một VPC hoàn chỉnh, hoạt động được bao gồm các subnet, bảng định tuyến và internet gateway. Học cách bảo mật VPC bằng Security Group (tường lửa có trạng thái) và Network ACLs (tường lửa không trạng thái). Bật tính năng hiển thị hoạt động bằng cách cấu hình VPC Flow Logs để giám sát lưu lượng mạng. "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #1” Mục Đích Của Sự Kiện Cung cấp kiến thức thực tế về AWS Bedrock và phát triển AI hiện đại Giới thiệu khái niệm mô hình nền tảng và phương pháp kỹ thuật prompt hiệu quả Minh họa quy trình làm việc RAG và tìm kiếm dựa trên embedding Trình bày các dịch vụ AI của AWS thường được sử dụng trong ứng dụng thực tế Giải thích kiến trúc hệ thống AgentCore và GenAI sẵn sàng cho sản xuất Danh Sách Diễn Giả Lâm Tuấn Kiệt – Kỹ sư DevOps cao cấp, FPT Software Đặng Hoàng Hiếu Nghi – Kỹ sư AI, Reonova Cloud Đinh Lê Hoàng Anh – Thực tập sinh Kỹ sư Đám mây, FCJ Khá – Chia sẻ lời khuyên về xây dựng dự án hướng sản phẩm cho CV Đại diện FPT – Nói về việc các công ty sử dụng AI trên đám mây để tối ưu hóa và tiết kiệm chi phí Nội Dung Nổi Bật Mô Hình Nền Tảng \u0026amp; Xu Hướng Ngành Các mô hình ML truyền thống xử lý một tác vụ và yêu cầu dữ liệu được gán nhãn. Mô hình nền tảng trong GenAI được đào tạo trên tập dữ liệu không nhãn khổng lồ, cho phép thực hiện đa tác vụ linh hoạt. Bedrock hiện tích hợp các mô hình như OpenAI và DeepSeek. Các công ty ngày càng xây dựng sản phẩm AI trên nền tảng đám mây để giảm chi phí vận hành. Góc Nhìn Từ Lâm Tuấn Kiệt Giải thích sự phát triển từ ML truyền thống → mô hình nền tảng. Nhấn mạnh tầm quan trọng của kỹ thuật prompt để có đầu ra chất lượng cao. Chứng minh cách Bedrock đơn giản hóa việc truy cập các mô hình tiên tiến mà không cần DevOps phức tạp. Nhấn mạnh rằng việc xây dựng sản phẩm AI đòi hỏi kỹ năng, lặp lại và triển khai có trách nhiệm. Kỹ Thuật Prompt Prompt zero-shot – Ngữ cảnh tối thiểu; kết quả có thể đơn giản hoặc mơ hồ. Prompt few-shot – Cung cấp các ví dụ trong prompt để nhận phản hồi rõ ràng hơn. Prompt chain-of-thought – Hướng dẫn mô hình với các bước lập luận để cải thiện độ chính xác và chi tiết. Hệ Thống Sinh Tăng Cường Truy Xuất (RAG) Hệ thống truy xuất thông tin liên quan từ nguồn dữ liệu. Tự động kết hợp prompt của người dùng với ngữ cảnh được truy xuất. Tạo ra phản hồi chính xác và phù hợp hơn. Embeddings Văn bản được chuyển đổi thành vector biểu thị ý nghĩa. Các ý nghĩa tương tự được nhóm lại với nhau trong không gian vector. AWS Titan Text Embeddings hỗ trợ hơn 100 ngôn ngữ. Các Dịch Vụ AI Của AWS Rekognition – Phát hiện đối tượng trong hình ảnh/video Translate – Dịch tự động Textract – Trích xuất văn bản và cấu trúc bố cục Transcribe – Chuyển giọng nói thành văn bản với nhận diện người nói Polly – Chuyển văn bản thành giọng nói Comprehend – NLP, trích xuất thực thể, hiểu mối quan hệ Kendra – Tìm kiếm tài liệu thông minh Lookout Family – Phát hiện bất thường cho số liệu, thiết bị và thị giác máy tính Personalize – Hệ thống đề xuất Pipecat – Khung công tác đường ống tác nhân AI Các nhà phát triển có thể sử dụng trực tiếp các dịch vụ này qua API.\nAmazon Bedrock AgentCore Cho phép xây dựng ứng dụng AI mà không cần quản lý hạ tầng và DevOps nặng nề. Hỗ trợ các khung công tác hiện đại như LangGraph và LangChain. Được thiết kế để giúp các nhóm chuyển từ nguyên mẫu → sản xuất hiệu quả. Cơ Chế Chính\nThời gian chạy Bộ nhớ Danh tính Cổng kết nối Trình thông dịch mã Công cụ duyệt web Khả năng quan sát Những Gì Học Được Tư Duy Phát Triển AI Việc tạo ra sản phẩm thực tế có giá trị hơn việc chỉ đáp ứng yêu cầu học thuật. Mô hình nền tảng cho phép thử nghiệm và triển khai nhanh chóng. Kỹ thuật prompt ảnh hưởng đáng kể đến chất lượng đầu ra. Tác Động Kỹ Thuật RAG nâng cao độ chính xác bằng cách căn cứ phản hồi vào dữ liệu thực. Embeddings cải thiện tìm kiếm ngữ nghĩa và truy xuất thông tin. Các dịch vụ AI của AWS bao quát quy trình làm việc từ đầu đến cuối — từ giọng nói, thị giác đến NLP. Tính Ứng Dụng Thực Tế Các công ty ngày càng áp dụng AI dựa trên đám mây để giảm chi phí và đẩy nhanh phát triển sản phẩm. Kỹ năng về kỹ thuật prompt, embeddings và dịch vụ Bedrock đang trở nên thiết yếu. Trải Nghiệm Trong Event Tham dự AWS Cloud Mastery Series #1 mang lại hiểu biết thực tế về cách các hệ thống AI hiện đại hoạt động trên AWS.\n1. Học Hỏi Trực Tiếp Từ Kỹ Sư Các diễn giả chia sẻ kinh nghiệm làm việc thực tế từ các vai trò DevOps, AI và kỹ sư đám mây. 2. Kiến Thức Kỹ Thuật Thực Hành Ví dụ về kỹ thuật prompt Minh họa về RAG Các trường hợp sử dụng cho từng dịch vụ AI của AWS 3. Xây Dựng Cho Tương Lai Được khuyến khích xây dựng sản phẩm thực Kỹ năng Đám mây + AI đang trở thành yêu cầu cốt lõi Tập trung mạnh vào triển khai thực tế thay vì lý thuyết Một Số Hình Ảnh Khi Tham Gia Sự Kiện "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Thành thạo việc triển khai và quản lý máy chủ EC2 Triển khai mạng AWS và kết nối VPN Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học cách triển khai máy chủ Amazon EC2 + Tạo máy chủ EC2 + Kết nối vào máy chủ EC2 + Tạo NAT Gateway + Sử dụng Reachability Analyzer + Tạo EC2 Instance Connect Endpoint + Truy cập Secure Shell với AWS Systems Manager Session Manager + Triển khai Giám sát CloudWatch và cảnh báo cho tài nguyên VPC 15/09/2025 15/09/2025 https://000003.awsstudygroup.com/ 3 - Thiết lập Kết nối VPN Site-to-Site trên AWS + Tạo môi trường VPN (VPC cho VPN) + Tạo máy chủ EC2 đóng vai trò Customer Gateway + Tạo Virtual Private Gateway + Tạo Customer Gateway 16/09/2025 16/09/2025 https://000003.awsstudygroup.com/ 4 - Cấu hình Kết nối VPN + Tạo Kết nối VPN + Thực hiện Cấu hình Customer Gateway + Chỉnh sửa cài đặt AWS VPN Tunnel + Xem lại các Cấu hình VPN Thay thế 17/09/2025 17/09/2025 https://000003.awsstudygroup.com/ 5 - Tham gia sự kiện Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders 18/09/2025 18/09/2025 6 - Xử lý Sự cố VPN \u0026amp; Cấu hình Nâng cao + Làm theo Hướng dẫn Xử lý sự cố VPN + Xem lại Hướng dẫn Xử lý sự cố VPN chính thức của AWS + Kết nối VPN sử dụng Strongswan với Transit Gateway 19/09/2025 19/09/2025 https://000003.awsstudygroup.com/ Kết quả đạt được tuần 2: Triển khai và quản lý thành công máy chủ EC2:\nĐã tạo và khởi chạy máy chủ EC2 sử dụng AWS Management Console. Kết nối vào máy chủ thông qua EC2 Instance Connect và Systems Manager Session Manager. Cấu hình NAT Gateway để cho phép subnet private truy cập internet. Sử dụng Reachability Analyzer để xác minh kết nối mạng. Triển khai giám sát CloudWatch và cảnh báo cho tài nguyên VPC và EC2. Thiết lập và cấu hình kết nối VPN Site-to-Site:\nTạo môi trường VPN bao gồm VPC chuyên dụng cho cấu hình VPN. Triển khai máy chủ EC2 đóng vai trò Customer Gateway. Tạo và gắn Virtual Private Gateway. Cấu hình kết nối VPN giữa AWS và Customer Gateway. Chỉnh sửa cài đặt VPN tunnel và xem xét các cấu hình VPN thay thế. Thực hiện xử lý sự cố và cấu hình nâng cao VPN:\nLàm theo hướng dẫn xử lý sự cố VPN của AWS để xác định và giải quyết các vấn đề kết nối phổ biến. Kiểm tra kết nối VPN sử dụng Strongswan tích hợp với AWS Transit Gateway. Xác minh giao tiếp an toàn giữa tài nguyên on-premises và VPC trên AWS. Nâng cao hiểu biết về các thành phần mạng AWS và quản lý kết nối, bao gồm mạng EC2, NAT Gateway, VPN và các công cụ giám sát.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Tài liệu Đề Xuất Xem tài liệu Đề Xuất\nNỀN TẢNG TRỰC TUYẾN ĐỂ THEO DÕI VÀ DỰ BÁO QUỸ ĐẠO BÃO Kỹ thuật tự nhận thức trắc địa (Geodesic-Aware Deep Learning) cho dự đoán hướng di chuyển chính xác: Một phương pháp tiếp cận dựa trên kêt hợp \u0026ldquo;mô phỏng vật lý\u0026rdquo; và \u0026ldquo;tăng cường dữ liệu\u0026rdquo; 1. Tóm tắt điều hành Dữ liệu chuỗi thời gian đóng vai trò là một trong những dạng biểu diễn thông tin quan trọng nhất trong các ứng dụng khoa học và công nghiệp hiện đại. Nó cần thiết để hiểu các quá trình động như xu hướng kinh tế, mô hình tiêu thụ năng lượng và sự thay đổi khí tượng theo thời gian. Đặc biệt, dự báo thời tiết phụ thuộc mạnh mẽ vào dữ liệu chuỗi thời gian để dự đoán điều kiện khí quyển trong tương lai, quỹ đạo bão và các biến động theo mùa dựa trên dữ liệu lịch sử.\nVới sự phát triển nhanh chóng trong nghiên cứu về học sâu và mạng nơ-ron, dự án của chúng tôi hướng đến việc phát triển một mô hình dự báo tiên tiến có khả năng dự đoán chính xác đường đi, cường độ và tổng quãng đường di chuyển của các cơn bão trong vài ngày tiếp theo. Các dự đoán này có thể hỗ trợ hệ thống cảnh báo sớm, giúp chính quyền và cư dân tại các khu vực bị ảnh hưởng có thể đưa ra biện pháp phòng tránh trước khi bão đổ bộ.\nĐể vượt qua những hạn chế của công nghệ và nghiên cứu hiện tại, nghiên cứu này giới thiệu một số kỹ thuật và thuật toán mới, bao gồm hai phương pháp tăng cường dữ liệu mới cho chuỗi thời gian trắc địa và một cơ chế mã hóa không gian được thiết kế để nâng cao hiệu suất dự đoán của điện toán tích chập. Hệ thống cuối cùng sẽ được tích hợp vào kiến trúc đám mây không máy chủ trên AWS, đảm bảo khả năng mở rộng, tính khả dụng cao và hiệu quả chi phí cho việc theo dõi và phân tích bão theo thời gian thực.\nKiến trúc hệ thống tận dụng một số dịch vụ AWS để tạo thành một quy trình xử lý và triển khai dữ liệu được quản lý hoàn toàn. Các hàm AWS Lambda đóng vai trò là là xương sống cho hoạt động tính toán không máy chủ, được kích hoạt tự động bởi Amazon EventBridge để thu thập và xử lý dữ liệu bão mới từ các nguồn khí tượng mở theo lịch trình. Dữ liệu đã xử lý được lưu trữ an toàn trên Amazon S3, trong khi AWS CodePipeline và CodeBuild tự động hóa việc tích hợp và triển khai liên tục các phiên bản mô hình mới. Mô hình sau khi huấn luyện được lưu trữ và cung cấp qua Amazon API Gateway, cho phép nền tảng dự báo trực tuyến thực hiện các yêu cầu suy luận nhẹ, theo thời gian thực. Mọi hoạt động của hệ thống được giám sát thông qua Amazon CloudWatch, cung cấp khả năng quan sát hoạt động, phát hiện lỗi và các số liệu hiệu suất.\nPhương pháp đầu tiên được đề xuất, Khung Tăng cường Dữ liệu Phai mờ Theo Thời Gian Theo Từng Bước (Stepwise Temporal Fading Augmentation - STFA), là một khuôn khổ tăng cường dữ liệu chuỗi thời gian mới, mô phỏng sự suy giảm tự nhiên của ảnh hưởng từ các quan sát trong quá khứ. Khác với các phương pháp tiếp cận truyền thống dựa trên việc gây nhiễu ngẫu nhiên hoặc bơm nhiễu, STFA áp dụng các trọng số phai mờ cho các bước thời gian trước đó trong khi vẫn bảo toàn thông tin gần đây. Quá trình này tạo ra các chuỗi tổng hợp đa dạng và chân thực, từ đó cải thiện độ mạnh mẽ và khả năng khái quát hóa của mô hình. Kỹ thuật này sẽ được đánh giá trên các tác vụ dự báo quỹ đạo bão, vốn dựa trên dữ liệu vĩ độ-kinh độ tuần tự.\nPhương pháp thứ hai, Tăng cường Hướng đi Trắc địa Hợp lý (Plausible Geodesic Bearing Augmentation - PGBA), giới thiệu một chiến lược tăng cường dựa trên phạm vi khả thi của hướng di chuyển và khoảng cách của bão. Bằng cách phân tích hướng đi trắc địa (geodesic bearing) và khoảng cách giữa các vị trí bão liên tiếp, PGBA xác định một biên giới chuyển động thực tế, trong đó các quỹ đạo tổng hợp mới được tạo ra. Cách tiếp cận này nâng cao khả năng của mô hình trong việc nắm bắt sự biến đổi không gian tự nhiên và độ bất định về hướng trong chuyển động của bão.\nNgoài ra, nghiên cứu này còn khám phá một biểu diễn không gian-thời gian (spatial-temporal representation) của dữ liệu chuỗi thời gian, cho phép áp dụng các mạng nơ-ron tích chập (Convolutional Neural Networks - CNNs) để nắm bắt cả sự phụ thuộc về không gian và thời gian. Biểu diễn này tận dụng thế mạnh của điện toán tích chập để mô hình hóa các tương tác cục bộ trên không gian và thời gian. Nó sẽ đóng vai trò là cơ sở (baseline) để so sánh với các mô hình Mạng Tích chập Thời gian (Temporal Convolutional Network - TCN) được huấn luyện bằng các phương pháp tăng cường dữ liệu đã được đề xuất.\nCác mạng nơ-ron truyền thống, dù được sử dụng cho mô hình hóa dữ liệu chuỗi thời gian hay dữ liệu ảnh, chủ yếu chỉ học các mẫu thống kê từ dữ liệu. Tuy nhiên, trong nhiều hệ thống vật lý thực tế, các mô hình hoàn toàn dựa trên dữ liệu như vậy có thể không tuân thủ các ràng buộc tự nhiên, chẳng hạn như các mối quan hệ trọng lực hoặc trắc địa. Để khắc phục hạn chế này, chúng tôi kết hợp các nguyên lý của Học máy Thông tin Vật lý (Physics-Informed Machine Learning - PIML) vào phương pháp tiếp cận của mình.khoảng cách trắc địa và phương vị được lấy từ dữ liệu vĩ độ-kinh độ và được tích hợp vào quá trình huấn luyện của mô hình như như những đặc trưng mang ý nghĩa vật lý. Hơn nữa, chúng tôi sử dụng công thức Haversine — công thức tính khoảng cách hình cầu giữa hai điểm - làm một số hạng mất mát phụ, bổ sung cho các số liệu sai số chuẩn như MSE, RMSE, MAE và MAPE.\nBằng cách kết hợp các phương pháp tăng cường dữ liệu được đề xuất, các nguyên tắc học máy thông tin vật lý (PIML) và một cơ sở hạ tầng học sâu không máy chủ được vận hành bởi các dịch vụ AWS, nghiên cứu này hướng đến mục tiêu phát triển một khuôn khổ dự báo quỹ đạo bão có khả năng mở rộng, mạnh mẽ và chính xác. Hệ thống thu được không chỉ nâng cao trình độ mô hình hóa chuỗi thời gian trắc địa mà còn chứng minh tính thực tiễn của việc triển khai các hệ thống dự báo môi trường dựa trên AI như các ứng dụng bản địa đám mây (cloud-native) bền bỉ, giúp tăng cường khả năng chuẩn bị và đảm bảo an toàn cho các khu vực dễ bị ảnh hưởng bởi bão.\n2. Tuyên bố vấn đề Vấn đề hiện tại? Để phát triển một nền tảng đáng tin cậy nhằm theo dõi và đưa ra cảnh báo về đường đi của bão trong tương lai, việc xây dựng một mô hình máy học vừa chính xác vừa có khả năng đưa ra các dự đoán đáng tin cậy là hết sức quan trọng. Thành phần theo dõi có thể được giải quyết bằng cách liên tục thu thập và cập nhật dữ liệu từ các nguồn khí tượng công cộng. Tuy nhiên, các tập dữ liệu này thường bị giới hạn về mặt địa lý và chứa nhiều thông tin trùng lặp hoặc không đầy đủ.\nNgược lại, thành phần dự báo lại có độ phức tạp cao hơn. Việc đạt được dự báo chuỗi thời gian chính xác trong bối cảnh này thường phải đối mặt với hai thách thức chính: (1) tính đa dạng và phạm vi bao phủ của dữ liệu có sẵn còn hạn chế, và (2) sự thiếu vắng các nguyên tắc vật lý nền tảng, điều này làm hạn chế khả năng của mô hình trong việc phản ánh các động lực địa vật lý cơ bản của hành vi bão.\nThiếu dữ liệu: Nhiều tác vụ dự báo chuỗi thời gian gặp hạn chế về lượng dữ liệu huấn luyện. Mặc dù có nhiều phương pháp tăng cường dữ liệu, nhưng rất ít phương pháp tập trung trực tiếp vào sự suy giảm tầm quan trọng của các giá trị trong quá khứ theo thời gian.\nBỏ qua yếu tố vật lý:: Hầu hết các mạng nơ-ron chỉ học từ dữ liệu thô mà không xét đến các ràng buộc vật lý trong thế giới thực. Trong các tác vụ dự đoán quỹ đạo (ví dụ: bão), điều này thường dẫn đến những kết quả phi thực tế.\nMục tiêu của nhóm :\nPhát triển một phương pháp tăng cường chuỗi thời gian mới (STFA) nhằm cải thiện độ bền vững và khả năng khái quát của mô hình. Tích hợp các ràng buộc dựa trên vật lý vào quá trình huấn luyện mô hình, thu hẹp khoảng cách giữa học máy dựa trên dữ liệu và động lực học của thế giới thực. Kiểm tra sức mạnh của mạng tích chập (convolution2D) trong việc dự báo quỹ đạo. Xây dựng một nền tảng trực tuyến cung cấp thông tin mới nhất về các cơn bão hiện tại và các dự đoán chính xác về quỹ đạo của chúng. Giải Pháp A - Tăng cường cường dữ liệu bằng Stepwise Temporal Fading (STFA) STFA biến đổi các chuỗi thời gian bằng cách giảm dần ảnh hưởng của các giá trị trong quá khứ. Khác với phương pháp thêm nhiễu ngẫu nhiên, nó áp dụng một cách có hệ thống các hệ số phai mờ theo từng bước vào các nhóm dữ liệu cũ.\nCho một chuỗi đơn biến là:\n$$ X = [x_0, x_1, \\ldots, x_{T-1}] $$\ntrong đó $T$ là độ dài của chuỗi $X$.\nCác tham số:\n$n$: khoảng giá trị gần nhất muốn giữ nguyên $S$: số dải được áp dụng phai dần $L = T - n$: độ dài của vùng phai dần $k = \\frac{L}{S}$: số giá trị trong mỗi dải $I_b$: tập chỉ số của dải thứ $b$ \\[ I_b = {, i \\mid L - b \\cdot k ;\\leq; i ;\\leq; L - (b-1)\\cdot k - 1 ,} \\]\nBiến đổi::\nKý hiệu chuỗi dữ liệu đã được tăng cường là:\n$$ X = [x_0, \\ldots, x_{T-1}] $$\nvới các quy tắc biến đổi sau:\n$$ x_t = \\begin{cases} x_t, \u0026amp; t \\in {T-n, \\ldots, T-1}, \\\\ m_b , x_t, \u0026amp; t \\in I_b, \\\\ m_{S+1} , x_t, \u0026amp; t \u0026lt; \\min(I_S), \\end{cases} $$\ntrong đó các hệ số nhân $m_b \\in (0,1)$ giảm dần đều từ các nhóm dữ liệu gần nhất tới các dữ liệu cũ hơn.\nCông thức này duy trì độ thực tế, chính xác của các dữ liệu gần đây trong khi kiểm soát chặt chẽ hơn ảnh hưởng của các giá trị xa trong chuỗi. Việc tăng cường này buộc mô hình tập trung vào các mẫu hình mạnh mẽ hơn thay vì chỉ phụ thuộc vào dữ liệu thô, đồng thời gia tăng tính đa dạng của dữ liệu theo các tham số được chọn.\nB - Tăng Cường theo Hướng Di Chuyển Hợp Lý (PGBA - Plausible Geodesic Bearing Augmentation) Kỹ thuật Tăng cường Hướng Di chuyển (dựa trên) Trắc địa Hợp lý (PGBA) nâng cao tính chân thực và khả năng kiểm soát của việc tạo ra quỹ đạo trong các tác vụ dự báo chuỗi thời gian không gian địa lý. Khác với các phương pháp nhiễu loạn ngẫu nhiên thông thường, PGBA đưa vào yếu tố ngẫu nhiên nhưng vẫn đảm bảo sự hợp lý trong các ràng buộc vật lý của chuyển động cơ bản. Các quỹ đạo được tạo ra bắt nguồn từ các mối quan hệ hình học của các quan sát trong quá khứ thay vì từ các bước hoàn toàn ngẫu nhiên, dẫn đến các đường đi mượt mà hơn và tính biến thiên có ý nghĩa trong tập dữ liệu huấn luyện. Kỹ thuật này được áp dụng cho mỗi bốn vị trí trong một chuỗi dữ liệu.\nPGBA đóng vai trò là phương pháp tăng cường bổ trợ cho STFA, làm phong phú thêm tính đa dạng của các mẫu huấn luyện trong khi vẫn bảo toàn cấu trúc động học ban đầu. Mục tiêu của nó là tạo ra các quỹ đạo dư thừa nhưng vẫn đảm bảo tính nhất quán vật lý, từ đó nắm bắt được các biến thể tiềm năng trong chuyển động của bão hoặc các hiện tượng không gian địa lý tương tự.\nCơ chế cốt lõi\nXét một quỹ đạo bão được biểu diễn bằng một chuỗi $n$ các vị trí địa lý theo thứ tự:\n$$ P = [P_1, P_2, \\ldots, P_n] $$\nChúng tôi chia chuỗi này thành các khối nhỏ gồm 4 điểm, với $P_i$ là điểm bắt đầu của mỗi khối, được xác định bởi vĩ độ và kinh độ:\n$$ P_i = (\\phi_i, \\lambda_i) $$\nỞ đây, $\\phi_i$ và $\\lambda_i$ lần lượt biểu thị cho vĩ độ và kinh độ theo đơn vị radian.\nKhoảng cách trắc địa $d_i$ và góc phương vị $\\theta_i$ giữa hai điểm liên tiếp $P_i$ và $P_{i+1}$ được xác định như sau:\n$$ d_i = \\text{Distance}(P_i, P_{i+1}), \\qquad \\theta_i = \\text{Bearing}(P_i, P_{i+1}) $$\nĐể tạo ra biến đổi hợp lý, PGBA làm nhiễu góc phương vị bằng cách thêm một nhiễu ngẫu nhiên nhỏ có phân phối đều $\\epsilon_i$:\n$$ \\theta_i^{\\text{aug}} = \\theta_i + \\epsilon_i, \\qquad \\epsilon_i \\sim \\text{Uniform}(-\\delta, \\delta) $$\ntrong đó $\\delta$ là giới hạn góc có thể điều chỉnh để kiểm soát phạm vi lệch.\nHai điểm đầu tiên luôn được giữ nguyên và được sử dụng để tính toán khoảng cách và hướng di chuyển. Điểm tiếp theo được tăng cường sau đó được tính toán bằng công thức định vị trắc địa, giữ nguyên khoảng cách trong khi cho phép hướng di chuyển thay đổi trong phạm vi nhiễu ngẫu nhiên:\n$$ P_{i+2}^{\\text{aug}} = \\text{Destination}(P_i, d_i, \\theta_i^{\\text{aug}}) $$\nQuá trình này bảo toàn khoảng cách giữa các điểm $d_i$ trong khi làm lệch hướng một cách nhẹ để tạo ra các độ lệch hợp lý về mặt vật lý.\nLàm mượt và Hiệu chỉnh Đa Bước\nĐể nâng cao độ mượt và tạo ra các quỹ đạo cong tự nhiên, PGBA áp dụng một hiệu chỉnh tại mỗi điểm thứ tư. Gọi $P_{i+3}^{\\text{aug}}$ là điểm thứ tư. Nó được tính toán lại sao cho góc phương vị $\\theta_{i+3}^{\\text{corr}}$ của nó tối thiểu hóa độ lệch so với điểm gốc $P_{i+3}$:\n$$ \\theta_{i+3}^{\\text{corr}} = \\arg\\min_{\\theta}; \\text{Distance}\\Big( \\text{Destination}(P_{i+2}^{\\text{aug}}, d_{i+2}, \\theta),; P_{i+3} \\Big) $$\nSau đó, điểm tăng cường đã hiệu chỉnh được xác định như sau:\n$$ P_{i+3}^{\\text{aug}} = \\text{Destination}(P_{i+2}^{\\text{aug}}, d_{i+2}, \\theta_{i+3}^{\\text{corr}}) $$\nBước này đảm bảo sự chuyển tiếp mượt mà giữa nhiều điểm trong khi vẫn duy trì tính hợp lý về mặt vật lý.\nLưu ý rằng hai điểm đầu tiên và điểm cuối cùng trong mỗi chuỗi thời gian trắc địa luôn được giữ nguyên không thay đổi.\nC - Học máy (Machine Lerning) dựa trên vật lý Các mô hình mạng nơ-ron như RNNs, CNNs, và Transformers không cần công thức hay quy tắc đặc thù cho từng tác vụ để đạt hiệu suất tốt, miễn là chúng được huấn luyện với đủ dữ liệu. Ví dụ, trong tác vụ dịch máy như dịch từ tiếng Đức sang tiếng Anh bằng RNN, không có quy tắc ngữ pháp nào được cung cấp trong quá trình huấn luyện (không tính stemming, letmat, pos tagging, \u0026hellip; chỉ nói đến quá trình huấn luyện). Tuy nhiên, mô hình vẫn có thể tạo ra bản dịch mạch lạc, thể hiện một trong những điểm mạnh chính của học sâu: khả năng học trực tiếp các mẫu phức tạp từ dữ liệu. Ngược lại, các phương pháp truyền thống — chẳng hạn như các hệ thống dịch dựa trên quy tắc (ví dụ: Google Translate trước những năm 2000) — phụ thuộc nhiều vào quy tắc ngữ pháp và từ điển. Mặc dù chính xác, nhưng các hệ thống này thường thiếu linh hoạt và thất bại khi gặp từ có nhiều nghĩa hoặc các cấu trúc phụ thuộc vào ngữ cảnh.\nLấy cảm hứng từ sự khác biệt đó, mục tiêu của chúng tôi là kết hợp sức mạnh của học sâu với các công thức do con người định nghĩa để đạt hiệu suất tốt hơn. Cụ thể trong lĩnh vực địa lý này, chúng tôi sẽ thử đưa các lợi ích từ công thức Haversine vào quá trình huấn luyện để tính toán khoảng cách và góc phương vị giữa hai vị trí trên một hình cầu. Những yếu tố này cung cấp cho mô hình một cấu trúc bổ sung và độ lệch quy nạp, định hướng việc học vượt ra ngoài các tương quan thuần túy thống kê.\nCông thức Haversine\nĐối với việc tính toán khoảng cách\nCông thức Haversine được sử dụng để tính khoảng cách cung lớn giữa hai điểm trên bề mặt hình cầu — tức là đường đi ngắn nhất trên bề mặt Trái Đất.\n$$ d = 2r , \\arcsin!\\left( \\sqrt{ \\sin^2!\\left(\\frac{\\Delta \\varphi}{2}\\right) + \\cos(\\varphi_1)\\cos(\\varphi_2) \\sin^2!\\left(\\frac{\\Delta \\lambda}{2}\\right) } \\right) $$\nTrong đó:\n$$(\\varphi_1, \\lambda_1)$$ và $$(\\varphi_2, \\lambda_2)$$ là vĩ độ và kinh độ của hai điểm (tính bằng raidian). $\\Delta \\varphi = \\varphi_2 - \\varphi_1$ $\\Delta \\lambda = \\lambda_2 - \\lambda_1$ $r$ là bán kính Trái Đất (≈ 6,371 km). Trong khuôn khổ của chúng tôi, thay vì chỉ dựa vào các hàm mất mát tiêu chuẩn như MSE, RMSE hay MAPE, chúng tôi đề xuất sử dụng công thức Haversine để tính khoảng cách làm hàm mất mát chính. Khi mô hình xuất ra tọa độ vĩ độ và kinh độ cho vị trí bão tiếp theo, công thức Haversine trực tiếp đo lường khoảng cách giữa điểm dự đoán và điểm thực tế. Khoảng cách gần 0 cho thấy dự đoán có độ chính xác cao, trong khi khoảng cách lớn báo hiệu một sai số đáng kể.\nĐối với việc tính toán góc phương vị (bearing)\nCông thức tính góc phương vị được suy ra từ Công thức Haversine, cho biết hướng đi từ một điểm địa lý này đến một điểm khác dọc theo đường tròn lớn:\n$$\\theta = \\text{atan2}!\\left(\\sin(\\Delta \\lambda)\\cos(\\varphi_2),, \\cos(\\varphi_1)\\sin(\\varphi_2) - \\sin(\\varphi_1)\\cos(\\varphi_2)\\cos(\\Delta \\lambda)\\right)$$\nTrong đó:\n$(\\varphi_1, \\lambda_1)$ là điểm xuất phát. $(\\varphi_2, \\lambda_2)$ là điểm kết thúc. $\\Delta \\lambda$ là hiệu số kinh độ. Kết quả $\\theta$ đại diện cho góc phương vị ban đầu (azimuth) được đo theo chiều kim đồng hồ từ hướng Bắc thực.\nTrong quá trình triển khai, chúng tôi tận dụng triệt để việc sử dụng Công thức Haversine để tính toán hai đặc trưng bổ sung — \u0026ldquo;khoảng cách\u0026rdquo; và \u0026ldquo;góc phương vị\u0026rdquo; — được thêm vào tập dữ liệu. Các đặc trưng này cung cấp cho mô hình thông tin phong phú hơn về quỹ đạo bão, đồng thời vẫn duy trì mục tiêu cốt lõi là dự đoán vị trí địa lý tiếp theo.\nD - Tổng quan ngắn về những hiểu lầm phổ biến trong các phương pháp tiếp cận mô hình hóa chuỗi Trong lĩnh vực mô hình hóa chuỗi thuộc học sâu, các kiến trúc dạng hồi quy như RNN, LSTM và GRU thường được coi là giải pháp mặc định. Nhận thức này đã khiến nhiều người thực hành và nhà nghiên cứu bỏ qua các kiến trúc thay thế, đặc biệt là Mạng Nơ-ron Tích chập (CNN) - vốn thường được liên hệ chủ yếu với các tác vụ xử lý hình ảnh. Sách giáo khoa và các khóa học thường phân loại các tác vụ như mô hình hóa ngôn ngữ, dịch máy, hoặc các dự đoán tuần tự khác là lĩnh vực của các mạng hồi quy, trong khi các mạng tích chập thường chỉ được giới thiệu trong bối cảnh dữ liệu không gian như hình ảnh. Kết quả là, tiềm năng của CNN cho mô hình hóa chuỗi thường bị đánh giá thấp hoặc bị bỏ qua.\nCác mạng tích chập (Convolutional networks) mang lại một số ưu điểm khiến chúng phù hợp cho dữ liệu tuần tự. Tính song song vốn có của chúng cho phép huấn luyện nhanh hơn đáng kể so với các mô hình tuần tự nghiêm ngặt. Ngoài ra, CNN có hiệu quả cao trong việc nắm bắt các quan hệ không gian và thời gian cục bộ - một đặc tính có thể được tận dụng trong dự báo chuỗi thời gian và các tác vụ tuần tự khác. Tuy vậy, CNN thường bị hiểu nhầm là không phù hợp cho chuỗi do thiếu cơ chế bộ nhớ rõ ràng và không có thứ tự thời gian nội tại.\nTrong nghiên cứu của chúng tôi, chúng tôi tập trung vào dự báo quỹ đạo bão, nơi dữ liệu bao gồm các bản ghi chuỗi thời gian của tọa độ vĩ độ và kinh độ. Chúng tôi chứng minh rằng loại dữ liệu tuần tự này có thể được mô hình hóa hiệu quả bằng cách sử dụng CNN, tận dụng hiệu suất tính toán và khả năng nắm bắt các mẫu hình không-thời gian cục bộ của chúng. Để hỗ trợ điều này, chúng tôi mã hóa các vị trí thành một biểu diễn ma trận 2D, cho phép mạng tích chập trích xuất và học các mẫu hình từ dữ liệu hiệu quả hơn. Mỗi mục trong ma trận tương ứng với một \u0026ldquo;điểm ảnh\u0026rdquo; của một hình ảnh, một cách tiếp cận mà chúng tôi gọi là Quỹ đạo-dưới-dạng-Hình ảnh (Trajectory-as-Image). Phương pháp của chúng tôi sử dụng một CNN tiêu chuẩn làm cơ sở, sau đó so sánh nó với các mô hình chuỗi chuyên biệt hơn, bao gồm TCN, LSTM và RNN, đồng thời kết hợp các kỹ thuật tăng cường dữ liệu khác nhau, bao gồm hai phương pháp mới được đề xuất trong công trình này.\nThông qua quá trình thử nghiệm và đánh giá có hệ thống, chúng tôi mong muốn thách thức quan điểm phổ biến cho rằng kiến trúc tích chập không phù hợp với dữ liệu chuỗi. Bằng cách làm nổi bật hiệu quả của CNN trong mô hình hóa chuỗi, chúng tôi hy vọng mở rộng góc nhìn của cộng đồng nghiên cứu và thực hành, khuyến khích họ xem xét điện toán tích chập như một hướng tiếp cận khả thi và cạnh tranh trong dự báo chuỗi thời gian cũng như các tác vụ dự đoán tuần tự khác.\nLợi ích và Hiệu quả đầu tư Tăng hiệu suất: STFA + PGBA tạo ra các chuỗi tổng hợp có cấu trúc giúp tăng cường độ mạnh mẽ của mô hình, giảm hiện tượng quá khớp và cải thiện khả năng khái quát hóa trên các quỹ đạo bão chưa từng thấy.\nNhận thức vật lý: Việc tích hợp các nguyên lý địa lý như khoảng cách và góc phương vị giúp tăng khả năng diễn giải và đảm bảo kết quả dự đoán phù hợp với các ràng buộc vật lý.\nHướng nghiên cứu mới: Thiết lập hai mô hình mới cho việc tăng cường chuỗi thời gian dựa trên sự phai mờ liên quan theo thời gian, mở rộng bộ công cụ phương pháp luận cho học máy chuỗi.\nScalability and Reusability: Khuôn khổ kết hợp STFA + PGBA + PIML có thể được mở rộng sang các lĩnh vực dự báo chuỗi khác như nhu cầu năng lượng, lưu lượng giao thông và xu hướng tài chính.\nTác động tổng thể: Bằng cách cải thiện độ ổn định và khả năng diễn giải của mô hình trong khi vẫn duy trì tính mở rộng, phương pháp được đề xuất mang lại cả giá trị khoa học lẫn hiệu quả thực tiễn trong đầu tư tính toán.\n3. Kiến trúc giải pháp Nền tảng trực tuyến cung cấp cho người dùng thông tin cập nhật về các cơn bão gần đây và một công cụ mạnh mẽ để dự báo quỹ đạo bão. Người dùng có thể xem dữ liệu bão gần đây hoặc chạy các dự đoán bằng các mô hình ML. Kết quả được hiển thị trực quan trên bản đồ, cho thấy vị trí, thời gian và đường đi dự đoán của bão.\nNền tảng được xây dựng bằng kiến trúc không máy chủ trên AWS để giảm chi phí vận hành trong khi vẫn đảm bảo khả năng mở rộng và độ tin cậy. Nội dung frontend được lưu trữ trên Amazon S3 và phân phối toàn cầu thông qua CloudFront, đảm bảo truy cập với độ trễ thấp. Yêu cầu của người dùng được định tuyến qua API Gateway tới các hàm Lambda, nơi xử lý tính toán dự đoán và truy xuất dữ liệu. Các mô hình ML đã được huấn luyện trước và tập dữ liệu bão gần đây được lưu trữ an toàn trong S3, với các bản cập nhật hàng tuần được quản lý tự động bởi trình thu thập dữ liệu kích hoạt qua EventBridge. Các khóa API nhạy cảm được lưu trữ trong Secrets Manager, và hiệu suất hệ thống được giám sát thông qua nhật ký và số liệu trên CloudWatch. IAM thực thi quyền truy cập tối thiểu cho tất cả các dịch vụ.\nCác mô hình dự báo tận dụng các kỹ thuật STFA (Tăng cường Phai mờ Thời gian Theo từng Bước) và PGBA (Tăng cường Hướng đi Trắc địa Hợp lý) được đề xuất. Các phương pháp này tạo ra các quỹ đạo chuỗi thời gian tổng hợp chân thực, bảo toàn mức độ liên quan theo thời gian và tính nhất quán không gian, giúp cải thiện đáng kể độ mạnh mẽ và độ chính xác của mô hình. Bằng cách tích hợp STFA và PGBA, nền tảng cung cấp các dự báo đường đi bão chính xác hơn, giúp người dùng hiểu rõ hơn về hành vi của bão và đưa ra quyết định sáng suốt.\nKiến trúc này cho phép tạo ra một nền tảng phản hồi nhanh, hiệu quả về chi phí và bảo mật, nơi người dùng có thể trực quan hóa thông tin bão theo thời gian thực và khám phá các dự báo quỹ đạo bão với bản đồ tương tác, được hỗ trợ bởi các phương pháp tăng cường tiên tiến để nâng cao hiệu suất mô hình.\nHình 1 : Sơ đồ huấn luyện mô hình Machine Learning Hình 2 : Kiến Trúc Platform Các dịch vụ AWS được sử dụng Amazon S3: Lưu trữ các tệp frontend tĩnh, các mô hình ML đã được huấn luyện trước và dữ liệu bão mới nhất. AWS Lambda: Chạy các mô hình dự đoán, truy xuất dữ liệu bão và thực thi tự động hóa thu thập dữ liệu web. Amazon API Gateway: Xử lý các yêu cầu từ frontend cho dự báo và dữ liệu bão. Amazon CloudFront: Phân phối nội dung tĩnh trên toàn cầu với độ trễ thấp. Amazon Route 53: Định tuyến lưu lượng người dùng đến CloudFront. Amazon EventBridge: Lập lịch trình thu thập dữ liệu hàng tuần. AWS Secrets Manager: Lưu trữ an toàn các khóa API từ bên ngoài. Amazon CloudWatch: Giám sát nhật ký Lambda, số liệu hiệu suất và tình trạng hệ thống. AWS IAM: Gắn quyền truy cập tối thiểu (least-privilege) cho tất cả các dịch vụ. Thiết kế thành phần Lớp Frontend: Được lưu trữ trên S3 và phân phối thông qua CloudFront. Lớp Backend: Xử lý dự báo và truy xuất dữ liệu bằng API Gateway và Lambda. lưu trữ Dữ liệu: Các mô hình ML được lưu trữ trong S3, dữ liệu bão mới nhất được cập nhật hàng tuần bởi trình thu thập dữ liệu. Tự động hóa: EventBridge kích hoạt Crawler Lambda hàng tuần để lấy dữ liệu bão từ các nguồn bên ngoài. Bảo mật \u0026amp; Giám sát: Các thông tin nhạy cảm được lưu trữ trong Secrets Manager, số liệu và nhật ký được thu thập thông qua CloudWatch. 4. Triển Khai Kỹ Thuật Các Giai Đoạn Triển Khai Dự án này có ba phần chính: xây dựng pipeline dự đoán, thiết lập thu thập dữ liệu và triển khai nền tảng web. Mỗi phần trải qua bốn giai đoạn:\nThiết Kế Kiến Trúc: Lên kế hoạch cho hệ thống serverless AWS, các hàm Lambda, cấu trúc S3. (Tuần 1-2) Ước Tính Chi Phí: Sử dụng AWS Pricing Calculator để đánh giá tính khả thi và điều chỉnh thiết kế (Tuần 1-2). Tối Ưu Hóa Kiến Trúc: Điều chỉnh bộ nhớ Lambda, cách sử dụng S3 và bộ nhớ đệm để giảm chi phí (Tuần 2-4). Phát Triển, Kiểm Thử, Triển Khai: Triển khai các hàm Lambda, lập lịch sự kiện, tích hợp mô hình ML và frontend web với Next.js (Tuần 4-8). Yêu Cầu Kỹ Thuật\nCác Mô Hình ML: Các mô hình quỹ đạo được đào tạo sẵn lưu trữ trong S3 (.h5/.pth), được tải bởi hàm Lambda dự đoán. Dữ Liệu Bão: Các tệp JSON được cập nhật hàng tuần, lưu trữ trong S3, được sử dụng để hiển thị frontend và xác thực dự đoán. Cơ Sở Hạ Tầng Serverless: Lambda cho dự đoán, truy xuất và thu thập; API Gateway cho các yêu cầu frontend; CloudFront/S3 để phân phối nội dung. Bảo Mật: Secrets Manager cho khóa API, IAM cho quyền truy cập tối thiểu. Giám Sát: CloudWatch để ghi log và các số liệu Lambda Insights. 5. Tiến Độ \u0026amp; Các Mốc Quan Trọng Dòng Thời Gian Dự Án\nTrước Kỳ Thực Tập (Tuần 1): Lập kế hoạch, nghiên cứu các API thời tiết bên ngoài và chuẩn bị mô hình ML.\nTrong Kỳ Thực Tập (Tuần 1-8):\nTuần 1-2: Nghiên cứu AWS, thiết kế kiến trúc và ước tính chi phí. Tuần 2-4: Tối ưu hóa kiến trúc, cấu hình quy trình không máy chủ và tích hợp các mô hình ML. Tuần 4-8: Triển khai các hàm Lambda, thiết lập frontend, kiểm thử hệ thống và triển khai lên môi trường production. Sau Khi Ra Mắt: Thu thập dữ liệu liên tục và giám sát trong tối đa 1 năm.\n6. Ước Tính Ngân Sách Khu vực: ap-southeast-1 (Singapore)\nChi phí ước tính hàng tháng để vận hành nền tảng dự đoán bão trên AWS như sau:\nA. Frontend \u0026amp; Phân Phối Nội Dung\nAmazon S3 (Tệp Tĩnh): Lưu trữ 5 GB tệp frontend (HTML, CSS, JS) và xử lý 10 GB chuyển dữ liệu mỗi tháng. Chi phí ≈ $0.54/tháng. Amazon CloudFront: Xử lý 50 GB chuyển dữ liệu và lên đến 1 triệu yêu cầu (trong phạm vi miễn phí). Chi phí ≈ $6.00/tháng. Amazon Route 53: 1 hosted zone và 1 triệu truy vấn DNS mỗi tháng. Chi phí ≈ $0.90/tháng. AWS Certificate Manager (ACM): Cung cấp chứng chỉ TLS cho truy cập HTTPS bảo mật. Miễn phí. Tổng cho Frontend \u0026amp; CDN: ≈ $7.4/tháng\nB. Backend (Xử Lý API \u0026amp; ML)\nAmazon API Gateway: Xử lý 1 triệu yêu cầu HTTP API mỗi tháng, mỗi yêu cầu có kích thước khoảng 1 MB. Chi phí ≈ $2.5/tháng. Lambda (Dự đoán Bão): Dự đoán quỹ đạo bão sử dụng các mô hình ML. Chạy ~1,000 lần mỗi ngày với 512 MB bộ nhớ được cấp phát và 1 GB bộ nhớ tạm thời. Mỗi lần thực thi kéo dài ~5 giây. Chi phí ≈ $2.54/tháng. Lambda (Lấy Dữ Liệu Bão Gần Đây): Lấy dữ liệu bão từ S3 cho frontend. Chạy ~20,000 lần mỗi ngày với 512 MB bộ nhớ và 512 MB bộ nhớ tạm thời trong 1 giây mỗi lần thực thi. Chi phí ≈ $0.00/tháng (nằm trong free tier). Tổng cho Backend: ≈ $4.54/tháng\nC. Tự Động Hóa \u0026amp; Thu Thập Dữ Liệu\nAmazon EventBridge: Lập lịch thu thập dữ liệu bão hàng tuần (1 cron trigger mỗi ngày). Miễn phí theo AWS free tier. Lambda (Trình Thu Thập Web): Lấy dữ liệu từ các API bên ngoài hàng tuần. Sử dụng 128 MB bộ nhớ và 512 MB bộ nhớ tạm thời, ~30 giây mỗi lần thực thi. Chi phí ≈ $0.00/tháng (free tier). AWS Secrets Manager: Lưu trữ 5 khóa API để truy cập an toàn vào các dịch vụ thời tiết bên ngoài. Chi phí ≈ $2.00/tháng. Tổng cho Tự Động Hóa \u0026amp; Thu Thập Dữ Liệu: ≈ $2.0/tháng\nD. Giám Sát \u0026amp; Ghi Log\nAmazon CloudWatch Logs: Thu thập logs từ tất cả các hàm Lambda và chuyển đến S3 với thời gian lưu giữ 1 tháng. Khoảng 2 GB logs mỗi tháng. Chi phí ≈ $0.57/tháng. CloudWatch Metrics (Lambda Insights): Giám sát 8 metrics trên các hàm Lambda. 10 metrics đầu tiên miễn phí, và chỉ ghi lại cho dự đoán và dữ liệu thu thập. Chi phí ≈ $0.00/tháng. Tổng cho Giám Sát \u0026amp; Ghi Log: ≈ $0.57/tháng\nE. Lưu Trữ \u0026amp; Truyền Dữ Liệu\nS3 (Bucket Mô Hình): Lưu trữ các mô hình ML (~1 GB) và xử lý ~60,000 yêu cầu GET mỗi tháng. Chi phí ≈ $0.05/tháng. S3 (Bucket Dữ Liệu Bão Gần Đây): Lưu trữ dữ liệu bão gần đây (~1 GB) với ~60,000 yêu cầu GET và 30 yêu cầu PUT mỗi tháng. Chi phí ≈ $0.27/tháng. Tổng cho Lưu Trữ \u0026amp; Truyền Dữ Liệu: ≈ $0.32/tháng\nF. Di chuyển lên AWS\nDùng AWS CodePipeline và CodeBuild cho 10 phút chỉnh sửa mỗi tháng ≈ $0.90/month. Tổng Chi Phí Hàng Tháng Ước Tính\nFrontend \u0026amp; CDN: $7.4 Backend (API + ML): $4.54 Tự động hóa (Crawler + Secrets): $2.0 Giám sát \u0026amp; Ghi log: $0.57 Lưu trữ \u0026amp; Truyền dữ liệu: $0.32 Phí di chuyển kỹ thuật : $0.90 TỔNG CỘNG ≈ $15.73/tháng\n7. Đánh Giá Rủi Ro Các Rủi Ro Chính\nSự cố Mạng: Mức độ ảnh hưởng trung bình, khả năng xảy ra trung bình. Nguồn Dữ liệu Không Khả Dụng: Mức độ ảnh hưởng trung bình, khả năng xảy ra thấp. Lỗi Mô Hình ML: Mức độ ảnh hưởng cao, khả năng xảy ra thấp. Vượt Quá Chi Phí: Mức độ ảnh hưởng trung bình, khả năng xảy ra thấp. Chiến Lược Giảm Thiểu\nMạng: Lưu vào bộ nhớ đệm (cache) dữ liệu bão gần đây trong S3 để cho phép hiển thị frontend trong thời gian xảy ra sự cố. Nguồn Dữ liệu: Lưu trữ dữ liệu bão lịch sử để dự phòng. Mô Hình ML: Xác thực và kiểm tra mô hình thường xuyên. Chi Phí: Giám sát mức sử dụng AWS và thiết lập cảnh báo ngân sách. Kế Hoạch Dự Phòng\nChuyển sang cập nhật thủ công nếu API bên ngoài thất bại. Khôi phục (rollback) về mô hình ML trước đó bằng cách sử dụng tính năng versioning của S3 nếu mô hình mới thất bại. 8. Kết Quả Kỳ Vọng Cải Tiến Kỹ Thuật:\nDự đoán quỹ đạo bão thời gian thực với các đường đi được hiển thị hóa. Hệ thống không máy chủ có khả năng mở rộng, xử lý hàng nghìn yêu cầu/ngày. Giá Trị Lâu Dài:\nDữ liệu bão tập trung cho nghiên cứu và phân tích. Khung (framework) có thể tái sử dụng cho các tác vụ dự đoán không gian địa lý khác. Chi phí vận hành hàng tháng thấp (\u0026lt; $20/tháng). "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.2-data-preparation/","title":"Chuẩn Bị Dữ Liệu","tags":[],"description":"","content":"Thu Thập và Xử Lý Dữ Liệu Dữ liệu là một thành phần quan trọng trong dự án. Nó không chỉ cung cấp nguồn kiến thức cho mô hình machine learning mà còn được hiển thị trực tiếp cho người dùng cuối để theo dõi các cơn bão mới nhất tại khu vực Tây Thái Bình Dương. Vì dữ liệu có mục đích kép — huấn luyện mô hình và trực quan hóa theo thời gian thực — chúng em đã xem xét kỹ lưỡng nhiều nguồn data source đáng tin cậy và có thẩm quyền trước khi chọn một bộ dữ liệu đáp ứng đầy đủ các yêu cầu, đó là: Dữ liệu bão của NOAA.\nNOAA (National Oceanic and Atmospheric Administration) là cơ quan khoa học thuộc Bộ Thương mại Hoa Kỳ. NOAA cung cấp dữ liệu môi trường có độ chính xác cao phục vụ nghiên cứu, bao gồm quan sát thời tiết toàn cầu, ảnh vệ tinh và thông tin về các xoáy thuận nhiệt đới. Với nhiều thập kỷ đầu tư vào công nghệ tiên tiến như vệ tinh địa tĩnh, hệ thống radar và mạng lưới giám sát khí hậu, NOAA được xem là một trong những nguồn cung cấp dữ liệu bão đáng tin cậy nhất trên thế giới.\nTrong dự án này, chúng em sử dụng dữ liệu từ International Best Track Archive for Climate Stewardship (IBTrACS) — một dự án do NOAA khởi xướng và là bộ dữ liệu xoáy thuận nhiệt đới toàn diện nhất thế giới. IBTrACS tổng hợp dữ liệu đường đi của bão trong lịch sử từ nhiều cơ quan khí tượng (ví dụ: JTWC, JMA, CMA, NHC). Bằng cách hợp nhất các nguồn vào một định dạng thống nhất, IBTrACS cải thiện khả năng so sánh giữa các cơ quan và đảm bảo các nhà nghiên cứu trên toàn thế giới có quyền truy cập dữ liệu chất lượng cao nhất.\nPhiên bản mới nhất của bộ dữ liệu này chứa 226.153 dòng ghi nhận quan sát bão. Mỗi dòng bao gồm nhiều thuộc tính giá trị như:\nsid – mã cơn bão number – số thứ tự bão basin / subbasin – phân loại khu vực nature – loại bão (ví dụ: áp thấp, bão nhiệt đới, siêu bão) iso_time – thời gian lat / lon – tọa độ tâm bão … và nhiều thông số khí tượng học khác Tuy nhiên, đối với mô hình machine learning, chúng em chỉ tập trung vào bốn cột chính: sid, iso_time, lat, và lon. Đây là chuỗi thời gian cơ bản dùng để dự đoán quỹ đạo di chuyển của bão.\nBộ dữ liệu bao gồm các cơn bão từ 1870 đến 2025, được lọc chỉ giữ lại các cơn bão trong khu vực Tây Thái Bình Dương — phạm vi địa lý mà dự án hướng đến. Bộ dữ liệu gốc được công khai tại: https://data.humdata.org/dataset/vnm-ibtracs-tropical-storm-tracks#\nLàm sạch dữ liệu và Trích xuất đặc trưng dựa trên quy luật vật lý Một ưu điểm của IBTrACS là dữ liệu đã được bảo trì tốt và có tính nhất quán cao. Việc tiền xử lý chỉ yêu cầu các bước tối thiểu, chủ yếu là loại bỏ giá trị thiếu.\nSau khi làm sạch, chúng em áp dụng bước đầu tiên của machine learning dựa trên vật lý (physics-informed ML) — kỹ thuật đưa kiến thức vật lý trực tiếp vào pipeline dữ liệu. Từ tọa độ vĩ độ – kinh độ, nhóm tính thêm hai đặc trưng bằng công thức Haversine:\nKhoảng cách giữa hai điểm bão liên tiếp Góc phương vị (bearing) — hướng di chuyển Các đặc trưng này mang ý nghĩa vật lý: chúng phản ánh quy luật chuyển động thực tế, thay vì những biến đổi tùy ý. Nhờ đó, chúng tăng cường bối cảnh về quán tính và hướng di chuyển của bão, giúp mô hình học hiệu quả hơn và dự đoán chính xác hơn.\nHình 1 : Mô tả dữ liệu Dữ Liệu Hiển Thị Trên Nền Tảng Dữ liệu dùng để hiển thị trên nền tảng khác với dữ liệu dùng để huấn luyện, dù cả hai đều xuất phát từ NOAA. Dữ liệu huấn luyện là tĩnh, còn dữ liệu hiển thị phải cập nhật theo tình hình bão hiện tại.\nĐể xử lý yêu cầu này, nhóm đã triển khai một AWS Lambda chạy theo lịch, tự động lấy dữ liệu đường đi bão mới nhất vào cuối mỗi ngày. Điều này đảm bảo nền tảng luôn hiển thị thông tin mới, chính xác và kịp thời cho người dùng.\nDữ liệu hiển thị sau xử lý được lưu dưới dạng file JSON trong S3. Khi người dùng truy cập website:\nFrontend gửi yêu cầu tới API Gateway API Gateway kích hoạt Lambda tương ứng Lambda lấy file JSON từ S3 Dữ liệu được trả về cho người dùng để hiển thị trực quan Pipeline này đảm bảo khả năng cập nhật thời gian thực, serverless và tiết kiệm chi phí.\nBộ dữ liệu bão có thể truy cập tại: https://ncics.org/ibtracs/\nHình 2 : Web để crawl dữ liệu "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Mở rộng quy mô sản xuất hình ảnh bằng Stability AI Image Services trong Amazon Bedrock Blog này giới thiệu cách sử dụng Stability AI Image Services ngay trong Amazon Bedrock để thực hiện các tác vụ chỉnh sửa hình ảnh chuyên nghiệp ở quy mô lớn. Bài viết trình bày 13 công cụ thuộc ba nhóm: Edit, Upscale, và Control, giúp xoá vật thể, thay đổi màu sắc, áp dụng phong cách, mở rộng ảnh, chuyển phác thảo thành ảnh thật và nâng cấp độ phân giải. Ngoài ra, blog hướng dẫn đầy đủ cách thiết lập môi trường bằng SageMaker AI, cấu hình IAM role, chạy notebook mẫu và dọn dẹp tài nguyên. Đây là giải pháp hỗ trợ đội ngũ sáng tạo và marketing tạo nội dung trực quan chất lượng cao nhanh hơn, tiết kiệm chi phí và mở ra nhiều khả năng sáng tạo mới.\nBlog 2 - DeepSeek-V3.1 Model Đã Có Mặt Trong Amazon Bedrock Blog này công bố rằng DeepSeek-V3.1 hiện đã có mặt dưới dạng mô hình nền tảng được quản lý hoàn toàn trong Amazon Bedrock. DeepSeek-V3.1 sử dụng cơ chế kết hợp giữa chế độ “thinking” và “non-thinking”, mang lại khả năng suy luận đa bước mạnh hơn, tốc độ phản hồi nhanh hơn và hiệu quả sử dụng công cụ vượt trội so với DeepSeek-R1. Bài viết nêu bật các cải thiện lớn trên nhiều bộ đánh giá, hỗ trợ hơn 100 ngôn ngữ và các trường hợp sử dụng chính như sinh mã, agentic AI và ứng dụng doanh nghiệp. Blog cũng hướng dẫn cách thử nghiệm mô hình trong Bedrock console, bật/tắt reasoning mode, chạy ví dụ và gọi mô hình qua AWS CLI hoặc SDK. Mô hình hiện khả dụng ở nhiều vùng AWS và sẽ tự động được bật cho tất cả tài khoản AWS từ tháng 10/2025.\nBlog 3 - Các mô hình Qwen hiện đã có mặt trên Amazon Bedrock Blog này thông báo việc bổ sung các mô hình Qwen3 của Alibaba vào Amazon Bedrock, mở rộng thêm lựa chọn mô hình nền tảng dạng open-weight được quản lý hoàn toàn. Đợt phát hành bao gồm bốn mô hình—hai mô hình MoE tối ưu cho lập trình, một mô hình MoE đa dụng, và một mô hình dense—tương ứng với từng nhu cầu hiệu năng và chi phí khác nhau. Bài viết nêu bật nhiều khả năng quan trọng như suy luận đa bước, gọi công cụ (tool calling), chế độ tư duy kết hợp (thinking/non-thinking) và xử lý ngữ cảnh dài đến 1M token. Blog cũng hướng dẫn thời điểm nên sử dụng từng mô hình, cách thử nghiệm trong Bedrock console, và cách tích hợp vào ứng dụng thông qua AWS SDK hoặc các agent framework như AgentCore. Các mô hình Qwen3 hiện khả dụng tại nhiều vùng AWS và sẽ được tự động bật cho mọi tài khoản AWS từ tháng 10/2025.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Thành thạo việc triển khai và quản lý máy chủ EC2 Triển khai ứng dụng trên Amazon Linux 2 Triển khai quản trị chi phí với chính sách IAM Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Bắt đầu tìm hiểu về Amazon EC2 - Chuẩn bị cho Triển khai EC2 * Tạo VPC cho Linux * Tạo VPC cho Instance Windows * Tạo Security Group cho Instance Linux * Tạo Security Group cho Instance Windows 22/09/2025 22/09/2025 https://000004.awsstudygroup.com/ 3 - Khởi chạy và Kết nối vào Máy chủ EC2 * Khởi chạy Instance Microsoft Windows Server 2022 * Kết nối từ Máy tính vào Instance Microsoft Windows Server 2022 * Khởi chạy Instance Amazon Linux * Kết nối vào Instance Amazon Linux 23/09/2025 24/09/2025 https://000004.awsstudygroup.com/ 4 - Thực hành Các Kiến thức Cơ bản về Amazon EC2: + Thay đổi Loại Instance EC2 + Tạo và Quản lý EBS Snapshots + Tạo AMI Tùy chỉnh + Khởi chạy Instance từ AMI Tùy chỉnh + Khôi phục Quyền Truy cập vào Instance Windows/Linux + Remote Desktop vào EC2-Ubuntu 24/09/2025 25/09/2025 https://000004.awsstudygroup.com/ 5 - Triển khai Ứng dụng Quản lý Người dùng: + Cài đặt Máy chủ Web LAMP trên Amazon Linux 2 + Cài đặt Node.js trên Amazon Linux 2 + Triển khai ứng dụng trên Instance Linux 25/09/2025 25/09/2025 https://000004.awsstudygroup.com/ 6 - Quản trị Chi phí \u0026amp; Sử dụng với IAM: + Hạn chế Sử dụng Dịch vụ theo Khu vực AWS + Giới hạn Sử dụng EC2 theo Họ Instance + Kiểm soát Triển khai EC2 theo Loại Instance + Quản lý Loại Lưu trữ EBS Volume + Giới hạn quyền xóa tài nguyên theo địa chỉ IP của Công ty + Giới hạn quyền xóa tài nguyên theo khoảng thời gian 26/09/2025 28/09/2025 https://000004.awsstudygroup.com/ Kết quả đạt được tuần 3: Thành thạo các kiến thức cơ bản về Amazon EC2 bao gồm:\nCác loại instance và thay đổi loại instance Tạo và quản lý EBS snapshots Tạo và triển khai AMI tùy chỉnh Khôi phục quyền truy cập cho instance Windows và Linux Kết nối remote desktop vào các instance EC2 Triển khai thành công Ứng dụng Quản lý Người dùng trên Amazon Linux 2:\nCài đặt và cấu hình máy chủ web LAMP Thiết lập và kiểm tra máy chủ cơ sở dữ liệu Cài đặt môi trường thực thi Node.js Triển khai và quản lý ứng dụng trên instance Linux Triển khai Quản trị Chi phí \u0026amp; Sử dụng với IAM:\nHạn chế sử dụng dịch vụ theo khu vực AWS Giới hạn sử dụng EC2 theo họ instance và loại instance Quản lý loại lưu trữ EBS volume Cấu hình quyền xóa tài nguyên theo địa chỉ IP và khoảng thời gian Có được kinh nghiệm thực tế với mạng AWS:\nTạo và cấu hình VPC cho instance Linux và Windows Thiết lập security group cho các loại instance khác nhau Khởi chạy và kết nối vào cả instance Windows Server 2022 và Amazon Linux Phát triển kỹ năng quản lý EC2 toàn diện:\nTriển khai và cấu hình instance Phương thức kết nối và truy cập từ xa Giám sát và tối ưu hóa tài nguyên Chiến lược sao lưu và khôi phục "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.3-ml-model/","title":"Mô Hình Học Máy","tags":[],"description":"","content":"HUẤN LUYỆN MÔ HÌNH Mục sau đây trình bày về quá trình phát triển mô hình dự đoán được thiết kế để dự đoán vị trí địa lý tiếp theo của một cơn bão, dựa trên dữ liệu quan sát từ quỹ đạo di chuyển trước đó. Nói cách đơn giản, nhóm sử dụng chuỗi các giá trị vĩ độ và kinh độ trong quá khứ để dự đoán vĩ độ và kinh độ tại bước thời gian kế tiếp.\nTrích Xuất Đặc Trưng Sau khi hoàn tất bước tiền xử lý dữ liệu, nhóm tiến hành chia bộ dữ liệu thành 70% để huấn luyện, 10% để kiểm định, và 20% để kiểm tra. Việc chia này được thực hiện theo mã định danh cơn bão (storm ID), đảm bảo không có cơn bão nào xuất hiện đồng thời trong cả tập huấn luyện và tập kiểm định/kiểm tra. Điều này giúp ngăn rò rỉ dữ liệu và đảm bảo độ tin cậy của quá trình đánh giá.\nTrong quá trình huấn luyện mô hình, mỗi mẫu đầu vào bao gồm chuỗi 4 bước thời gian liên tiếp, trong đó mỗi bước cách nhau 3 giờ. Như vậy, một chuỗi đầu vào tương ứng với quãng di chuyển 9 giờ của cơn bão.\nFigure 1 : Dataset Distribution Áp dụng Kỹ thuật Stepwise Temporal Fading Augmentation (STFA) Để tăng độ đa dạng của dữ liệu huấn luyện, nhóm áp dụng phương pháp tự đề xuất — Stepwise Temporal Fading Augmentation (STFA) — lên 50% tập huấn luyện, được lựa chọn dựa trên từng storm ID riêng biệt. Các chuỗi gốc của những cơn bão này sẽ được thay thế bằng chuỗi đã được tăng cường, đảm bảo kích thước tập huấn luyện cuối cùng vẫn giữ nguyên (xấp xỉ 100% kích thước ban đầu).\nNhư đã đề cập trong phần đề xuất mô hình, STFA thay đổi các điểm cũ hơn trong chuỗi, trong khi giữ các quan sát mới nhất không đổi. Với mỗi chuỗi 4 bước:\n2 bước mới nhất được giữ nguyên 2 bước cũ hơn được nhân với hệ số giảm dần: [0.98, 0.99] Mặc dù những giá trị này có vẻ nhỏ, nhưng vĩ độ và kinh độ cực kỳ nhạy cảm. Một thay đổi nhỏ — ví dụ từ 6.7 lên 6.8 — có thể tương ứng với hàng chục kilomet dịch chuyển ngoài thực tế. Do đó, mức điều chỉnh nhỏ như vậy là hợp lý và phù hợp với quy luật vật lý, giúp dữ liệu tăng cường vẫn mang tính chân thực.\nVí dụ STFA trên một chuỗi 4 bước thời gian Row Original (lat, lon) Augmented (lat, lon) Operation 1 [-6.8, 107.5] [-6.66, 105.35] nhân với 0.98 2 [-7.0, 107.1] [-6.93, 106.03] nhân với 0.99 3 [-7.3, 106.7] [-7.3, 106.7] giữ nguyên 4 [-7.5, 106.4] [-7.5, 106.4] giữ nguyên Quy trình trên làm giảm giá trị của các quan sát cũ, đồng thời giữ nguyên các bước mới. Việc tăng cường này giúp mô hình có thêm biến thiên có kiểm soát, cải thiện khả năng tổng quát hóa trong dự báo quỹ đạo.\nTrước đó, nhóm đã sử dụng machine learning dựa trên quy luật vật lý để tính khoảng cách và góc phương vị bằng công thức Haversine. Sau khi STFA được áp dụng, các giá trị này sẽ được tính lại dựa trên tọa độ đã tăng cường để đảm bảo các đặc trưng vật lý vẫn chính xác và nhất quán.\nFigure 2 : Comparison of Augmentation Techniques on Storm Trajectories Thiết lập Mô hình 1. Hàm Loss dựa trên quy luật vật lý Việc ứng dụng công thức Haversine không chỉ dừng lại ở bước trích xuất đặc trưng. Ngoài việc tạo ra các giá trị khoảng cách và hướng, nhóm còn tích hợp Công thức Haversine như một hàm loss tùy chỉnh, sử dụng cùng với các hàm loss truyền thống như MSE, RMSE và MAPE.\nCông thức Haversine đo khoảng cách địa lý thực giữa hai điểm, nên đây là metric tự nhiên để đánh giá sai số dự đoán vị trí bão. Khoảng cách Haversine càng lớn nghĩa là dự đoán càng sai; ngược lại, giá trị gần 0 km cho thấy mô hình hoạt động tốt.\nVí dụ:\nDự đoán: [-6.72, 107.1] Giá trị thật: [-6.8, 107.5] Haversine loss: 45.06 km Giá trị 45.06 km phản ánh chính xác sai số vị trí ngoài thực tế, giúp việc giải thích mô hình dễ dàng và ý nghĩa hơn.\n2. Kiến trúc mô hình Các bài toán mô hình hóa chuỗi thường được xử lý bằng RNN, LSTM hoặc GRU, nhưng các nghiên cứu gần đây cho thấy mô hình dựa trên tích chập (CNN) có thể vượt trội hơn trong nhiều tác vụ time-series.\nDo đó, nhóm sử dụng kiến trúc CNN — cụ thể là Temporal Convolutional Network (TCN).\nTCN sử dụng tích chập giãn (dilated convolution), giúp mô hình có receptive field rộng mà không cần dùng mạng hồi quy.\nTCN kết hợp được cả:\nkhả năng học phụ thuộc dài hạn tốc độ huấn luyện nhanh gradient ổn định Nên rất phù hợp cho bài toán dự báo quỹ đạo bão.\n3. Các siêu tham số mô hình Input: 4 đặc trưng (lat, lon, distance, bearing) Hidden units: 1024 Số lớp TCN: 2 Learning rate: 1e-4 Epochs: 80 Optimizer: Adam Early stopping: patience = 6 4. Hàm Loss tổng hợp Loss chính của mô hình được kết hợp từ:\nMSE của lat/lon MSE của distance/bearing Haversine loss (dựa trên vật lý) Trong đó:\nλ_aux = 0.5 λ_hav = 0.3 Cách thiết kế này giúp mô hình:\ngiảm sai số tọa độ tôn trọng quy luật dịch chuyển vật lý tránh overfit vào một loại đặc trưng cụ thể Figure 3 : Training Process Evaluation Đánh giá mô hình Sau khi mô hình hoàn tất quá trình huấn luyện và dừng sớm (early stopping), nhóm tiến hành đánh giá trên tập kiểm tra để xác định khả năng tổng quát hóa và mức độ sẵn sàng triển khai thực tế.\nKết quả đánh giá:\nTotal Loss: 74.3849 MSE: 0.0832 RMSE: 0.2772 MAPE: 0.60% Haversine: 30.75 km Sai số vị trí trung bình khoảng 30 km — mức hoàn toàn chấp nhận được đối với hệ thống có quy mô hàng trăm đến hàng nghìn kilomet như bão nhiệt đới. MSE nhỏ (0.08) cho thấy khả năng dự đoán tốt và ổn định.\nKết quả này cũng chứng minh rằng các mô hình convolution có thể hoạt động xuất sắc trong bài toán mô hình hóa chuỗi, không chỉ trong xử lý ảnh.\nSau khi xác thực mô hình, bước tiếp theo là tải mô hình lên Amazon S3 và sử dụng AWS Lambda để thực thi mô hình khi người dùng gửi yêu cầu dự đoán.\nFigure 4 : Evaluation Metrics "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Thành thạo sử dụng vai trò IAM để ủy quyền cho ứng dụng Học về môi trường phát triển AWS Cloud9 Triển khai website tĩnh trên S3 với CloudFront Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Học cách cấp quyền ủy quyền cho ứng dụng truy cập dịch vụ AWS với vai trò IAM - Chuẩn bị + Tạo instance EC2 + Tạo bucket S3 - Tạo người dùng IAM với access keys để ứng dụng Python upload lên S3 - Tạo vai trò IAM với quyền cho ứng dụng upload files lên bucket S3 09/29/2025 09/29/2025 https://000048.awsstudygroup.com/ 3 - Tạo Instance Cloud9 - Học các tính năng cơ bản của Cloud9: + Sử dụng command line + Làm việc với text files + Quay lại giao diện Dashboard - Sử dụng AWS CLI trong Cloud9 09/30/2025 09/30/2025 https://000049.awsstudygroup.com/ 4 - Tìm hiểu thông tin về Amazon S3 + Hiểu sự khác biệt giữa S3 Buckets và Object + Tính năng chính (storage classes, security and compliance, management and analytics, performance and availability) + Các trường hợp sử dụng phổ biến - Tạo bucket S3 và upload dữ liệu để chuẩn bị host website tĩnh - Cấu hình website tĩnh: + Bật tính năng website tĩnh + Cấu hình public access block + Cấu hình public objects + Kiểm tra website - Tăng tốc với CloudFront: + Block all public access + Cấu hình Amazon CloudFront + Kiểm tra Amazon CloudFront - Tính năng S3 nâng cao: + Cấu hình bucket versioning + Di chuyển objects giữa các buckets + Thiết lập cross-region replication 10/01/2025 10/04/2025 https://000057.awsstudygroup.com/ 5 - Tham gia sự kiện [AWS GenAI Builder Club] AI-Driven Development Life Cycle: Reimagining Software Engineering 10/03/2025 10/03/2025 Kết quả đạt được tuần 4: Thành thạo cấu hình vai trò IAM để ủy quyền cho ứng dụng:\nTạo người dùng IAM với access keys để upload lên S3 Cấu hình vai trò IAM với quyền truy cập S3 Thiết lập instance EC2 và bucket S3 để kiểm tra ứng dụng Thành thạo sử dụng môi trường phát triển AWS Cloud9:\nTạo và quản lý instance Cloud9 Sử dụng command line interface và tính năng chỉnh sửa text Thực thi các lệnh AWS CLI trong Cloud9 Triển khai thành công hosting website tĩnh trên S3:\nCấu hình bucket S3 để host website tĩnh Quản lý public access blocks và quyền truy cập objects Kiểm tra chức năng và hiệu suất website Triển khai CloudFront để tăng tốc phân phối nội dung:\nCấu hình CloudFront distributions cho website S3 Triển khai các biện pháp bảo mật bằng cách block public access Kiểm tra hiệu suất và caching của CloudFront Áp dụng các tính năng S3 nâng cao:\nBật bucket versioning để bảo vệ dữ liệu Quản lý di chuyển objects giữa các buckets Thiết lập cross-region replication cho disaster recovery "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia 2 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AWS Cloud Mastery Series #1\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.4-frontback-end/5.4.1-frontend-architecture/","title":"Kiến Trúc Frontend","tags":[],"description":"","content":"Kiến trúc Frontend – Ứng dụng Web Dự báo Bão Tổng quan Dưới đây là tài liệu chi tiết về quá trình phát triển front-end của nhóm: Một ứng dụng web xây dựng bằng React và TypeScript dùng để theo dõi và dự đoán quỹ đạo bão\nKiến trúc dịch vụ AWS ┌─────────────────────────────────────────────────────────────┐ │ TRÌNH DUYỆT NGƯỜI DÙNG │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ CloudFront CDN │ │ - Distribution: d3lj47ilp0fgxy.cloudfront.net │ │ - SSL/TLS: HTTPS │ │ - Cache: Tài nguyên tĩnh + dữ liệu JSON │ │ - Truy cập Origin: OAI/OAC (bảo mật) │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ S3 Bucket (Riêng tư) │ │ - Bucket: storm-frontend-hosting-duc-2025 │ │ - Static Website Hosting: TẮT │ │ - Quyền truy cập: Chỉ CloudFront được phép qua REST API │ │ - Nội dung: HTML, CSS, JS, hình ảnh, recent_storms.json │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ Các hàm Lambda │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ Lambda #1: Dự báo bão │ │ │ │ - URL: vill3povlzqxdyxm7ubldizobu0kdgbi... │ │ │ │ - Phương thức: POST /predict │ │ │ │ - Xác thực: KHÔNG (công khai) │ │ │ │ - Container: ECR (Docker) │ │ │ │ - Mô hình: LSTM + TCN │ │ │ └─────────────────────────────────────────────────────┘ │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ Lambda #2: Thu thập dữ liệu bão (mới) │ │ │ │ - Kích hoạt: EventBridge (hàng tuần) │ │ │ │ - Chức năng: Thu thập dữ liệu IBTrACS │ │ │ │ - Đầu ra: recent_storms.json → S3 │ │ │ └─────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ EventBridge │ │ - Rule: storm-data-crawler-weekly-trigger │ │ - Lịch chạy: Mỗi Chủ nhật 00:00 UTC (07:00 giờ Việt Nam) │ │ - Đích: Lambda #2 (Thu thập dữ liệu bão) │ └─────────────────────────────────────────────────────────────┘ Cấu trúc thư mục Frontend frontend/ ├── src/ │ ├── components/ # Các component React │ │ ├── ui/ # Component từ shadcn/ui (button, card, input, ...) │ │ ├── storm/ # Component chuyên cho nghiệp vụ bão │ │ ├── timeline/ # Điều khiển timeline │ │ ├── wind/ # Trực quan hóa gió │ │ ├── StormPredictionForm.tsx # Form nhập tọa độ bão │ │ ├── WeatherMap.tsx # Bản đồ Leaflet chính │ │ ├── StormTracker.tsx # Danh sách bão │ │ ├── StormInfo.tsx # Thông tin chi tiết bão │ │ ├── StormAnimation.tsx # Marker hoạt ảnh │ │ ├── WeatherOverlay.tsx # Lớp phủ Nhiệt độ/Gió │ │ ├── WeatherLayerControl.tsx # Lớp Satellite/Radar │ │ ├── WeatherLayerControlPanel.tsx # UI bảng điều khiển lớp dữ liệu │ │ ├── WeatherValueTooltip.tsx # Tooltip khi rê chuột │ │ ├── WindyLayer.tsx # Tích hợp Windy.com │ │ ├── ProvinceLayer.tsx # Lớp ranh giới tỉnh/thành Việt Nam │ │ ├── OptimizedTemperatureLayer.tsx │ │ ├── TemperatureHeatMapLayer.tsx │ │ ├── ThemeToggle.tsx # Chế độ Sáng/Tối │ │ ├── PreferencesModal.tsx # Tùy chọn người dùng │ │ ├── RightSidebar.tsx # Panel bên phải │ │ └── WeeklyForecast.tsx # Dự báo 7 ngày │ │ │ ├── pages/ │ │ ├── Index.tsx # Trang chính │ │ └── NotFound.tsx # Trang 404 │ │ │ ├── lib/ # Logic nghiệp vụ \u0026amp; tiện ích │ │ ├── api/ # Client gọi API │ │ ├── __tests__/ # Unit test │ │ ├── stormData.ts # Kiểu dữ liệu \u0026amp; interface │ │ ├── stormAnimations.ts # Logic hoạt ảnh │ │ ├── stormIntensityChanges.ts │ │ ├── stormPerformance.ts │ │ ├── stormValidation.ts │ │ ├── windData.ts │ │ ├── windStrengthCalculations.ts │ │ ├── windyStatePersistence.ts │ │ ├── windyUrlState.ts │ │ ├── mapUtils.ts # Tiện ích hỗ trợ bản đồ │ │ ├── openWeatherMapClient.ts │ │ ├── dataWorker.ts # Web Worker │ │ ├── utils.ts │ │ └── colorInterpolation.ts │ │ │ ├── hooks/ # Custom React hooks │ │ ├── use-toast.ts │ │ ├── use-theme.tsx │ │ ├── use-mobile.tsx │ │ ├── useTimelineState.ts │ │ ├── useWindyStateSync.ts │ │ └── useSimplifiedTooltip.ts │ │ │ ├── contexts/ # React Context │ │ └── WindyStateContext.tsx │ │ │ ├── api/ │ │ └── weatherApi.ts # Các hàm gọi API │ │ │ ├── utils/ │ │ └── colorInterpolation.ts │ │ │ ├── styles/ │ │ └── accessibility.css # Style tuân thủ WCAG │ │ │ ├── test/ # Bộ test │ │ ├── accessibility.test.ts │ │ ├── accessibility-audit.test.ts │ │ ├── wcag-compliance.test.ts │ │ ├── performance.test.ts │ │ ├── cross-browser.test.ts │ │ └── setup.ts │ │ │ ├── assets/ # Ảnh, icon │ ├── App.tsx │ ├── main.tsx │ └── index.css │ ├── public/ # Tài nguyên tĩnh ├── dist/ # Output sau khi build (npm run build) ├── .env.production # Cấu hình môi trường production ├── .env.example ├── package.json ├── vite.config.ts ├── vitest.config.ts # Cấu hình test ├── tailwind.config.ts ├── tsconfig.json └── components.json # Cấu hình shadcn/ui Biến môi trường .env.production # OpenWeather API VITE_OPENWEATHER_API_KEY=8ff7f009d2bd420c86845c6bcf6de4a9 # CloudFront URL - Dùng để lấy dữ liệu bão VITE_CLOUDFRONT_URL=https://d3lj47ilp0fgxy.cloudfront.net # Lambda Function URL - API dự đoán bão VITE_PREDICTION_API_URL=https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws Quy trình Build \u0026amp; Deploy 1. Build bản Production cd frontend npm run build Đầu ra: thư mục dist/ bao gồm:\nindex.html assets/index-[hash].js assets/index-[hash].css 2. Upload lên S3 aws s3 sync dist/ s3://storm-frontend-hosting-duc-2025/ --delete Important Notes:\nS3 bucket ở chế độ riêng tư (không public) CloudFront dùng REST API endpoint, không dùng website endpoint Origin: storm-frontend-hosting-duc-2025.s3.ap-southeast-1.amazonaws.com 3. Invalidate cache của CloudFront aws cloudfront create-invalidation \\ --distribution-id E1234567890ABC \\ --paths \u0026#34;/*\u0026#34; Luồng dữ liệu A. Tải dữ liệu bão (khi khởi động ứng dụng) Trình duyệt → CloudFront → S3 ↓ GET /recent_storms.json ↓ Parse JSON → Hiển thị lên bản đồ File: src/pages/Index.tsx (dòng ~40)\nconst CLOUDFRONT_URL = import.meta.env.VITE_CLOUDFRONT_URL; const FETCH_URL = `${CLOUDFRONT_URL}/recent_storms.json?t=${Date.now()}`; B. Dự báo bão (khi người dùng thao tác) Người dùng điền form → Nhấn \u0026#34;Run Prediction\u0026#34; ↓ POST /predict tới Lambda Function URL ↓ { \u0026#34;history\u0026#34;: [{lat, lng}, ...], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } ↓ Lambda xử lý → Trả về dự báo ↓ Hiển thị đường đi dự đoán lên bản đồ File: src/components/StormPredictionForm.tsx (dòng ~80)\nconst API_URL = `${import.meta.env.VITE_PREDICTION_API_URL}/predict`; const response = await fetch(API_URL, { method: \u0026#34;POST\u0026#34;, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify({ history, storm_name }) }); Các thành phần chính 1. Thành phần cốt lõi StormPredictionForm File: src/components/StormPredictionForm.tsx\nTính năng:\nForm nhập tọa độ bão (tối thiểu 9 điểm) Kiểm tra dữ liệu đầu vào (lat/lng hợp lệ) Gọi Lambda API để dự báo Hiển thị kết quả lên bản đồ Danh sách vị trí có thể cuộn, hỗ trợ thêm/xóa điểm thuộc tính truyền:\ninterface StormPredictionFormProps { onPredictionResult: (result: PredictionResult) =\u0026gt; void; setIsLoading: (isLoading: boolean) =\u0026gt; void; } WeatherMap File: src/components/WeatherMap.tsx\nTính năng:\nHiển thị bản đồ Leaflet Vẽ quỹ đạo bão (lịch sử + dự báo) Vẽ đường dự đoán (màu tím, nét đứt) Lớp phủ thời tiết (nhiệt độ, gió, radar) Hiển thị nhiều cơn bão cùng lúc Tự động zoom tới cơn bão đang được chọn Dùng các pane tùy chỉnh để quản lý thứ tự lớp (z-index) Props:\ninterface WeatherMapProps { storms: Storm[]; selectedStorm?: Storm; customPrediction?: PredictionResult | null; mapFocusBounds?: LatLngBounds | null; onMapFocusComplete?: () =\u0026gt; void; } Mục cần chụp màn hình:\nWeb UI → Bản đồ có quỹ đạo bão (xanh/đỏ) Web UI → Đường dự đoán tùy chỉnh (màu tím, nét đứt) Web UI → Lớp phủ thời tiết (nhiệt độ/gió) Index (Trang chính) File: src/pages/Index.tsx\nTính năng:\nBố cục chính với header/footer Quản lý state (storms, selectedStorm, customPrediction) Sidebar có tab (Current Storms / Predict Storm) Đồng bộ trạng thái timeline Xử lý loading và lỗi Skip link hỗ trợ truy cập (accessibility) 2. Các component về bão StormTracker File: src/components/StormTracker.tsx\nDanh sách các cơn bão hiện tại Lọc theo trạng thái (active/developing/dissipated) Bấm để chọn cơn bão StormInfo File: src/components/StormInfo.tsx\nThông tin chi tiết về bão Tốc độ gió, áp suất, phân loại Dữ liệu lịch sử Timeline dự báo StormAnimation File: src/components/StormAnimation.tsx\nMarker động cho các vị trí của bão Hiệu ứng nhấp nháy/pulsing Màu sắc theo cấp độ bão 3. Các component lớp thời tiết WeatherOverlay File: src/components/WeatherOverlay.tsx\nLớp phủ heatmap nhiệt độ Trực quan hóa tốc độ gió Dữ liệu thời gian thực từ OpenWeather API Rê chuột để xem giá trị WeatherLayerControl File: src/components/WeatherLayerControl.tsx\nLớp ảnh vệ tinh (satellite) Lớp radar Lớp nhiệt độ Quản lý các tile layer WeatherLayerControlPanel File: src/components/WeatherLayerControlPanel.tsx\nĐiều khiển UI cho các lớp thời tiết Thanh chỉnh độ trong suốt (opacity) Nút bật/tắt layer Bật/tắt animation cho nhiệt độ OptimizedTemperatureLayer \u0026amp; TemperatureHeatMapLayer Files: src/components/OptimizedTemperatureLayer.tsx, TemperatureHeatMapLayer.tsx\nRender nhiệt độ tối ưu hiệu năng Nội suy màu (color interpolation) Heatmap dạng lưới (grid-based) 4. Các component về gió WindyLayer File: src/components/WindyLayer.tsx\nTích hợp Windy.com bằng iframe Lớp phủ animation gió Đồng bộ trạng thái với bản đồ chính Context: src/contexts/WindyStateContext.tsx\nState toàn cục cho lớp Windy Lưu trạng thái vào URL Đồng bộ giữa các component 5. Component nâng cấp bản đồ ProvinceLayer File: src/components/ProvinceLayer.tsx\nRanh giới tỉnh/thành Việt Nam Render GeoJSON Nhãn tên tỉnh/thành WeatherValueTooltip File: src/components/WeatherValueTooltip.tsx\nTooltip hiển thị giá trị thời tiết khi rê chuột Nhiệt độ, tốc độ gió, áp suất Tooltip định vị theo vị trí con trỏ 6. Các component UI ThemeToggle File: src/components/ThemeToggle.tsx\nChuyển chế độ Sáng/Tối Lưu lại tùy chọn người dùng Tự nhận theme theo hệ thống PreferencesModal File: src/components/PreferencesModal.tsx\nThiết lập tùy chọn người dùng Tùy chọn bản đồ Tùy chọn hiển thị RightSidebar File: src/components/RightSidebar.tsx\nPanel thông tin bổ sung Sidebar có thể thu gọn WeeklyForecast File: src/components/WeeklyForecast.tsx\nDự báo thời tiết 7 ngày Xu hướng nhiệt độ Icon thời tiết 7. Các component timeline Thư mục: src/components/timeline/\nĐiều khiển timeline cho hoạt ảnh bão Chức năng Play/Pause Kéo để tua thời gian (scrubbing) Điều chỉnh tốc độ Kiểu dữ liệu PredictionResult File: src/lib/stormData.ts\nexport interface PredictionResult { storm_id: string; storm_name: string; prediction_time: string; totalDistance: number; // km actualDistance: number; // km lifespan: number; // giờ forecastHours: number; // giờ forecast: StormPoint[]; // Các điểm vị trí dự đoán path?: StormPoint[]; // Hỗ trợ tương thích (legacy) } StormPoint export interface StormPoint { timestamp: number; // Unix timestamp (ms) lat: number; lng: number; windSpeed: number; // km/h pressure: number; // hPa category: string; // \u0026#34;Typhoon\u0026#34;, \u0026#34;Super Typhoon\u0026#34;, ... } `md\nQuyền IAM/AWS cần thiết S3 Bucket Policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::storm-frontend-hosting-duc-2025/*\u0026#34; } ] } CloudFront Origin Access Origin: S3 bucket Origin Access: Public (hoặc OAI nếu dùng) Kiểm thử Local Development npm run dev # Mở http://localhost:5173 Kiểm thử bản build production npm run build npm run preview # Mở http://localhost:4173 Các lỗi thường gặp 1. Lỗi CORS khi gọi Lambda Đặc điểm: lỗi Access-Control-Allow-Origin\nCách xử lý: Lambda cần trả về header CORS:\nreturn { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } 2. CloudFront bị cache cũ Đặc điểm: Code mới không hiển thị\nCách xử lý: Invalidate cache\naws cloudfront create-invalidation --distribution-id E... --paths \u0026#34;/*\u0026#34; 3. Biến môi trường không được load Triệu chứng: undefined khi truy cập import.meta.env.VITE_*\nCách xử lý:\nĐảm bảo có file .env.production Build lại: npm run build Biến phải bắt đầu bằng VITE_ Checklist triển khai Cập nhật .env.production với đúng URL npm run build chạy thành công Upload dist/ lên S3 Invalidate CloudFront cache Test trên URL production Kiểm tra Lambda API hoạt động Kiểm tra dữ liệu bão tải được Test form dự đoán với 9+ điểm tọa độ API Endpoints 1. Lấy dữ liệu bão GET https://d3lj47ilp0fgxy.cloudfront.net/recent_storms.json Phản hồi: mảng các object Storm\n2. Dự đoán đường đi bão POST https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict Body: { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } Response: { \u0026#34;storm_id\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34;, \u0026#34;totalDistance\u0026#34;: 500.5, \u0026#34;lifespan\u0026#34;: 72, \u0026#34;forecast\u0026#34;: [...] } Tối ưu hiệu năng 1. Tối ưu mã nguồn Code Splitting: Vite tự động tách chunk theo routes Tree Shaking: Loại bỏ code không dùng Minification: Build production tự nén JS/CSS Lazy Loading: Component được tải khi cần 2. Tối ưu dữ liệu Web Workers: Tính toán nặng chạy trong worker (dataWorker.ts) Memoization: Dùng React.memo cho component tốn tài nguyên Debouncing: Debounce cho handler input Caching: Lưu cache tùy chọn bằng LocalStorage 3. Tối ưu render Virtual Scrolling: Danh sách lớn dùng virtual scrolling Optimized Layers: OptimizedTemperatureLayer tối ưu hiệu năng Canvas Rendering: Heatmap render bằng canvas thay vì DOM Pane Management: Tạo Leaflet pane riêng để tối ưu z-index 4. Tối ưu mạng CDN Caching: CloudFront cache tài nguyên tĩnh Image Optimization: WebP, lazy loading API Caching: Cache dữ liệu bão kèm timestamp Compression: Nén Gzip/Brotli 5. Tối ưu cho khả năng truy cập (Accessibility) Skip Links: Phím tắt điều hướng bằng bàn phím ARIA Labels: Dùng nhãn ARIA và HTML ngữ nghĩa đúng Focus Management: Quản lý focus, đảm bảo thứ tự tab hợp lý Screen Reader: Tối ưu để hoạt động tốt với trình đọc màn hình Thư viện \u0026amp; tiện ích Business Logic (lib/) Quản lý bão stormData.ts: Kiểu dữ liệu, interface, định nghĩa Storm/StormPoint stormAnimations.ts: Logic animation cho marker bão stormIntensityChanges.ts: Tính toán thay đổi cường độ bão stormPerformance.ts: Tối ưu hiệu năng render stormValidation.ts: Kiểm tra/validate dữ liệu bão Hệ thống gió windData.ts: Cấu trúc dữ liệu gió windStrengthCalculations.ts: Tính toán cường độ gió windyStatePersistence.ts: Lưu trạng thái lớp Windy windyUrlState.ts: Quản lý trạng thái theo URL cho Windy Bản đồ \u0026amp; thời tiết mapUtils.ts: Tiện ích bản đồ (center, zoom, tính bounds) openWeatherMapClient.ts: Client gọi OpenWeather API colorInterpolation.ts: Tính toán gradient/nội suy màu Hiệu năng dataWorker.ts: Web Worker cho tác vụ tính toán nặng utils.ts: Tiện ích dùng chung Custom Hooks (hooks/) use-toast.ts: Hệ thống thông báo toast use-theme.tsx: Quản lý theme sáng/tối use-mobile.tsx: Nhận diện thiết bị mobile useTimelineState.ts: Đồng bộ trạng thái timeline useWindyStateSync.ts: Đồng bộ trạng thái lớp Windy useSimplifiedTooltip.ts: Logic tooltip rút gọn Context (contexts/) WindyStateContext.tsx: State toàn cục cho tích hợp lớp Windy Testing (test/) accessibility.test.ts: Kiểm thử accessibility accessibility-audit.test.ts: Audit theo WCAG wcag-compliance.test.ts: Kiểm thử tuân thủ WCAG 2.1 performance.test.ts: Benchmark hiệu năng cross-browser.test.ts: Kiểm thử tương thích đa trình duyệt setup.ts: Thiết lập môi trường test Dependencies Core React 18 TypeScript Vite (công cụ build) Vitest (framework test) UI Framework Tailwind CSS shadcn/ui (thư viện component) Lucide Icons Radix UI (primitives) Map \u0026amp; Visualization Leaflet React-Leaflet Hỗ trợ GeoJSON API \u0026amp; Data Fetch API (native) OpenWeather API AWS Lambda Function URL Quản lý state React Context API State theo URL (query params) Lưu trạng thái bằng LocalStorage Hiệu năng Web Workers Code splitting (Vite) Lazy loading Ảnh chụp tài liệu CloudFront Phân phối (Distribution) Hình 1 Cài đặt Origin (Origin Settings) Hình 1 Invalidations Hình 2 storm-frontend-hosting-duc-2025 Hình 3 Phân quyền (Permissions) Hình 4 storm-ai-models-2025 Hình 5 storm-data-store-2025 Hình 6 Trang chính (Main Page) Hình 7 Tính năng theo dõi bão (Storm Tracking Features) Hình 8 Chi tiết cơn bão (Storm Details) Hình 9 Tính năng dự đoán (Predict Feature) Hình 10 Hình 11 Hình 12 "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/","title":"Kiến trúc Lambda","tags":[],"description":"","content":"Kiến trúc Lambda - Dịch vụ AI Dự báo Bão Tổng quan Hàm Lambda là một thành phần quan trọng trong kiến trúc serverless. Chúng đặc biệt hữu ích nhờ chi phí vận hành thấp và khả năng triển khai dễ dàng—những yếu tố rất phù hợp với nền tảng dự đoán bão của nhóm.\nPhần này trình bày chi tiết cách chúng tôi thiết kế và xây dựng kiến trúc Lambda.\nCác hàm Lambda của chúng em chạy mô hình PyTorch để dự đoán quỹ đạo bão và được triển khai thông qua Docker container image.\nKiến trúc các dịch vụ AWS ┌─────────────────────────────────────────────────────────────┐ │ Frontend (Trình duyệt) │ └────────────────────────┬────────────────────────────────────┘ │ POST /predict ▼ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Function URL (Công khai) │ │ URL: https://vill3povlzqxdyxm7ubldizobu0kdgbi... │ │ Auth: NONE (không xác thực) │ │ Method: POST │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Function │ │ Tên: storm-prediction │ │ Runtime: Python 3.10 (Container) │ │ Bộ nhớ: 3008 MB │ │ Timeout: 120 giây │ │ Kiến trúc: x86_64 │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ ECR Repository │ │ Account: 339570693867 │ │ Region: ap-southeast-1 │ │ Repo: storm-prediction │ │ Image: latest │ │ Size: ~2 GB │ └────────────────────────┬────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ S3 Buckets │ │ 1. storm-frontend-hosting-duc-2025 │ │ - models/lstm_totald_256_4.pt (tùy chọn) │ │ - predictions/[storm_id]_[timestamp].json │ │ │ │ 2. storm-ai-models (khuyến nghị) │ │ - models/lstm_totald_256_4.pt │ │ - models/tcn_model.pth (backup) │ └─────────────────────────────────────────────────────────────┘ Cấu trúc thư mục storm_prediction/ storm_prediction/ ├── app.py # Lambda handler (mã chính) ├── Dockerfile # Định nghĩa container ├── requirements.txt # Thư viện Python phụ thuộc ├── cropping_storm_7304_2l.pth # Mô hình TCN (đóng kèm trong image) │ ├── DEPLOY_NOW.md # Hướng dẫn deploy nhanh ├── DEPLOY_CONSOLE_STEP_BY_STEP.md # Hướng dẫn AWS Console từng bước ├── LAMBDA_DEPLOYMENT_GUIDE.md # Hướng dẫn triển khai chi tiết ├── AWS_CONSOLE_DEPLOYMENT_GUIDE.md ├── FIX_ECR_PUSH_ERROR.md # Tài liệu xử lý lỗi ECR ├── FIX_UNICODE_ERROR.md # Sửa lỗi UnicodeDecodeError ├── FIX_UNICODE_ERROR_SOLUTION.md # Chi tiết giải pháp └── REBUILD_AND_DEPLOY.sh # Script tự động build \u0026amp; deploy Cấu trúc Docker Image Dockerfile FROM public.ecr.aws/lambda/python:3.10 # Cài đặt dependencies COPY requirements.txt . RUN pip3 install -r requirements.txt \\ --target \u0026#34;${LAMBDA_TASK_ROOT}\u0026#34; \\ --extra-index-url https://download.pytorch.org/whl/cpu # Copy Lambda handler COPY app.py ${LAMBDA_TASK_ROOT} # Copy mô hình TCN vào thư mục con (tránh nhầm file .pth) RUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ # Đặt handler CMD [ \u0026#34;app.handler\u0026#34; ] Các lớp (Image Layers) Layer 1: AWS Lambda Python 3.10 base (~500 MB) Layer 2: PyTorch CPU + dependencies (~1.2 GB) Layer 3: app.py + mô hình TCN (~300 MB) ───────────────────────────────────────────── Tổng dung lượng: ~2 GB Các mô hình AI 1. Mô hình TCN (Dự đoán quỹ đạo) File: cropping_storm_7304_2l.pth\nVị trí: Bên trong Docker image tại /var/task/models/\nDung lượng: ~300 MB\nMục đích: Dự đoán bước tiếp theo (lat, lng) của quỹ đạo bão\nKiến trúc:\nclass StormTCN(nn.Module): def __init__(self, input_dim=4, hidden_units=1024, num_layers=2): self.tcn = TCN(...) self.head_latlon = nn.Linear(hidden_units, 2) # Dự đoán lat, lng self.head_aux = nn.Linear(hidden_units, 2) # Dự đoán đặc trưng phụ Input: [batch, sequence, 4] - (lat, lng, distance, bearing)\nOutput:\npred_latlon: (lat, lng) kế tiếp pred_aux: đặc trưng phụ 2. Mô hình LSTM (Dự đoán tổng quãng đường) File: lstm_totald_256_4.pt\nVị trí: S3 bucket (tải về ở lần chạy đầu tiên)\nDung lượng: ~50 MB\nMục đích: Dự đoán tổng quãng đường bão sẽ di chuyển\nKiến trúc:\nclass StormLSTM(nn.Module): def __init__(self, input_size=4, hidden_size=256, num_layers=2): self.lstm = nn.LSTM(...) self.fc = nn.Sequential( nn.Linear(hidden_size, hidden_size // 2), nn.ReLU(), nn.Linear(hidden_size // 2, 1) # Dự đoán tổng quãng đường ) Input: Tổng hợp theo ngày [batch, days, 4] - (day, daily_dist, avg_speed, motion_type)\nOutput: Tổng quãng đường (km)\nLuồng xử lý request 1. Nhận request POST /predict Content-Type: application/json { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... // Tối thiểu 9 điểm ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34;, \u0026#34;storm_id\u0026#34;: \u0026#34;TEST001\u0026#34; // Tùy chọn } 2. Tải mô hình (chỉ lần gọi đầu tiên) def load_models(): global LSTM_MODEL, TCN_MODEL # Tải LSTM từ S3 (nếu có) if not os.path.exists(\u0026#39;/tmp/lstm_model.pt\u0026#39;): s3_client.download_file( MODEL_BUCKET, \u0026#39;models/lstm_totald_256_4.pt\u0026#39;, \u0026#39;/tmp/lstm_model.pt\u0026#39; ) LSTM_MODEL = StormLSTM(...) LSTM_MODEL.load_state_dict(torch.load(\u0026#39;/tmp/lstm_model.pt\u0026#39;)) # Tải TCN từ local (đã có sẵn trong image) TCN_MODEL = StormTCN(...) TCN_MODEL.load_state_dict( torch.load(\u0026#39;/var/task/models/cropping_storm_7304_2l.pth\u0026#39;) ) 4. Dự đoán tổng quãng đường (LSTM) def predict_total_distance(record_tensor): if LSTM_MODEL is None: # Dự phòng (fallback): avg_distance * 24 bước return fallback_distance # Gom theo ngày (9 điểm/ngày) # Chạy dự đoán bằng LSTM with torch.no_grad(): pred = LSTM_MODEL(summary_tensor, lengths) return pred.item() # km 5. Dự đoán đường đi (TCN) def predict_storm_path(record_tensor, total_distance, history): seq = record_tensor.clone() gone_distance = 0 predicted_points = [] while gone_distance \u0026lt; total_distance: # Dự đoán vị trí tiếp theo pred_latlon, pred_aux = TCN_MODEL(seq) new_lat = pred_latlon[0, -1, 0].item() new_lng = pred_latlon[0, -1, 1].item() # Tính khoảng cách \u0026amp; hướng di chuyển step_distance = haversine(last_lat, last_lng, new_lat, new_lng) # Ước lượng tốc độ gió (giảm dần theo thời gian) estimated_wind = max(avg_wind * (0.98 ** step), 30) predicted_points.append({ \u0026#39;lat\u0026#39;: new_lat, \u0026#39;lng\u0026#39;: new_lng, \u0026#39;timestamp\u0026#39;: base_timestamp + (step * 3 * 3600 * 1000), \u0026#39;windSpeed\u0026#39;: estimated_wind, \u0026#39;pressure\u0026#39;: 980.0, \u0026#39;category\u0026#39;: calculate_category(estimated_wind) }) # Cập nhật chuỗi (sliding window) seq = torch.cat([seq[:, 1:, :], next_point.unsqueeze(1)], dim=1) gone_distance += step_distance step += 1 return predicted_points 6. Trả về response result = { \u0026#39;storm_id\u0026#39;: storm_id, \u0026#39;storm_name\u0026#39;: storm_name, \u0026#39;prediction_time\u0026#39;: datetime.now().isoformat(), \u0026#39;totalDistance\u0026#39;: 500.5, \u0026#39;actualDistance\u0026#39;: 520.3, \u0026#39;lifespan\u0026#39;: 72, \u0026#39;forecastHours\u0026#39;: 72, \u0026#39;forecast\u0026#39;: [ { \u0026#39;lat\u0026#39;: 15.1, \u0026#39;lng\u0026#39;: 106.99, \u0026#39;timestamp\u0026#39;: 1765015351626, \u0026#39;windSpeed\u0026#39;: 65, \u0026#39;pressure\u0026#39;: 980, \u0026#39;category\u0026#39;: \u0026#39;Typhoon\u0026#39; }, ... ] } return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } Quy trình Build \u0026amp; Deploy Bước 1: Build Docker Image cd storm_prediction docker build \\ --provenance=false \\ --platform linux/amd64 \\ -t storm-prediction-model . Giải thích flags:\n--provenance=false: Giảm kích thước image (không kèm metadata build) --platform linux/amd64: Lambda chỉ hỗ trợ x86_64 -t storm-prediction-model: Tên tag của image Bước 2: Tag để push lên ECR docker tag storm-prediction-model:latest \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 3: Đăng nhập ECR aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com Bước 4: Push image lên ECR docker push \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Thời gian: ~5–10 phút (upload ~2GB)\nBước 5: Cập nhật Lambda Function Trên AWS Console:\nLambda → storm-prediction Tab Image → Deploy new image Chọn image latest Nhấn Save Cấu hình Lambda Thiết lập Function Name: storm-prediction Runtime: Container image Architecture: x86_64 Memory: 3008 MB Timeout: 120 seconds Ephemeral storage: 512 MB Biến môi trường MODEL_BUCKET=storm-frontend-hosting-duc-2025 DATA_BUCKET=storm-frontend-hosting-duc-2025 Function URL URL: https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws Auth type: NONE CORS: Enabled - Allow origins: * - Allow methods: POST, OPTIONS - Allow headers: Content-Type Quyền IAM Role { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::storm-frontend-hosting-duc-2025/*\u0026#34;, \u0026#34;arn:aws:s3:::storm-ai-models/*\u0026#34; ] } ] } Giám sát \u0026amp; Logs CloudWatch Logs Log Group: /aws/lambda/storm-prediction\nCác log quan trọng:\nLoading LSTM model... Downloaded LSTM from S3 LSTM loaded successfully Loading TCN model... Checking: /var/task/models/cropping_storm_7304_2l.pth Found TCN at /var/task/models/cropping_storm_7304_2l.pth TCN loaded successfully Processing: Test Storm (TEST001) Input points: 9 Predicted total distance: 500.50 km Generated 24 predictions (72 hours) Saved to S3: predictions/TEST001_1733486400.json Metrics CloudWatch Metrics:\nInvocations Duration (trung bình ~5–10 giây) Errors Throttles Memory used (~500–800 MB) Lỗi thường gặp \u0026amp; cách xử lý 1. UnicodeDecodeError: \u0026lsquo;utf-8\u0026rsquo; codec can\u0026rsquo;t decode byte 0x80 Triệu chứng:\nUnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 64 Nguyên nhân: file model .pth ở thư mục gốc bị Lambda hiểu nhầm như file cấu hình Python\nCách xử lý: chuyển model vào thư mục con\nRUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ 2. 502 Bad Gateway Triệu chứng: Frontend nhận lỗi 502\nNguyên nhân có thể:\nLambda timeout (quá 120s) Lambda crash (hết bộ nhớ) Load model thất bại Cách xử lý:\nKiểm tra CloudWatch Logs Tăng memory nếu cần Tăng timeout nếu cần 3. LSTM Fallback Đặc điểm: log có \u0026quot; Using fallback distance\u0026quot;\nNguyên nhân: chưa có model LSTM trên S3\nCách xử lý: upload lstm_totald_256_4.pt lên S3\naws s3 cp lstm_totald_256_4.pt \\ s3://storm-frontend-hosting-duc-2025/models/ 4. ECR Push 403 Forbidden Đặc điểm: 403 Forbidden khi push image\nNguyên nhân có thể:\nHết hạn đăng nhập ECR Sai account ID Repo chưa tồn tại Cách xử lý:\n# Đăng nhập lại aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com # Tạo repository nếu cần aws ecr create-repository \\ --repository-name storm-prediction \\ --region ap-southeast-1 Kiểm thử Test local (nếu có thể) # Chạy local python app.py # Test event test_event = { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } result = handler(test_event, None) print(result) Test trực tiếp trên Lambda Trên AWS Console:\nLambda → tab Test Tạo test event: { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 120.2}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 120.3}, {\u0026#34;lat\u0026#34;: 15.4, \u0026#34;lng\u0026#34;: 120.4}, {\u0026#34;lat\u0026#34;: 15.5, \u0026#34;lng\u0026#34;: 120.5}, {\u0026#34;lat\u0026#34;: 15.6, \u0026#34;lng\u0026#34;: 120.6}, {\u0026#34;lat\u0026#34;: 15.7, \u0026#34;lng\u0026#34;: 120.7}, {\u0026#34;lat\u0026#34;: 15.8, \u0026#34;lng\u0026#34;: 120.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } Nhấn Test Kiểm tra response Test bằng cURL bash curl -X POST \\ \u0026quot;https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict\u0026quot; \\ -H \u0026quot;Content-Type: application/json\u0026quot; \\ -d '{ \u0026quot;history\u0026quot;: [ {\u0026quot;lat\u0026quot;: 15.0, \u0026quot;lng\u0026quot;: 120.0}, {\u0026quot;lat\u0026quot;: 15.1, \u0026quot;lng\u0026quot;: 120.1}, {\u0026quot;lat\u0026quot;: 15.2, \u0026quot;lng\u0026quot;: 120.2}, {\u0026quot;lat\u0026quot;: 15.3, \u0026quot;lng\u0026quot;: 120.3}, {\u0026quot;lat\u0026quot;: 15.4, \u0026quot;lng\u0026quot;: 120.4}, {\u0026quot;lat\u0026quot;: 15.5, \u0026quot;lng\u0026quot;: 120.5}, {\u0026quot;lat\u0026quot;: 15.6, \u0026quot;lng\u0026quot;: 120.6}, {\u0026quot;lat\u0026quot;: 15.7, \u0026quot;lng\u0026quot;: 120.7}, {\u0026quot;lat\u0026quot;: 15.8, \u0026quot;lng\u0026quot;: 120.8} ], \u0026quot;storm_name\u0026quot;: \u0026quot;Test Storm\u0026quot; }' Checklist triển khai File model cropping_storm_7304_2l.pth tồn tại (Tùy chọn) Upload model LSTM lên S3 Build Docker image thành công Tag image đúng account ID (339570693867) Login ECR thành công Push image lên ECR Update Lambda function với image mới Kiểm tra cấu hình Lambda (memory, timeout) Test Lambda với test event Test qua Function URL bằng cURL Test từ frontend Kiểm tra CloudWatch Logs Xác nhận kết quả dự đoán hiển thị trên bản đồ Ảnh chụp Hình 1 Cấu hình (Configuration) Hình 2 Biến môi trường (Environment Variables) Hình 3 ECR Kho lưu trữ (Repository) Hình 4 Hình 5 "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.2-fix-unicode-error-solution/","title":"Sửa lỗi Unicode","tags":[],"description":"","content":"Giải quyết lỗi UnicodeDecodeError trong Lambda Đây là một lỗi quan trọng mà nhóm gặp phải trong quá trình xây dựng nền tảng và tích hợp model nên dành riêng một mục để nói về nó. Chi tiết xe ở bên dưới.\nVấn đề UnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 64: invalid start byte Nguyên nhân Model PyTorch có extension .pth (binary file) Python runtime cũng sử dụng .pth files cho path configuration (text files) Khi đặt model .pth trực tiếp trong LAMBDA_TASK_ROOT, Python cố đọc nó như text → lỗi Giải pháp đã áp dụng 1. Sửa Dockerfile Di chuyển model vào thư mục con models/:\nRUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ 2. Sửa app.py Update đường dẫn tìm model:\npossible_paths = [ \u0026#39;/var/task/models/cropping_storm_7304_2l.pth\u0026#39;, \u0026#39;models/cropping_storm_7304_2l.pth\u0026#39;, tcn_path ] Các bước rebuild và deploy Bước 1: Build Docker image cd storm_prediction docker build --provenance=false --platform linux/amd64 -t storm-prediction-model . Lưu ý: --provenance=false giúp giảm kích thước image để push lên ECR\nBước 2: Tag image docker tag storm-prediction-model:latest 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 3: Login ECR aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com Bước 4: Push to ECR docker push 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 5: Update Lambda Vào AWS Console → Lambda → storm-prediction Click tab Image Click Deploy new image Chọn image mới nhất Click Save Bước 6: Test curl -X POST \u0026#34;https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 14.5, \u0026#34;lng\u0026#34;: 121.0}, {\u0026#34;lat\u0026#34;: 14.6, \u0026#34;lng\u0026#34;: 121.1}, {\u0026#34;lat\u0026#34;: 14.7, \u0026#34;lng\u0026#34;: 121.2}, {\u0026#34;lat\u0026#34;: 14.8, \u0026#34;lng\u0026#34;: 121.3}, {\u0026#34;lat\u0026#34;: 14.9, \u0026#34;lng\u0026#34;: 121.4}, {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 121.5}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 121.6}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 121.7}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 121.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; }\u0026#39; Kiểm tra logs sau khi deploy aws logs tail /aws/lambda/storm-prediction --region ap-southeast-1 --follow Tóm tắt Trước: Model .pth ở root → Python nhầm là config file → UnicodeDecodeError Sau: Model .pth ở models/ → Python bỏ qua → Lambda hoạt động ✅ "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.1-ai-model-integration/","title":"Tích Hợp AI","tags":[],"description":"","content":"Tiến hành tích hợp AI Model từ Lambda Tổng quan Dưới đây xin trình bày về cách mà nhóm đã tích hợp mô hình AI dự đoán bão từ lambda để dùng theo từng bước.\nCác file đang dùng Mock Data 1. WeatherOverlay.tsx (QUAN TRỌNG) Vị trí: frontend/src/components/WeatherOverlay.tsx Mock data: Temperature và Wind overlay data Function: generateWeatherData() Cần sửa: Thay thế bằng API call đến Lambda 2. WeeklyForecast.tsx Vị trí: frontend/src/components/WeeklyForecast.tsx Mock data: mockForecast array Cần sửa: Fetch từ backend API 3. windData.ts Vị trí: frontend/src/lib/windData.ts Mock data: mockWindData Cần sửa: Fetch từ OpenWeatherMap hoặc Lambda 4. WindFieldManager.ts Vị trí: frontend/src/components/wind/WindFieldManager.ts Mock data: Fallback khi không có API key Đã OK: Có logic fetch từ OpenWeatherMap, chỉ cần config API key Cách tích hợp AI Model từ Lambda Bước 1: Thêm API endpoint cho Storm Prediction Trong file frontend/src/api/weatherApi.ts, thêm:\nexport interface StormPrediction { stormId: string; name: string; nameVi: string; currentPosition: { lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; }; historicalTrack: Array\u0026lt;{ lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; }\u0026gt;; forecastTrack: Array\u0026lt;{ lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; confidence?: number; // Độ tin cậy từ AI model }\u0026gt;; } export const weatherApi = { // ... existing methods ... // Lấy dự đoán bão từ Lambda AI model getStormPredictions: async (): Promise\u0026lt;StormPrediction[]\u0026gt; =\u0026gt; { const response = await api.get\u0026lt;StormPrediction[]\u0026gt;(\u0026#39;/storms/predictions\u0026#39;); return response.data; }, // Lấy chi tiết một cơn bão cụ thể getStormById: async (stormId: string): Promise\u0026lt;StormPrediction\u0026gt; =\u0026gt; { const response = await api.get\u0026lt;StormPrediction\u0026gt;(`/storms/${stormId}`); return response.data; }, }; Bước 2: Cập nhật Backend để gọi Lambda Trong backend C# (backend/Controllers/WeatherController.cs), thêm endpoint:\n[HttpGet(\u0026#34;storms/predictions\u0026#34;)] public async Task\u0026lt;IActionResult\u0026gt; GetStormPredictions() { try { // Gọi Lambda function var lambdaClient = new AmazonLambdaClient(); var request = new InvokeRequest { FunctionName = \u0026#34;storm-prediction-function\u0026#34;, InvocationType = InvocationType.RequestResponse, Payload = \u0026#34;{}\u0026#34; // Hoặc parameters nếu cần }; var response = await lambdaClient.InvokeAsync(request); using var reader = new StreamReader(response.Payload); var result = await reader.ReadToEndAsync(); return Ok(JsonSerializer.Deserialize\u0026lt;List\u0026lt;StormPrediction\u0026gt;\u0026gt;(result)); } catch (Exception ex) { return StatusCode(500, new { error = ex.Message }); } } Bước 3: Cập nhật Frontend để dùng API thật Trong frontend/src/pages/Index.tsx hoặc nơi fetch storm data:\nimport { weatherApi } from \u0026#39;../api/weatherApi\u0026#39;; import { useQuery } from \u0026#39;@tanstack/react-query\u0026#39;; // Thay vì dùng mock data const { data: storms, isLoading } = useQuery({ queryKey: [\u0026#39;storms\u0026#39;], queryFn: () =\u0026gt; weatherApi.getStormPredictions(), refetchInterval: 5 * 60 * 1000, // Refresh mỗi 5 phút }); Bước 4: Cấu hình Environment Variables Frontend (.env.production):\nVITE_API_BASE_URL=https://your-backend-api.com/api/weather Backend (appsettings.json):\n{ \u0026#34;AWS\u0026#34;: { \u0026#34;Region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;LambdaFunctionName\u0026#34;: \u0026#34;storm-prediction-function\u0026#34; } } Checklist Deploy Deploy AI model lên Lambda Test Lambda function với sample input Thêm API endpoint trong backend C# Test backend endpoint Cập nhật weatherApi.ts với endpoints mới Thay thế mock data bằng API calls Test frontend với data thật Cập nhật .env.production với URL production Build và deploy frontend Monitor logs và errors Files không cần sửa (chỉ là examples) Các file này chỉ là demo/example, không ảnh hưởng production:\n*.example.tsx */__tests__/* */GUIDE.md "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.3-lambda-deployment/","title":"Triển Khai Lamda","tags":[],"description":"","content":"Các bước Deploy PyTorch Model dự đoán bão lên AWS Lambda Việc triển khai Lambda là một phần quan trọng trong quy trình phát triển website của nhóm. Mục sau đây sẽ giải thích các bước chúng em đã thực hiện để hoàn thành quy trình này.\nChuẩn bị Code 1.1. Sửa app.py\nimport json import torch import numpy as np from typing import List, Dict # Load model khi Lambda khởi động (reuse across invocations) MODEL_PATH = \u0026#34;model.pth\u0026#34; device = torch.device(\u0026#34;cpu\u0026#34;) # Lambda không có GPU model = None def load_model(): global model if model is None: print(f\u0026#34;Loading model from {MODEL_PATH}...\u0026#34;) model = torch.load(MODEL_PATH, map_location=device) model.eval() print(\u0026#34;Model loaded successfully!\u0026#34;) return model def prepare_features(history: List[Dict]) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34; Chuyển đổi history thành tensor cho model history: [{\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 107.0}, ...] \u0026#34;\u0026#34;\u0026#34; # TODO: Implement feature engineering theo model của bạn lats = [p[\u0026#34;lat\u0026#34;] for p in history] lngs = [p[\u0026#34;lng\u0026#34;] for p in history] # Ví dụ: normalize và reshape features = np.array([lats + lngs]) # Shape: (1, 18) return torch.tensor(features, dtype=torch.float32) def format_predictions(predictions: torch.Tensor, storm_name: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34; Format output theo cấu trúc frontend cần \u0026#34;\u0026#34;\u0026#34; # TODO: Implement theo output của model pred_array = predictions.detach().cpu().numpy()[0] # Giả sử model predict 10 điểm tiếp theo (lat, lng) forecast = [] base_timestamp = int(time.time() * 1000) for i in range(0, len(pred_array), 2): if i + 1 \u0026lt; len(pred_array): forecast.append({ \u0026#34;lat\u0026#34;: float(pred_array[i]), \u0026#34;lng\u0026#34;: float(pred_array[i + 1]), \u0026#34;timestamp\u0026#34;: base_timestamp + (i // 2) * 3600000, # +1 hour each \u0026#34;windSpeed\u0026#34;: 120.0, # TODO: Predict từ model \u0026#34;pressure\u0026#34;: 980.0, # TODO: Predict từ model \u0026#34;category\u0026#34;: \u0026#34;Category 3\u0026#34;, # TODO: Classify từ windSpeed \u0026#34;confidence\u0026#34;: 0.85 }) return { \u0026#34;storm_name\u0026#34;: storm_name, \u0026#34;forecast\u0026#34;: forecast } def handler(event, context): \u0026#34;\u0026#34;\u0026#34; Lambda handler function \u0026#34;\u0026#34;\u0026#34; try: # Parse input body = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) history = body.get(\u0026#39;history\u0026#39;, []) storm_name = body.get(\u0026#39;storm_name\u0026#39;, \u0026#39;Unknown Storm\u0026#39;) # Validate input if len(history) \u0026lt; 9: return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: f\u0026#39;Need at least 9 positions, got {len(history)}\u0026#39; }) } # Load model model = load_model() # Prepare features X = prepare_features(history) # Predict with torch.no_grad(): predictions = model(X) # Format output result = format_predictions(predictions, storm_name) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: str(e) }) } 1.2. Sửa Dockerfile\nFROM public.ecr.aws/lambda/python:3.11 # Copy requirements và install COPY requirements.txt ${LAMBDA_TASK_ROOT} RUN pip install --no-cache-dir -r requirements.txt # Copy model (đổi tên thành model.pth) COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/model.pth # Copy code COPY app.py ${LAMBDA_TASK_ROOT} # Set handler CMD [\u0026#34;app.handler\u0026#34;] 1.3. Kiểm tra requirements.txt\ntorch==2.1.0 numpy==1.24.3 Bước 2: Build Docker Image cd storm_prediction # Build image docker build -t storm-prediction-model . # Test local (optional) docker run -p 9000:8080 storm-prediction-model # Test với curl curl -X POST \u0026#34;http://localhost:9000/2015-03-31/functions/function/invocations\u0026#34; \\ -d \u0026#39;{ \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;history\\\u0026#34;: [{\\\u0026#34;lat\\\u0026#34;: 15.0, \\\u0026#34;lng\\\u0026#34;: 107.0}, {\\\u0026#34;lat\\\u0026#34;: 15.1, \\\u0026#34;lng\\\u0026#34;: 107.1}, {\\\u0026#34;lat\\\u0026#34;: 15.2, \\\u0026#34;lng\\\u0026#34;: 107.2}, {\\\u0026#34;lat\\\u0026#34;: 15.3, \\\u0026#34;lng\\\u0026#34;: 107.3}, {\\\u0026#34;lat\\\u0026#34;: 15.4, \\\u0026#34;lng\\\u0026#34;: 107.4}, {\\\u0026#34;lat\\\u0026#34;: 15.5, \\\u0026#34;lng\\\u0026#34;: 107.5}, {\\\u0026#34;lat\\\u0026#34;: 15.6, \\\u0026#34;lng\\\u0026#34;: 107.6}, {\\\u0026#34;lat\\\u0026#34;: 15.7, \\\u0026#34;lng\\\u0026#34;: 107.7}, {\\\u0026#34;lat\\\u0026#34;: 15.8, \\\u0026#34;lng\\\u0026#34;: 107.8}], \\\u0026#34;storm_name\\\u0026#34;: \\\u0026#34;Test Storm\\\u0026#34;}\u0026#34; }\u0026#39; Bước 3: Upload lên AWS ECR # 1. Tạo ECR repository aws ecr create-repository \\ --repository-name storm-prediction-model \\ --region ap-southeast-1 # 2. Đăng nhập Docker vào ECR aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com # 3. Tag image docker tag storm-prediction-model:latest \\ \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest # 4. Push image docker push \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest Lưu ý: Thay \u0026lt;account-id\u0026gt; bằng AWS Account ID của bạn.\nBước 4: Tạo Lambda Function 4.1. Tạo Lambda từ Console\nVào AWS Lambda Console Click \u0026ldquo;Create function\u0026rdquo; Chọn \u0026ldquo;Container image\u0026rdquo; Function name: storm-prediction Container image URI: Chọn image vừa push lên ECR Architecture: x86_64 Click \u0026ldquo;Create function\u0026rdquo; 4.2. Cấu hình Lambda\n# Hoặc dùng AWS CLI aws lambda create-function \\ --function-name storm-prediction \\ --package-type Image \\ --code ImageUri=\u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest \\ --role arn:aws:iam::\u0026lt;account-id\u0026gt;:role/lambda-execution-role \\ --timeout 60 \\ --memory-size 3008 \\ --region ap-southeast-1 Cấu hình quan trọng:\nMemory: 3008 MB (PyTorch model cần nhiều RAM) Timeout: 60 seconds (model inference có thể mất 10-30s) Ephemeral storage: 512 MB (default, tăng nếu cần) 4.3. Tạo IAM Role\nLambda cần role với permissions:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Bước 5: Tạo API Gateway # 1. Tạo REST API aws apigateway create-rest-api \\ --name storm-prediction-api \\ --region ap-southeast-1 # 2. Lấy API ID và Root Resource ID API_ID=\u0026lt;your-api-id\u0026gt; ROOT_ID=\u0026lt;your-root-resource-id\u0026gt; # 3. Tạo resource /predict aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $ROOT_ID \\ --path-part predict # 4. Tạo POST method RESOURCE_ID=\u0026lt;predict-resource-id\u0026gt; aws apigateway put-method \\ --rest-api-id $API_ID \\ --resource-id $RESOURCE_ID \\ --http-method POST \\ --authorization-type NONE # 5. Integrate với Lambda aws apigateway put-integration \\ --rest-api-id $API_ID \\ --resource-id $RESOURCE_ID \\ --http-method POST \\ --type AWS_PROXY \\ --integration-http-method POST \\ --uri arn:aws:apigateway:ap-southeast-1:lambda:path/2015-03-31/functions/arn:aws:lambda:ap-southeast-1:\u0026lt;account-id\u0026gt;:function:storm-prediction/invocations # 6. Deploy API aws apigateway create-deployment \\ --rest-api-id $API_ID \\ --stage-name prod API URL: https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/prod/predict\nBước 6: Cập nhật Frontend 6.1. Cập nhật .env.production\nVITE_PREDICTION_API_URL=https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/prod 6.2. Build và deploy frontend\ncd frontend npm run build # Deploy dist/ lên S3/CloudFront Tối ưu hóa 1. Giảm Cold Start Provisioned Concurrency:\naws lambda put-provisioned-concurrency-config \\ --function-name storm-prediction \\ --provisioned-concurrent-executions 1 \\ --qualifier $LATEST 2. Giảm kích thước Image Dùng PyTorch CPU-only:\n# requirements.txt torch==2.1.0+cpu --extra-index-url https://download.pytorch.org/whl/cpu numpy==1.24.3 Multi-stage build:\n# Stage 1: Build FROM python:3.11-slim as builder COPY requirements.txt . RUN pip install --target /packages -r requirements.txt # Stage 2: Runtime FROM public.ecr.aws/lambda/python:3.11 COPY --from=builder /packages ${LAMBDA_RUNTIME_DIR} COPY model.pth ${LAMBDA_TASK_ROOT}/ COPY app.py ${LAMBDA_TASK_ROOT}/ CMD [\u0026#34;app.handler\u0026#34;] 3. Cache Model trong /tmp import os MODEL_PATH = \u0026#34;/tmp/model.pth\u0026#34; if os.path.exists(\u0026#34;/tmp/model.pth\u0026#34;) else \u0026#34;model.pth\u0026#34; def load_model(): global model if model is None: # Copy to /tmp for faster access if not os.path.exists(\u0026#34;/tmp/model.pth\u0026#34;): import shutil shutil.copy(\u0026#34;model.pth\u0026#34;, \u0026#34;/tmp/model.pth\u0026#34;) model = torch.load(\u0026#34;/tmp/model.pth\u0026#34;, map_location=device) model.eval() return model Monitoring CloudWatch Logs # Xem logs aws logs tail /aws/lambda/storm-prediction --follow CloudWatch Metrics Invocations: Số lần gọi Duration: Thời gian chạy Errors: Số lỗi Throttles: Số lần bị throttle Alerts # Tạo alarm cho errors aws cloudwatch put-metric-alarm \\ --alarm-name storm-prediction-errors \\ --alarm-description \u0026#34;Alert when Lambda has errors\u0026#34; \\ --metric-name Errors \\ --namespace AWS/Lambda \\ --statistic Sum \\ --period 300 \\ --threshold 5 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=FunctionName,Value=storm-prediction Troubleshooting Lỗi: \u0026ldquo;Task timed out after 3.00 seconds\u0026rdquo; Giải pháp: Tăng timeout lên 60s\nLỗi: \u0026ldquo;Runtime exited with error: signal: killed\u0026rdquo; Giải pháp: Tăng memory lên 3008 MB\nLỗi: \u0026ldquo;No module named \u0026rsquo;torch'\u0026rdquo; Giải pháp: Kiểm tra requirements.txt và rebuild image\nLỗi: Model không load được Giải pháp: Kiểm tra tên file model trong Dockerfile và app.py\nChi phí ước tính Lambda:\nFree tier: 1M requests/month, 400,000 GB-seconds Sau đó: $0.20 per 1M requests + $0.0000166667 per GB-second Ví dụ: 10,000 requests/month, mỗi request 10s, 3GB RAM\nCompute: 10,000 × 10s × 3GB × $0.0000166667 = $5/month Requests: 10,000 × $0.20/1M = $0.002/month Total: ~$5/month API Gateway:\n$3.50 per million requests 10,000 requests = $0.035/month ECR:\n$0.10 per GB/month storage Image ~2GB = $0.20/month Total ước tính: ~$5.25/month cho 10,000 predictions\nChecklist cuối cùng Sửa tên file model trong app.py hoặc Dockerfile Test Docker image locally Push image lên ECR Tạo Lambda function với memory 3008MB, timeout 60s Tạo API Gateway và integrate với Lambda Test API với Postman/curl Cập nhật VITE_PREDICTION_API_URL trong frontend Build và deploy frontend Test form prediction trên web Setup CloudWatch alerts Monitor logs và performance "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Triển khai ứng dụng full-stack với EC2 và RDS Triển khai AWS Lightsail để host WordPress Đóng góp vào phát triển và tài liệu hóa dự án nhóm Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chuẩn bị cơ sở hạ tầng để triển khai ứng dụng: + Tạo VPC cho môi trường ứng dụng + Tạo Security Group cho EC2 + Tạo Security Group cho RDS + Tạo DB Subnet Group - Triển khai các thành phần ứng dụng: + Tạo Instance EC2 + Tạo instance database RDS - Triển khai và quản lý ứng dụng: + Triển khai ứng dụng lên instance EC2 + Triển khai quy trình backup và restore 10/06/2025 10/06/2025 https://000005.awsstudygroup.com/ 3 - Tạo dataset tọa độ bão với bước thời gian 3 giờ cho việc training model của dự án nhóm 10/07/2025 10/08/2025 4 - Làm việc trên phiên bản tiếng Việt của file đề xuất dự án nhóm Markdown - Triển khai database trên AWS Lightsail - Triển khai instance WordPress: + Khởi chạy instance WordPress trên Lightsail + Cấu hình cài đặt server Ubuntu + Thiết lập cấu hình mạng + Hoàn tất thiết lập và cấu hình WordPress 10/09/2025 10/09/2025 https://000045.awsstudygroup.com/ 5 - Làm việc trên bản dịch tiếng Việt của 3 bài blog theo yêu cầu từ mentors: + Mô hình Qwen hiện đã có sẵn trong Amazon Bedrock + Mô hình DeepSeek-V3.1 hiện đã có sẵn trong Amazon Bedrock + Mở rộng sản xuất hình ảnh bằng Stability AI Image Services trong Amazon Bedrock 10/10/2025 10/10/2025 Kết quả đạt được tuần 5: Triển khai thành công cơ sở hạ tầng ứng dụng đầy đủ sử dụng EC2 và RDS:\nTạo VPC với security groups và subnet groups phù hợp Cấu hình instance EC2 và database RDS để host ứng dụng Triển khai quy trình backup và restore để bảo vệ dữ liệu Triển khai thành công WordPress sử dụng AWS Lightsail:\nKhởi chạy và cấu hình instance WordPress trên Lightsail Thiết lập cấu hình server Ubuntu và mạng Triển khai database và hoàn tất thiết lập WordPress Đóng góp vào phát triển dự án nhóm:\nTạo dataset tọa độ bão cho việc training model Dịch tài liệu đề xuất dự án sang tiếng Việt Nâng cao khả năng tiếp cận dự án cho thành viên nhóm người Việt Hoàn thành công việc dịch thuật kỹ thuật:\nDịch các bài blog về AWS Bedrock và mô hình AI Bao gồm Qwen, DeepSeek-V3.1, và dịch vụ Stability AI Hỗ trợ chia sẻ kiến thức trong cộng đồng Việt Nam Có được kinh nghiệm với nhiều phương pháp triển khai AWS:\nKiến trúc EC2+RDS truyền thống Mô hình triển khai Lightsail đơn giản Các thực tiễn tốt nhất về hosting database và ứng dụng "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"NỀN TẢNG THEO DÕI VÀ DỰ ĐOÁN BÃO Tổng Quan Bão là một trong những thảm họa thiên nhiên nguy hiểm nhất, có thể gây thiệt hại nghiêm trọng đến cơ sở hạ tầng và đe dọa tính mạng con người. Việc phát hiện sớm và đưa ra cảnh báo kịp thời là vô cùng quan trọng để người dân trong khu vực bị ảnh hưởng có đủ thời gian chuẩn bị và sơ tán an toàn.\nĐể đáp ứng nhu cầu này, dự án của chúng tôi hướng đến việc xây dựng một nền tảng trực tuyến cho phép người dùng truy cập miễn phí vào thông tin về những cơn bão mới nhất ở khu vực Tây Thái Bình Dương, sử dụng dữ liệu từ NOAA (Cơ quan Quản lý Khí quyển và Đại dương Quốc gia Hoa Kỳ) — một nguồn dữ liệu đáng tin cậy. Bên cạnh đó, sinh viên, nhà khí tượng hoặc bất kỳ ai quan tâm đến động lực học của bão đều có thể tương tác với hệ thống bằng cách cung cấp quỹ đạo đầu vào của riêng họ và nhận về dự đoán được tạo bởi mô hình học máy của chúng tôi.\nWorkshop này trình bày toàn bộ quy trình xây dựng mô hình dự báo bão, bao gồm nhiều kỹ thuật chuỗi thời gian mới — Stepwise Temporal Fading và Plausible Geodesic-Aware Augmentation — cùng với phần giải thích chi tiết từng bước về cách chúng tôi xây dựng và triển khai nền tảng từ con số 0.\nVới sự hỗ trợ của các dịch vụ AWS như Amazon S3, AWS Lambda, API Gateway và CloudFront, chúng tôi xây dựng một kiến trúc hoàn toàn serverless. Giải pháp này mang lại sự đơn giản, khả năng mở rộng linh hoạt và hiệu quả chi phí dài hạn, đồng thời đảm bảo hiệu suất ổn định và phản hồi nhanh.\nKiến trúc Nền tảng Nền tảng cuối cùng cung cấp hai chức năng cốt lõi:\nXem Thông Tin Bão Người dùng có thể khám phá thông tin mới nhất về các cơn bão ở Tây Thái Bình Dương, bao gồm quỹ đạo lịch sử, tốc độ gió, nhiệt độ và các thông số liên quan khác.\nDự Đoán Quỹ Đạo Bão Người dùng có thể nhập quỹ đạo một phần của cơn bão và nhận về dự đoán quãng đường tiếp theo được tạo bởi mô hình đã huấn luyện.\nNội dung Tổng quan về workshop Chuẩn bị dữ liệu Kiến tạo mô hình ML Kiến trúc Front\u0026amp;Back-end API "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/5-workshop/5.5-platform-api/","title":"Nền tảng API","tags":[],"description":"","content":"MÔ TẢ CHI TIẾT BACK-END API Mục lục Giới thiệu Kiến trúc hệ thống Tính năng cốt lõi Công nghệ sử dụng Cấu trúc dự án API Endpoints 1. Giới thiệu Weather Backend API là một dịch vụ RESTful cung cấp thông tin thời tiết bằng cách tích hợp với OpenWeatherMap API. Backend hoạt động như lớp trung gian giữa ứng dụng frontend và các nguồn dữ liệu thời tiết bên ngoài.\nHình 1 2. Kiến trúc hệ thống Kiến trúc ┌─────────────────────────────────────────────────────────────┐ │ Ứng dụng Frontend │ │ (React, Mobile, Web Clients) │ └─────────────────────────────────────────────────────────────┘ │ │ HTTPS / REST API ▼ ┌─────────────────────────────────────────────────────────────┐ │ Weather Backend API │ │ (.NET 9.0 - ASP.NET Core) │ ├─────────────────────────────────────────────────────────────┤ │ ┌────────────────┐ ┌────────────────┐ ┌────────────────┐ │ │ Bộ điều khiển │ │ Dịch vụ │ │ Program.cs │ │ │ │ │ │ │ - Khởi động app│ │ │ - WeatherCtrl │ │ - WeatherSvc │ │ - Ghi log │ │ │ - ForecastCtrl │ │ - Lớp cache │ │ - Thiết lập DI │ │ └────────────────┘ └────────────────┘ └────────────────┘ └─────────────────────────────────────────────────────────────┘ │ │ HTTPS / REST API (Bên ngoài) ▼ ┌─────────────────────────────────────────────────────────────┐ │ Dịch vụ thời tiết bên ngoài │ ├─────────────────────────────────────────────────────────────┤ │ • OpenWeatherMap API │ │ • Redis Caching Layer │ │ • Giới hạn tốc độ \u0026amp; Giám sát │ └─────────────────────────────────────────────────────────────┘ 3. Tính năng cốt lõi Mô tả: Lấy dữ liệu thời tiết hiện tại của bất kỳ thành phố nào trên thế giới.\nTính năng:\nTìm kiếm theo tên thành phố (ví dụ: \u0026ldquo;Hà Nội\u0026rdquo;, \u0026ldquo;TP Hồ Chí Minh\u0026rdquo;) Tùy chọn mã quốc gia để xác định vị trí chính xác Hỗ trợ nhiều hệ thống đơn vị (metric, imperial, standard) Hỗ trợ đa ngôn ngữ cho phần mô tả thời tiết Phản hồi được lưu cache để tăng hiệu suất Tham số API:\ncityName (bắt buộc): Tên thành phố countryCode (tùy chọn): Mã quốc gia ISO 3166 units (tùy chọn): metric, imperial, standard language (tùy chọn): en, vi, fr, \u0026hellip; Ví dụ phản hồi:\nResponse body Download { \u0026#34;localDate\u0026#34;: \u0026#34;2025-12-06 19:57:02\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Hà Nội\u0026#34;, \u0026#34;coord\u0026#34;: { \u0026#34;lon\u0026#34;: 105.8412, \u0026#34;lat\u0026#34;: 21.0245 }, \u0026#34;weather\u0026#34;: [ { \u0026#34;id\u0026#34;: 804, \u0026#34;main\u0026#34;: \u0026#34;Clouds\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;mây đen u ám\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;04n\u0026#34; } ], \u0026#34;main\u0026#34;: { \u0026#34;temp\u0026#34;: 22, \u0026#34;feels_like\u0026#34;: 22.11, \u0026#34;temp_min\u0026#34;: 22, \u0026#34;temp_max\u0026#34;: 22, \u0026#34;pressure\u0026#34;: 1018, \u0026#34;humidity\u0026#34;: 71, \u0026#34;sea_level\u0026#34;: 1018, \u0026#34;grnd_level\u0026#34;: 1017 }, \u0026#34;wind\u0026#34;: { \u0026#34;speed\u0026#34;: 4.14, \u0026#34;deg\u0026#34;: 136, \u0026#34;gust\u0026#34;: 6.84 }, \u0026#34;sys\u0026#34;: { \u0026#34;type\u0026#34;: 1, \u0026#34;id\u0026#34;: 9308, \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;sunrise\u0026#34;: 1764976827, \u0026#34;sunset\u0026#34;: 1765016103 } } Hình 2 4. Công nghệ sử dụng Backend Framework .NET 9.0 – Runtime .NET mới nhất ASP.NET Core – Framework xây dựng Web API C# 12 – Ngôn ngữ lập trình chính Tích hợp API HttpClientFactory – Quản lý sử dụng HTTP client Polly – Chính sách thử lại \u0026amp; xử lý lỗi tạm thời Newtonsoft.Json / System.Text.Json – Tuần tự hóa JSON Cache \u0026amp; Hiệu năng MemoryCache – Cache trong bộ nhớ Redis (tùy chọn) – Cache phân tán ResponseCompression – Nén Gzip / Brotli Công cụ phát triển Visual Studio 2022 / VS Code - IDE / Trình soạn thảo mã Swagger / OpenAPI – Tài liệu API Git – Kiểm soát phiên bản Docker – Container hóa 5. Cấu trúc dự án WeatherBackend/ │ ├── WeatherBackend.csproj # Tập tin dự án ├── Program.cs # Điểm vào ứng dụng ├── WeatherBackend.http # Tập tin kiểm tra yêu cầu HTTP │ ├── appsettings.json # Cài đặt cấu hình │ ├── Controllers/ # Bộ điều khiển API │ └── WeatherController.cs # Điểm cuối thời tiết chính │ ├── Services/ # Dịch vụ logic nghiệp vụ │ └── WeatherService/ # Hợp đồng \u0026amp; triển khai dịch vụ 6. API Endpoints Base URL https://localhost:7042/swagger/index.html 6.1 GET /api/weather/current Mô tả:\nLấy dữ liệu thời tiết hiện tại theo tên thành phố.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather?city=hanoi\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather?city=hanoi 6.2 GET /api/weather/forecast Mô tả: Lấy dự báo thời tiết 5 ngày cho một thành phố được chọn.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/forecast?city=hochiminh\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/forecast?city=hochiminh 6.3 GET /api/weather/coordinates Mô tả: Lấy thông tin thời tiết bằng vĩ độ và kinh độ.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/by-coord?lat=21.0245\u0026amp;lon=105.8412\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/by-coord?lat=21.0245\u0026amp;lon=105.8412 6.4 GET /api/weather/location Mô tả: Lấy thông tin thời tiết theo vị trí của người dùng (yêu cầu thiết bị người dùng gửi tọa độ).\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/global\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/global Hình 3 Cập nhập lần cuối: 2025-12-09\nPhiên bản: 1.0.0\nBảo trì bởi: SKYNET\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Amazon Web Services từ 09/08/2025 đến 24/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế. Tôi đã tích cực hoàn thành nhiều lab và tham gia các sự kiện, đồng thời đóng góp cho dự án chính của nhóm: một nền tảng trực tuyến để theo dõi và dự báo quỹ đạo bão. Thông qua những trải nghiệm này, tôi đã cải thiện đáng kể các kỹ năng làm việc nhóm, báo cáo, thao tác thực hành trên AWS console, và có được cái nhìn rộng hơn về thực trạng hiện tại của các công nghệ Điện toán đám mây và Trí tuệ nhân tạo.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ☐ ✅ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ☐ ✅ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tốc độ và khả năng ứng dụng các thông tin mới học được vào bối cảnh thực tế. Xây dựng sự tự tin khi trình bày ý tưởng và mối quan tâm trong môi trường nhóm. Cải thiện tính rõ ràng và tính chuyên nghiệp trong các báo cáo bằng văn bản. "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Triển khai ứng dụng doanh nghiệp trên AWS Lightsail Thành thạo việc triển khai và quản lý container Triển khai auto scaling cho tính sẵn sàng cao Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Triển khai Instance Thương mại Điện tử Prestashop trên Lightsail: + Khởi chạy instance Prestashop + Cấu hình cài đặt mạng + Hoàn tất triển khai Prestashop - Triển khai biện pháp bảo mật ứng dụng - Tạo snapshot instance để backup 10/13/2025 10/13/2025 https://000045.awsstudygroup.com/ 3 - Triển khai Instance Akaunting trên Lightsail: + Khởi chạy instance ứng dụng Akaunting + Cấu hình cấu hình mạng + Hoàn tất triển khai ứng dụng Akaunting - Thực hiện quản lý instance: + Nâng cấp lên kích thước instance lớn hơn + Tạo alarms để giám sát 10/14/2025 10/14/2025 https://000045.awsstudygroup.com/ 4 - Tạo và cấu hình dịch vụ container trên AWS - Triển khai container images công khai - Build và triển khai container images tùy chỉnh: + Tạo instance Lightsail để triển khai container + Cấu hình AWS CLI để quản lý container + Cài đặt Docker trên instance Ubuntu + Build container images tùy chỉnh + Push container images lên registry + Triển khai các container mới 10/15/2025 10/15/2025 https://000046.awsstudygroup.com/ 5 - Triển khai Cơ sở Hạ tầng Quản lý FCJ: + Thiết lập cơ sở hạ tầng mạng + Khởi chạy instance EC2 + Khởi chạy instance database RDS + Thiết lập dữ liệu database + Triển khai web server + Chuẩn bị metrics cho predictive scaling - Tạo launch template - Thiết lập load balancer: + Tạo target group + Tạo load balancer 10/16/2025 10/16/2025 https://000006.awsstudygroup.com/ 6 - Hoàn tất Triển khai Auto Scaling: + Tạo Auto Scaling Group - Kiểm tra các giải pháp scaling: + Kiểm tra manual scaling + Kiểm tra scheduled scaling + Kiểm tra dynamic scaling + Đọc predictive scaling metrics 10/17/2025 10/17/2025 https://000006.awsstudygroup.com/ Kết quả đạt được tuần 6: Triển khai thành công ứng dụng doanh nghiệp trên AWS Lightsail:\nKhởi chạy và cấu hình nền tảng thương mại điện tử Prestashop Triển khai ứng dụng kế toán Akaunting với cấu hình mạng phù hợp Triển khai biện pháp bảo mật và snapshot backup Thành thạo việc triển khai và quản lý container:\nTạo và cấu hình dịch vụ container trên AWS Build container images tùy chỉnh sử dụng Docker Push images lên registry và triển khai các container mới Cấu hình AWS CLI để quản lý container Triển khai thành công các giải pháp auto scaling toàn diện:\nXây dựng cơ sở hạ tầng hoàn chỉnh với EC2, RDS và load balancers Tạo launch templates và target groups Cấu hình Auto Scaling Groups cho tính sẵn sàng cao Kiểm tra nhiều chiến lược scaling (manual, scheduled, dynamic) Nâng cao kỹ năng quản lý instance:\nThực hiện nâng cấp instance lên kích thước lớn hơn Tạo monitoring alarms để theo dõi hiệu suất Chuẩn bị metrics cho phân tích predictive scaling Có được chuyên môn trong triển khai ứng dụng trên nhiều dịch vụ AWS:\nLightsail để hosting ứng dụng đơn giản hóa Dịch vụ container để triển khai ứng dụng hiện đại Auto Scaling cho tính sẵn sàng cấp doanh nghiệp "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Thành thạo AWS CloudWatch để giám sát và quan sát Triển khai DNS hybrid với Route 53 Resolver Phát triển kỹ năng AWS CLI nâng cao Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Workshop AWS CloudWatch - Metrics: + Hoàn tất các bước chuẩn bị + Xem và phân tích CloudWatch metrics + Sử dụng search expressions để lọc metrics + Áp dụng math expressions để tính toán metrics + Cấu hình dynamic labels cho metrics 10/20/2025 10/20/2025 https://000008.awsstudygroup.com/ 3 - Workshop AWS CloudWatch - Logs \u0026amp; Monitoring: + Làm việc với CloudWatch Logs + Sử dụng CloudWatch Logs Insights để phân tích log + Cấu hình CloudWatch Metric Filters + Tạo và quản lý CloudWatch Alarms + Xây dựng và tùy chỉnh CloudWatch Dashboards 10/21/2025 10/21/2025 https://000008.awsstudygroup.com/ 4 - Thiết lập Hybrid DNS với Route 53 Resolver: + Tạo key pair để truy cập bảo mật + Khởi tạo CloudFormation template + Cấu hình security groups + Kết nối đến RD Gateway + Triển khai Microsoft Active Directory - Thiết lập cấu hình DNS: + Tạo Route 53 Outbound Endpoint + Tạo Route 53 Resolver Rules + Tạo Route 53 Inbound Endpoint + Kiểm tra kết quả DNS resolution 10/22/2025 10/23/2025 https://000010.awsstudygroup.com/ 5 - Thành thạo AWS CLI: + Cài đặt và cấu hình AWS CLI + Xem tài nguyên AWS qua các lệnh CLI + Quản lý các hoạt động Amazon S3 + Làm việc với dịch vụ Amazon SNS + Xử lý người dùng và chính sách IAM + Cấu hình VPC và Internet Gateway + Tạo instance EC2 sử dụng CLI + Xử lý sự cố CLI thông thường 10/23/2025 10/24/2025 https://000011.awsstudygroup.com/ Kết quả đạt được tuần 7: Thành thạo cách sử dụng khả năng giám sát của AWS CloudWatch:\nPhân tích metrics với search và math expressions Cấu hình dynamic labels để tăng cường trực quan hóa Sử dụng CloudWatch Logs Insights để phân tích log Tạo metric filters và cấu hình alarms Xây dựng dashboards tùy chỉnh để giám sát toàn diện Triển khai giải pháp DNS hybrid với Route 53 Resolver:\nTriển khai cơ sở hạ tầng Microsoft Active Directory Cấu hình Route 53 inbound và outbound endpoints Tạo resolver rules cho DNS resolution hybrid Kiểm tra và xác thực chức năng DNS xuyên suốt các môi trường Thành thạo AWS CLI nâng cao:\nQuản lý nhiều dịch vụ AWS (S3, SNS, IAM, VPC) qua CLI Cấu hình các thành phần VPC bao gồm Internet Gateway Tạo và quản lý instance EC2 sử dụng command line Phát triển kỹ năng xử lý sự cố cho hoạt động CLI Có được chuyên môn về tự động hóa cơ sở hạ tầng:\nSử dụng CloudFormation templates để triển khai tài nguyên Triển khai truy cập bảo mật với key pairs và security groups Kết nối đến RD Gateway để quản lý từ xa Tự động hóa cấu hình DNS và mạng Nâng cao kỹ năng giám sát và quản lý vận hành:\nThiết lập quan sát toàn diện với CloudWatch Triển khai giải pháp kết nối hybrid cloud Phát triển khả năng tự động hóa command line "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc tại công ty vừa thân thiện vừa rất thuận lợi cho năng suất. Vị trí văn phòng trên các tầng cao giúp giảm đáng kể tiếng ồn giao thông, tạo điều kiện tập trung tốt hơn. Hơn nữa, không gian làm việc khá rộng rãi, tạo nên một bầu không khí thoải mái và cởi mở. Các thành viên FCJ cũng đã hỗ trợ tôi rất tận tình, luôn cung cấp những chỉ dẫn hữu ích mỗi khi tôi gặp các nhiệm vụ khó khăn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn của tôi đã cung cấp những chỉ dẫn xuất sắc và luôn phản hồi nhanh chóng các câu hỏi của tôi. Team admin cũng hỗ trợ rất tích cực thông qua việc cung cấp đầy đủ các tài liệu thiết yếu như quy định chương trình và tiêu chí đánh giá, cũng như giải đáp kịp thời các yêu cầu cụ thể, bao gồm cả thắc mắc của tôi về sơ đồ cơ sở hạ tầng của dự án nhóm. 3. Sự phù hợp giữa công việc và chuyên ngành học\nCác nhiệm vụ được giao đã tạo cơ hội tuyệt vời để tôi áp dụng kiến thức đã học tại trường đại học vào một dự án thực tế và hiện thực hóa ý tưởng của nhóm. Trải nghiệm này cũng giúp tôi tiếp cận những lĩnh vực mới và mang tính thực tiễn mà trước đây tôi chưa từng khám phá, chẳng hạn như việc sử dụng nền tảng AWS để xây dựng và triển khai giải pháp cho dự án.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nĐợt thực tập này đã mang lại những cơ hội phát triển đáng kể cho cả chuyên môn và cá nhân tôi. Tôi đã phát triển được sự hiểu biết sâu sắc hơn và các kỹ năng thực tế trong việc sử dụng nền tảng AWS. Đồng thời, tôi cũng thu nhận được những hiểu biết quý giá về bức tranh hiện tại của lĩnh vực công nghệ liên quan đến chuyên ngành, từ đó mở rộng đáng kể góc nhìn về các ứng dụng thực tế. Hơn nữa, tôi đã có thể cải thiện khả năng truyền đạt ý tưởng một cách rõ ràng và hợp tác hiệu quả trong môi trường nhóm.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nCông ty nuôi dưỡng một văn hóa rất tích cực và bao trùm, nơi mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn giữ được sự thoải mái. Tinh thần đồng đội đặc biệt mạnh mẽ, với việc mọi người chủ động hoàn thành phần việc của mình và sẵn sàng hợp tác để giải quyết vấn đề. Các quyết định được đưa ra một cách tập thể, khi các thành viên trong nhóm luôn chia sẻ ý tưởng và thu thập ý kiến đóng góp từ toàn bộ nhóm trước khi đi đến thống nhất.\n6. Chính sách / phúc lợi cho thực tập sinh\nCác chính sách thực tập rất hỗ trợ, bao gồm mức trợ cấp hợp lý và sự linh hoạt trong việc điều chỉnh ngày làm việc khi cần thiết. Một lợi ích then chốt là được tiếp cận với các phòng thí nghiệm đào tạo có cấu trúc bài bản. Các buổi thực hành có hướng dẫn này trên giao diện điều khiển và nền tảng AWS đã cung cấp kiến thức nền tảng, thực tế, bổ trợ tốt cho công việc dự án chính.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Khía cạnh bổ ích nhất trong kỳ thực tập của tôi là cơ hội được trải nghiệm một môi trường làm việc chuyên nghiệp thực thụ lần đầu tiên. Thật sự thỏa mãn khi được áp dụng kiến thức học thuật vào bối cảnh công ty thực tế và trở thành một phần của một đội ngũ chuyên nghiệp. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Đối với các thực tập sinh tương lai, tôi tin rằng sẽ có lợi hơn nếu họ được làm việc thường xuyên hơn với không gian trên tầng 26 thay vì tầng 46, vì điều này cho phép tập hợp toàn bộ nhóm của họ dễ dàng hơn. Ngoài ra, việc có một điểm lấy nước uống tại nơi làm việc chắc chắn sẽ cải thiện sự tiện lợi hàng ngày. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Có, tôi sẽ tự tin giới thiệu về kỳ thực tập này. Nó hiệu quả trong việc thu hẹp khoảng cách giữa lý thuyết và thực hành, mang lại cơ hội tiếp xúc với các công nghệ mới và quy trình làm việc chuyên nghiệp mà tôi chưa từng gặp trước đây. Cùng với một môi trường làm việc thoải mái và hỗ trợ, nó tạo nền tảng vững chắc cho sự phát triển chuyên môn. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nNgoài những điểm đã đề cập, tôi không có đề xuất cụ thể nào khác. Trải nghiệm tổng thể của tôi rất tích cực và được tổ chức tốt. Bạn có muốn tiếp tục chương trình này trong tương lai?\nChắc chắn rồi. Nếu có cơ hội và thời gian, tôi sẽ rất vui lòng tiếp tục. Được làm việc với AWS, một trong những nền tảng điện toán đám mây hàng đầu thế giới, là một cơ hội đặc biệt. Trải nghiệm toàn diện này đã đóng góp đáng kể vào sự phát triển cả cá nhân và chuyên môn của tôi. Góp ý khác (tự do chia sẻ):\nKhông có. "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Thành thạo các kiến thức cơ bản và thao tác của Amazon DynamoDB Chuẩn bị và hoàn thành OJT Midterm Exam Phát triển kỹ năng tích hợp AWS SDK Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Kiến thức Cơ bản Amazon DynamoDB: + Học các thành phần cốt lõi và kiến trúc + Hiểu primary keys và secondary indexes + Nghiên cứu quy tắc đặt tên và kiểu dữ liệu + Khám phá read consistency models + So sánh read/write capacity modes - Quản lý DynamoDB: + Tạo access keys để truy cập theo chương trình + Tạo tables sử dụng AWS Management Console + Thực hiện các thao tác CRUD (Create, Read, Update) + Query dữ liệu và tạo Global Secondary Indexes 10/27/2025 10/27/2025 https://000060.awsstudygroup.com/ 3 - Chuẩn bị OJT Midterm Exam: + Ôn tập AWS Well-Architected Framework + Học các nguyên tắc kiến trúc bảo mật + Thực hành kiến trúc resilient và high-performing + Chuẩn bị cho các kịch bản thiết kế cost-optimized 10/28/2025 10/31/2025 4 - Thao tác DynamoDB Nâng cao: + Sử dụng AWS CloudShell để quản lý DynamoDB + Tạo tables và thực hiện thao tác qua CLI + Query Global Secondary Indexes trong CloudShell - Tích hợp AWS SDK: + Cấu hình AWS CLI để truy cập DynamoDB + Bắt đầu với Python và DynamoDB SDK + Thực hiện các thao tác table toàn diện: • Tạo, đọc, cập nhật và xóa dữ liệu • Load sample datasets • Query và scan operations • Dọn dẹp bằng cách xóa tables 10/29/2025 11/1/2025 https://000060.awsstudygroup.com/ 5 - FPTU OJT Midterm Exam - Exam 4: + Hoàn thành đánh giá kiến thức AWS + Chứng minh hiểu biết về Well-Architected Framework + Áp dụng kiến thức xuyên suốt các domain kiến trúc: • Secure Architectures • Resilient Architectures • High-Performing Architectures • Cost-Optimized Architectures 10/31/2025 10/31/2025 Kết quả đạt được tuần 8: Thành thạo sử dụng các dịch vụ của cơ sở dữ liệu NoSQL Amazon DynamoDB:\nHiểu các thành phần cốt lõi bao gồm tables, items và attributes Triển khai primary keys và Global Secondary Indexes Thực hiện các thao tác CRUD toàn diện qua console và CLI Cấu hình read consistency và capacity modes Phát triển kỹ năng quản lý cơ sở dữ liệu nâng cao:\nSử dụng AWS Management Console cho các thao tác DynamoDB Tận dụng AWS CloudShell để quản lý cơ sở dữ liệu command line Tạo và query Global Secondary Indexes để truy cập dữ liệu hiệu quả Có được kinh nghiệm lập trình AWS SDK:\nCấu hình AWS CLI để truy cập DynamoDB Tích hợp Python với DynamoDB sử dụng AWS SDK Thực hiện các thao tác table bao gồm tạo, query và xóa Quản lý vòng đời dữ liệu với load, scan và cleanup operations Chuẩn bị và hoàn thành OJT Midterm Exam:\nThành thạo các nguyên tắc AWS Well-Architected Framework Áp dụng kiến thức xuyên suốt bốn domain kiến trúc Chứng minh hiểu biết về thiết kế secure, resilient và cost-optimized Xác thực kỹ năng triển khai kiến trúc high-performing Nâng cao trình độ kỹ thuật xuyên suốt nhiều giao diện:\nWeb console để quản lý trực quan CLI cho các thao tác command line SDK cho tích hợp theo chương trình Khả năng quản trị cơ sở dữ liệu toàn diện "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Thành thạo sử dụng Amazon ElastiCache cho lưu trữ dữ liệu trong bộ nhớ Triển khai các giải pháp mạng và kết nối AWS nâng cao Phát triển kỹ năng cấu hình VPC và DNS toàn diện Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chuẩn bị \u0026amp; Tạo Cluster ElastiCache: + Tạo AWS Access Key để truy cập theo chương trình + Cài đặt và cấu hình AWS CLI + Tạo subnet groups sử dụng Console và CLI + Tạo cluster ElastiCache (cluster mode disabled) + Tạo cluster ElastiCache (cluster mode enabled) + Cấu hình quyền truy cập cluster 11/03/2025 11/03/2025 https://000061.awsstudygroup.com/ 3 - Kết nối \u0026amp; Thao tác Dữ liệu ElastiCache: + Kết nối đến cluster nodes (cả hai cluster modes) + Kiểm tra endpoints sử dụng AWS CLI + Kiểm tra chức năng user group + Thực hiện các thao tác string cơ bản (Set và Get) + Làm việc với cấu trúc dữ liệu hash (nhiều items) 11/04/2025 11/04/2025 https://000061.awsstudygroup.com/ 4 - Mạng VPC Nâng cao: + Triển khai các thành phần cơ sở hạ tầng VPC + Xem lại Cisco CSR agreement để thiết lập VPN + Tìm hiểu sâu kiến trúc các thành phần VPC + Triển khai Transit Gateway + Truy cập Cisco CSR Router sử dụng Cloud9 11/05/2025 11/05/2025 https://000092.awsstudygroup.com/ 5 - VPN, Endpoints \u0026amp; Peering: + Thiết lập kết nối VPN site-to-site + Cấu hình các đường dẫn ECMP bổ sung để dự phòng + Triển khai VPC Endpoints cho AWS Services + Thực hiện kiểm tra endpoint NP2 + Tạo yêu cầu VPC peering + Cấu hình peering routing tables 11/06/2025 11/06/2025 https://000092.awsstudygroup.com/ 6 - DNS \u0026amp; Quản lý Mạng: + Triển khai Route53 DNS endpoints và internal hosted zones + Thực hiện kiểm tra DNS toàn diện + Triển khai VPC Endpoint Services + Thiết lập Transit Gateway Network Manager + Cấu hình network sites và topology + Sử dụng Network Insights để giám sát + Kiểm tra cuối cùng kết nối VPC peering 11/07/2025 11/07/2025 https://000092.awsstudygroup.com/ Kết quả đạt được tuần 9: Thành thạo sử dụng kho dữ liệu trong bộ nhớ Amazon ElastiCache:\nTạo và cấu hình Redis clusters trong cả hai cluster modes Thiết lập quyền truy cập bảo mật và user groups Thực hiện các thao tác dữ liệu bao gồm strings, hashes và key-value pairs Kết nối đến cluster nodes và kiểm tra endpoints qua AWS CLI Triển khai các giải pháp mạng AWS toàn diện:\nTriển khai cơ sở hạ tầng VPC nâng cao với nhiều thành phần Cấu hình Transit Gateway để quản lý mạng tập trung Thiết lập kết nối VPN site-to-site với Cisco CSR routers Thiết lập các đường dẫn ECMP để dự phòng mạng và cân bằng tải Phát triển chuyên môn về các dịch vụ kết nối AWS:\nTriển khai VPC Endpoints để truy cập dịch vụ AWS riêng tư Tạo kết nối VPC peering và cấu hình routing tables Triển khai Route53 DNS endpoints và internal hosted zones Thực hiện kiểm tra và xác thực mạng toàn diện Quản lý và giám sát mạng nâng cao:\nCấu hình Transit Gateway Network Manager để hiển thị mạng toàn cầu Thiết lập network sites và ánh xạ topology Sử dụng Network Insights để giám sát hiệu suất và xử lý sự cố Truy cập thiết bị mạng sử dụng Cloud9 để quản lý từ xa Nâng cao kỹ năng tích hợp đa dịch vụ:\nKết nối ElastiCache với các mẫu dữ liệu ứng dụng Tích hợp mạng VPC với DNS và dịch vụ endpoint Kết hợp Transit Gateway với VPN và giải pháp peering Triển khai các kiến trúc kết nối mạng end-to-end "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Thành thạo sử dụng Amazon CloudFront để phân phối nội dung và edge computing Triển khai cấu hình CDN nâng cao với Lambda@Edge Triển khai và quản lý desktop ảo với Amazon WorkSpaces Tham gia sự kiện AWS Cloud Mastery Series #1 Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Phân phối Nội dung với Amazon CloudFront: + Tạo và cấu hình S3 bucket để host tĩnh + Upload file index.html ví dụ + Cấu hình Amazon CloudFront distribution với S3 bucket origin + Xác thực truy cập distribution qua CloudFront URL + Thực hiện teardown và dọn dẹp tài nguyên 11/10/2025 11/10/2025 https://000094.awsstudygroup.com/ 3 - Edge Computing với CloudFront và Lambda@Edge: + Tạo EC2 instance để host ứng dụng + Tạo S3 bucket để lưu trữ nội dung tĩnh + Cấu hình CloudFront distribution với EC2 origin + Kiểm tra phân phối ứng dụng qua CloudFront + Kiểm tra distribution invalidations + Cấu hình custom error pages 11/11/2025 11/11/2025 https://000130.awsstudygroup.com/ 4 - Cấu hình CloudFront Nâng cao: + Tạo origin groups cho các kịch bản failover + Cấu hình response headers policies + Tạo custom cache behaviors + Tạo Lambda@Edge functions + Deploy Lambda@Edge đến CloudFront distribution + Cấu hình metrics và access logs + Thực hiện dọn dẹp và teardown tài nguyên 11/12/2025 11/13/2025 https://000130.awsstudygroup.com/ 5 - Windows Workloads trên AWS: + Chuẩn bị môi trường triển khai cho Amazon WorkSpaces + Triển khai và cấu hình Amazon WorkSpaces + Truy cập WorkSpaces qua web browser + Truy cập WorkSpaces sử dụng WorkSpaces client application + Thực hiện dọn dẹp dịch vụ và kết thúc tài nguyên 11/14/2025 11/14/2025 https://000093.awsstudygroup.com/ 6 - Tham gia sự kiện AWS Cloud Mastery Series #1 11/15/2025 11/15/2025 Kết quả đạt được tuần 10: Thiết lập chuyên môn CloudFront toàn diện:\nTạo và cấu hình S3 buckets để host nội dung tĩnh Upload và quản lý file website tĩnh (index.html) Cấu hình CloudFront distributions với S3 bucket origins Triển khai EC2 instances để host ứng dụng Thiết lập CloudFront distributions với EC2 origins Kiểm tra phân phối ứng dụng qua CDN CloudFront Nâng cao khả năng edge computing:\nTriển khai cấu hình custom error pages Kiểm tra distribution invalidations để quản lý cache Tạo origin groups cho các kịch bản failover Cấu hình response headers policies Tạo custom cache behaviors Phát triển và triển khai Lambda@Edge functions Thành thạo sử dụng cơ sở hạ tầng desktop ảo:\nChuẩn bị môi trường triển khai cho Amazon WorkSpaces Triển khai và cấu hình Amazon WorkSpaces Truy cập WorkSpaces qua giao diện web browser Truy cập WorkSpaces sử dụng native client application Thực hiện dọn dẹp dịch vụ và kết thúc tài nguyên Nâng cao kỹ năng giám sát và tối ưu hóa:\nCấu hình CloudFront metrics và access logs Thực hiện dọn dẹp và teardown tài nguyên toàn diện Xác thực truy cập distribution qua CloudFront URLs "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Triển khai dịch vụ directory doanh nghiệp với AWS Managed Microsoft AD Xây dựng ứng dụng web có tính sẵn sàng cao với khả năng auto-scaling Thành thạo việc triển khai WordPress trên cơ sở hạ tầng đám mây AWS Tham gia sự kiện cộng đồng AWS và game day Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tham gia sự kiện AWS Cloud Mastery Series #2 11/17/2025 11/17/2025 3 - Dịch vụ Directory Services với AWS Managed Microsoft AD: + Triển khai dịch vụ directory AWS Managed Microsoft AD + Triển khai và cấu hình EC2 instances + Chỉnh sửa computer names để join domain + Cấu hình EC2 instances cho dịch vụ domain + Kiểm tra giao tiếp server trong domain + Thực hiện dọn dẹp dịch vụ và kết thúc tài nguyên 11/18/2025 11/18/2025 https://000095.awsstudygroup.com/ 4 - Xây dựng Ứng dụng Web Có Tính Sẵn Sàng Cao: + Chuẩn bị cơ sở hạ tầng VPC và subnet + Tạo security groups cho EC2 instances + Tạo security groups cho cơ sở dữ liệu instances + Khởi chạy và cấu hình EC2 instances + Triển khai và cấu hình database instances + Cài đặt và cấu hình WordPress trên EC2 11/19/2025 11/19/2025 https://000101.awsstudygroup.com/ 5 - Xây dựng Ứng dụng Web Có Tính Sẵn Sàng Cao: + Tạo AMI từ web server instance + Cấu hình launch templates cho auto scaling + Tạo application load balancer + Thiết lập auto scaling group + Triển khai database backup với snapshots + Khôi phục cơ sở dữ liệu từ snapshot + Cấu hình CloudFront cho web server + Thực hiện dọn dẹp tài nguyên 11/20/2025 11/20/2025 https://000101.awsstudygroup.com/ 6 - Tham gia sự kiện [AWS GenAI Builders Club] Game Day - Secret Agent(ic) Unicorns 11/21/2025 11/21/2025 Kết quả đạt được tuần 11: Thiết lập chuyên môn về dịch vụ directory doanh nghiệp:\nTriển khai dịch vụ directory AWS Managed Microsoft AD Cấu hình EC2 instances để join và quản lý domain Chỉnh sửa computer names và cấu hình dịch vụ domain Kiểm tra giao tiếp server trong Active Directory domain Quản lý vòng đời dịch vụ directory từ triển khai đến dọn dẹp Xây dựng kiến trúc ứng dụng web có tính sẵn sàng cao:\nThiết kế và triển khai cơ sở hạ tầng VPC và subnet Tạo security groups cho EC2 instances và các cơ sở dữ liệu Triển khai và cấu hình database instances cho WordPress Cài đặt và cấu hình WordPress trên EC2 instances Tạo AMI images từ web server instances Triển khai giải pháp auto-scaling và load balancing:\nCấu hình launch templates cho auto-scaling groups Triển khai application load balancers để phân phối traffic Thiết lập auto-scaling groups cho tính sẵn sàng cao Cấu hình CloudFront distributions để tăng tốc web server Thành thạo việc quản lý cơ sở dữ liệu và disaster recovery:\nTriển khai chiến lược database backup với snapshots Thực hiện khôi phục cơ sở dữ liệu từ snapshots Quản lý database instances cho ứng dụng WordPress "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Thành thạo kỹ thuật di chuyển VM sử dụng AWS VM Import/Export Triển khai di chuyển database với AWS Database Migration Service (DMS) Sử dụng Schema Conversion Tool (SCT) để chuyển đổi schema database Tham gia sự kiện AWS Cloud Mastery Series #3 Hỗ trợ hợp tác nhóm qua dịch tài liệu workshop Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Di chuyển VM với AWS VM Import/Export + Chuẩn bị môi trường VMWare Workstation + Export virtual machine từ cơ sở hạ tầng on-premises + Upload file virtual machine lên AWS S3 + Import virtual machine vào đám mây AWS + Triển khai EC2 instances từ AMI đã import 11/24/2025 11/24/2025 https://000014.awsstudygroup.com/ 3 - Di chuyển VM với AWS VM Import/Export + Cấu hình S3 bucket ACL để export VM + Export virtual machine từ EC2 instance đang chạy + Export virtual machine từ AMI hiện có + Tham khảo video hướng dẫn di chuyển + Thực hiện dọn dẹp tài nguyên trên đám mây AWS 11/25/2025 11/25/2025 https://000014.awsstudygroup.com/ 4 - Di chuyển Database với AWS Database Migration Service (DMS) và Schema Conversion Tool (SCT): + Bắt đầu với cấu hình AWS DMS + Chọn và cấu hình source database cho DMS + Chọn và cấu hình target database cho DMS + Triển khai serverless replication setup + Giám sát tiến trình và hiệu suất di chuyển DMS + Xử lý sự cố di chuyển với AWS DMS + Thực hiện dọn dẹp môi trường và kết thúc tài nguyên 11/26/2025 11/26/2025 https://000043.awsstudygroup.com/ 5 - Tạo phiên bản tiếng Việt của các file workshop tiếng Anh của nhóm 11/27/2025 11/28/2025 6 - Tham gia sự kiện AWS Cloud Mastery Series #3 11/29/2025 11/29/2025 Kết quả đạt được tuần 12: Thành thạo quy trình di chuyển virtual machine:\nChuẩn bị môi trường VMWare Workstation cho di chuyển Export virtual machines từ cơ sở hạ tầng on-premises Upload file VM lên AWS S3 storage Import virtual machines vào môi trường đám mây AWS Triển khai EC2 instances từ AMI images đã import Cấu hình S3 bucket ACLs cho hoạt động export VM Export virtual machines từ EC2 instances đang chạy Export virtual machines từ các AMIs hiện có Triển khai giải pháp di chuyển cơ sở dữ liệu toàn diện:\nCấu hình AWS Database Migration Service (DMS) Chọn và cấu hình source databases cho di chuyển Chọn và cấu hình target databases cho di chuyển Triển khai serverless replication setups Giám sát tiến trình và hiệu suất di chuyển DMS Xử lý sự cố di chuyển sử dụng công cụ AWS DMS Quản lý vòng đời di chuyển cơ sở dữ liệu từ thiết lập đến dọn dẹp Chuyên môn di chuyển đám mây nâng cao:\nThiết lập khả năng di chuyển VM end-to-end Xây dựng thành thạo di chuyển cơ sở dữ liệu xuyên suốt các nền tảng Triển khai chiến lược quản lý tài nguyên toàn diện Phát triển kỹ năng xử lý sự cố cho thách thức di chuyển "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://nguyenduyson2005.github.io/fcj-report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]
[{"uri":"https://nguyenduyson2005.github.io/fcj-report/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Scale visual production using Stability AI Image Services in Amazon Bedrock by Alex Gnibus, Isha Dua, Fabio Branco, and Suleman Patel on 18 SEP 2025 in Amazon Bedrock, Amazon Machine Learning, Amazon SageMaker AI, Announcements, Artificial Intelligence, Foundation models, Generative AI, Launch\nThis post was written with Alex Gnibus of Stability AI.\nStability AI Image Services are now available in Amazon Bedrock, offering ready-to-use media editing capabilities delivered through the Amazon Bedrock API. These image editing tools expand on the capabilities of Stability AI’s Stable Diffusion 3.5 models (SD3.5) and Stable Image Core and Ultra models, which are already available in Amazon Bedrock and have set new standards in image generation.\nThe professional creative production process consists of multiple editing steps to get the exact output needed. With Stability AI Image Services in Amazon Bedrock, you can modify, enhance, and transform existing images without jumping between multiple systems or sending files to external services. Everything runs through the same Amazon Bedrock experience you’re already using. The business impact can be immediate for teams that produce visual content at scale.\nIn this post, we explore examples of how these tools enable precise creative control to accelerate professional-grade visual content. Bài viết này được viết cùng với Alex Gnibus của Stability AI.\nEditing tools now available in Amazon Bedrock Stability AI Image Services span 13 tools across three categories: Edit, Upscale, and Control. Each tool handles specific editing tasks that typically require specialized software or manual intervention.\nEdit: Advanced capabilities for granular editing steps The tools in the Edit category make complex editing tasks more accessible and efficient.\nThe suite begins with fundamental yet powerful retouching tools. The Erase Object tool, for example, removes unwanted elements from images while intelligently maintaining background consistency. The following animation showcases the Erase Object tool removing a mannequin from a product shot while preserving the background. The tool can transform a source image based on a mask image or derive the mask from the source image’s alpha channel.\nThe Remove Background tool automatically isolates subjects with precision. This enables the creation of clean, professional product listings with consistent backgrounds or a variety of lifestyle settings, which is a game changer for ecommerce.\nThe following example illustrates the removal of an image background, while preserving details of a furniture product in the foreground.\nThe Search and Recolor and Search and Replace tools target specific elements within images for modification. Search and Recolor changes object colors; for example, showing different colorways of a dress without new photoshoots. In the following illustration, Search and Recolor changes the color swatch on furniture.\nSearch and Replace can swap objects entirely, which is useful for updating seasonal elements in marketing materials or replacing products. The following is an application of Search and Replace for virtual try-on experiences.\nThe Inpaint tool intelligently modifies images by filling in or replacing specified areas with new content based on the content of a mask image. In contrast, the Outpaint tool generates content to fill an image in any direction. Compared to other automated or manual attempts to expand the content in an image, the Outpaint tool minimizes artifacts and signs that the original image has been edited.S\nUpscale: Enhance images for professional quality Three of the new Stability AI Image Services offer different approaches to image upscaling and enhancement, each tailored to specific use cases.\nThe Creative Upscale tool enhances resolution while adding AI-driven detail enhancement. This tool increases both pixel count and visual appeal, making it suitable for high-impact marketing materials. Standard product shots become billboard-ready images through intelligent detail addition and vibrancy enhancement.\nFor situations where maintaining the integrity of the original image is crucial, the Conservative Upscale tool offers a more nuanced approach. It increases resolution while preserving the original image’s details and character. This service can upscale images by 20 to 40 times, up to a 4-megapixel output image with minimal alteration to the original image.\nCompleting the trio of tools is Fast Upscale. This Upscale tool is faster than the previous two and is ideal for enhancing the quality of compressed images, making it suitable for social media posts and other applications.\nControl: Structural and stylistic precision This category of tools provides precise manipulation of image structure and style through three specialized tools.\nThe Sketch tool transforms sketch-style renderings into photorealistic concepts. Architecture firms might use this to convert conceptual drawings into realistic visualizations, and apparel brands to turn design sketches into product mockups. The tool helps accelerate the creative production process from initial concepts to final visual execution.\nIn this example, the Sketch tool transforms a building architecture drawing to help real estate developers visualize the concept against a cityscape.\nIn another example, the Sketch tool transforms a mannequin drawing into a photorealistic model shot.\nThe Structure tool maintains the structural elements of input images while allowing content modification. This tool helps preserve layouts, compositions, and spatial relationships while changing subjects or styles. Creative teams can use the Structure tool to recreate scenes with different subjects or render new characters while maintaining consistent framing.\nThe following example demonstrates the Structure tool transforming a workshop scene into a new scene while preserving the composition and spatial relationships.\nThe Style Guide and Style Transfer tools help marketing teams produce new images that align with brand style and guidelines. The Style Guide tool takes artistic styles and colors from a reference style image and generates new images based on text prompts.\nIn the following example, the Style Guide tool takes clues from a brand’s color palette and textures and generates new images matching brand identity.\nThe Style Transfer tool uses visual characteristics from reference images to transform existing images, while preserving the original composition. For example, a home decor retailer can transform product imagery from modern minimalist to traditional styles without new photography. Marketing teams could create seasonal variations by applying different visual styles to existing product catalogs.\nSolution overview To demonstrate Stability AI Image Services in Amazon Bedrock, let’s walk through an example using a Jupyter notebook found in the GitHub repo.\nPrerequisites To follow along, you must have the following prerequisites:\nAn AWS account. AWS credentials configured for creating and accessing Amazon Bedrock and Amazon SageMaker AI resources. An AWS Identity and Access Management (IAM) execution role for SageMaker AI, which has the AmazonSageMakerFullAccess and AmazonBedrockLimitedAccess AWS managed policies attached. For more details, see How to use SageMaker AI execution roles. A SageMaker notebook instance. Stability AI Image Services model access, which you can request through the Amazon Bedrock console. Refer to Access Amazon Bedrock foundation models for more details. Create a SageMaker AI notebook instance Complete the following steps to create a SageMaker AI notebook instance, which can be used to run the sample notebook:\nOn the SageMaker AI console, in the navigation pane, under Applications and IDEs, choose Notebooks. Choose Create notebook instance. For Notebook instance name, enter a name for your notebook instance (for example, ai-images-notebook-instance). For Notebook Instance type, choose ml.t2.medium. For Platform identifier, choose Amazon Linux 2. For IAM role, choose either an existing IAM role, which has the AmazonSageMakerFullAccess and AmazonBedrockLimitedAccess policies attached, or choose Create a new role. Note the name of the IAM role that you chose. Leave other settings as default and choose Create notebook instance. After a few minutes, SageMaker AI creates a notebook instance, and its status changes from Pending to InService.\nConfirm the IAM role for the notebook instance has the necessary permissions Complete the following steps to verify that the SageMaker AI execution role that you assigned to the notebook instance has the correct permissions:\nOn the IAM console, in the navigation pane, under Access management, choose Roles.\nIn the Roles search bar, enter the name of the SageMaker AI execution role that you used when creating the notebook instance.\nChoose the IAM role.\nUnder Permissions policies, verify that the AWS managed policies AmazonSageMakerFullAccess and AmazonBedrockLimitedAccess are present.\n(Optional) If either policy is missing, choose Add permissions, then choose Attach policies to attach the missing policy.\na. In the Other permissions policies search bar, enter the policy name.\nb. Select the policy, then chose Add permissions.\nRun the notebook Complete the following steps to run the notebook:\nOn the SageMaker AI console, in the navigation pane, under Applications and IDEs, choose Notebooks. Choose the newly created ai-images-notebook-instance notebook instance. Wait for the notebook to be in InService status. Choose the Open JupyterLab link to launch JupyterLab in a new browser tab. On the Git menu, choose Clone a Repository. Enter the URI https://github.com/aws-samples/stabilityai-sample-notebooks.git and select Include submodules and Download the repository. Choose Clone. On the File menu, choose Open from path. Enter the following: stabilityai-sample-notebooks/stability-ai-image-services/stability-ai-image-services-sample-notebook.ipynb Choose Open. When prompted, choose the kernel conda_python3, then choose Select. Run through each notebook cell to experience Stability AI Image Services in Amazon Bedrock. Clean up To avoid ongoing charges, stop the ai-images-notebook-instance SageMaker AI notebook instance that you created in this walkthrough:\nOn the SageMaker AI console, in the navigation pane, under Applications and IDEs, choose Notebooks. Choose the ai-images-notebook-instance SageMaker AI notebook instance that you created. Choose Actions, then choose Stop. After a few minutes, the notebook instance transitions from Stopping to Stopped status.\nChoose Actions, then Delete. After a few seconds, SageMaker AI deletes the notebook instance.\nFor more details, refer to Clean up Amazon SageMaker notebook instance resources.\nConclusion The availability of Stability AI Image Services in Amazon Bedrock is an exciting step forward for visual content creation and manipulation, with particularly time-saving implications for professional creative teams at enterprises.\nFor example, in media and entertainment, creators can rapidly enhance scenes and create special effects, and marketing teams can generate multiple campaign variations effortlessly. Retail and ecommerce businesses can streamline product photography and digital catalog creation, and gaming developers can prototype environments more efficiently. Architecture firms can visualize design concepts instantly, and educational institutions can create more engaging visual content.\nWith these tools, businesses of different sizes can produce professional-grade, highly engaging visual content with efficiency and creativity. These tools can streamline operations, reduce costs, and open new creative possibilities, helping brands tell their stories more effectively and engage customers in more compelling ways.\nTo get started, check out Stability AI models in Amazon Bedrock and the AWS Samples GitHub repo.\nAbout the authors Alex Gnibus is a Product Marketing Manager at Stability AI, connecting the dots between cutting-edge research breakthroughs and practical use cases. With experience spanning from creative agencies to deep enterprise tech, Alex brings both technical expertise and an understanding of the challenges that professional creative teams can solve with generative AI.\nIsha Dua is a Senior Solutions Architect based in the San Francisco Bay Area. She helps AWS Enterprise customers grow by understanding their goals and challenges and guiding them on how they can architect their applications in a cloud-based manner while making sure they are resilient and scalable. She’s passionate about machine learning technologies and environmental sustainability.\nFabio Branco is a Senior Customer Solutions Manager at Amazon Web Services (AWS) and strategic advisor helping customers achieve business transformation, drive innovation through generative AI and data solutions, and successfully navigate their cloud journeys. Prior to AWS, he held Product Management, Engineering, Consulting, and Technology Delivery roles across multiple Fortune 500 companies in industries, including retail and consumer goods, oil and gas, financial services, insurance, and aerospace and defense.\nSuleman Patel is a Senior Solutions Architect at Amazon Web Services (AWS), with a special focus on machine learning and modernization. With expertise in both business and technology, Suleman helps customers design and build solutions that tackle real-world business problems. When he’s not immersed in his work, Suleman loves exploring the outdoors, taking road trips, and cooking up delicious dishes in the kitchen.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"DeepSeek-V3.1 model now available in Amazon Bedrock by Channy Yun (윤석찬) on 18 SEP 2025 in Amazon Bedrock, Amazon Machine Learning, Announcements, Artificial Intelligence, Featured, Launch, News, Open Source, Serverless\n▶️ Listen to audio Voiced by Polly\nIn March, Amazon Web Services (AWS) became the first cloud service provider to deliver DeepSeek-R1 in a serverless way by launching it as a fully managed, generally available model in Amazon Bedrock. Since then, customers have used DeepSeek-R1\u0026rsquo;s capabilities through Amazon Bedrock to build generative AI applications, benefiting from Bedrock\u0026rsquo;s robust guardrails and comprehensive tooling for safe AI deployment.\nToday, I am excited to announce DeepSeek-V3.1 is now available as a fully managed foundation model in Amazon Bedrock. DeepSeek-V3.1 is a hybrid open weight model that switches between thinking mode (chain-of-thought reasoning) for detailed step-by-step analysis and non-thinking mode (direct answers) for faster responses.\nAccording to DeepSeek, the thinking mode of DeepSeek-V3.1 achieves comparable answer quality with better results, stronger multi-step reasoning for complex search tasks, and big gains in thinking efficiency compared with DeepSeek-R1-0528.\nBenchmarks DeepSeek-V3.1 DeepSeek-R1-0528 Browsecomp 30.0 8.9 Browsecomp_zh 49.2 35.7 HLE 29.8 24.8 xbench-DeepSearch 71.2 55.0 Frames 83.7 82.0 SimpleQA 93.4 92.3 Seal0 42.6 29.7 SWE-bench Verified 66.0 44.6 SWE-bench Multilingual 54.5 30.5 Terminal-Bench 31.3 5.7 (c) https://api-docs.deepseek.com/news/news250821\nDeepSeek-V3.1 model performance in tool usage and agent tasks has significantly improved through post-training optimization compared to previous DeepSeek models. DeepSeek-V3.1 also supports over 100 languages with near-native proficiency, including significantly improved capability in low-resource languages lacking large monolingual or parallel corpora. You can build global applications to deliver enhanced accuracy and reduced hallucinations compared to previous DeepSeek models, while maintaining visibility into its decision-making process.\nHere are your key use cases using this model:\nCode generation – DeepSeek-V3.1 excels in coding tasks with improvements in software engineering benchmarks and code agent capabilities, making it ideal for automated code generation, debugging, and software engineering workflows. It performs well on coding benchmarks while delivering high-quality results efficiently. Agentic AI tools – The model features enhanced tool calling through post-training optimization, making it strong in tool usage and agentic workflows. It supports structured tool calling, code agents, and search agents, positioning it as a solid choice for building autonomous AI systems. Enterprise applications – DeepSeek models are integrated into various chat platforms and productivity tools, enhancing user interactions and supporting customer service workflows. The model\u0026rsquo;s multilingual capabilities and cultural sensitivity make it suitable for global enterprise applications. As I mentioned in my previous post, when implementing publicly available models, give careful consideration to data privacy requirements when implementing in your production environments, check for bias in output, and monitor your results in terms of data security, responsible AI, and model evaluation.\nYou can access the enterprise-grade security features of Amazon Bedrock and implement safeguards customized to your application requirements and responsible AI policies with Amazon Bedrock Guardrails. You can also evaluate and compare models to identify the optimal model for your use cases by using Amazon Bedrock model evaluation tools.\nGet started with the DeepSeek-V3.1 model in Amazon Bedrock To test the DeepSeek-V3.1 model in Amazon Bedrock console, choose Chat/Text under Playgrounds in the left menu pane. Then choose Select model in the upper left, and select DeepSeek as the category and DeepSeek-V3.1 as the model. Then choose Apply.\nUsing the selected DeepSeek-V3.1 model, I run the following prompt example about technical architecture decision:\nOutline the high-level architecture for a scalable URL shortener service like bit.ly. Discuss key components like API design, database choice (SQL vs. NoSQL), how the redirect mechanism works, and how you would generate unique short codes.\nYou can turn the thinking on and off by toggling Model reasoning mode to generate a response\u0026rsquo;s chain of thought prior to the final conclusion.\nYou can also access the model using the AWS Command Line Interface (AWS CLI) and AWS SDK. This model supports both the InvokeModel and Converse API. You can check out a broad range of code examples for multiple use cases and a variety of programming languages.\nTo learn more, visit DeepSeek model inference parameters and responses in the AWS documentation.\nNow available DeepSeek-V3.1 is now available in the US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Mumbai), Europe (London), and Europe (Stockholm) AWS Regions. Check the full Region list for future updates. To learn more, check out the DeepSeek in Amazon Bedrock product page and the Amazon Bedrock pricing page.\nGive the DeepSeek-V3.1 model a try in the Amazon Bedrock console today and send feedback to AWS re:Post for Amazon Bedrock or through your usual AWS Support contacts.\n— Channy\nUpdated on September 19, 2025 — Removed the model access section. Amazon Bedrock will simplify access to all serverless foundation models, and any new models, by automatically enabling them for every AWS account, eliminating the need to manually activate access through the Bedrock console. The model access page will be retired in October 8, 2025. Account administrators retain full control over model access through AWS IAM policies and Service Control Policies (SCPs) to restrict model access as needed.\nChanny Yun (윤석찬)\nChanny is a Lead Blogger of AWS News Blog and Principal Developer Advocate for AWS Cloud. As an open web enthusiast and blogger at heart, he loves community-driven learning and sharing of technology.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Qwen models are now available in Amazon Bedrock by Danilo Poccia on 18 SEP 2025 in Amazon Bedrock, Amazon Machine Learning, Announcements, Artificial Intelligence, Featured, Launch, News, Open Source, Serverless\n▶️ Listen to audio Voiced by Polly\nToday we are adding Qwen models from Alibaba in Amazon Bedrock. With this launch, Amazon Bedrock continues to expand model choice by adding access to Qwen3 open weight foundation models (FMs) in a full managed, serverless way. This release includes four models: Qwen3-Coder-480B-A35B-Instruct, Qwen3-Coder-30B-A3B-Instruct, Qwen3-235B-A22B-Instruct-2507, and Qwen3-32B (Dense). Together, these models feature both mixture-of-experts (MoE) and dense architectures, providing flexible options for different application requirements.\nAmazon Bedrock provides access to industry-leading FMs through a unified API without requiring infrastructure management. You can access models from multiple model providers, integrate models into your applications, and scale usage based on workload requirements. With Amazon Bedrock, customer data is never used to train the underlying models. With the addition of Qwen3 models, Amazon Bedrock offers even more options for use cases like:\nCode generation and repository analysis with extended context understanding Building agentic workflows that orchestrate multiple tools and APIs for business automation Balancing AI costs and performance using hybrid thinking modes for adaptive reasoning Qwen3 models in Amazon Bedrock These four Qwen3 models are now available in Amazon Bedrock, each optimized for different performance and cost requirements:\nQwen3-Coder-480B-A35B-Instruct – This is a mixture-of-experts (MoE) model with 480B total parameters and 35B active parameters. It\u0026rsquo;s optimized for coding and agentic tasks and achieves strong results in benchmarks such as agentic coding, browser use, and tool use. These capabilities make it suitable for repository-scale code analysis and multistep workflow automation. Qwen3-Coder-30B-A3B-Instruct – This is a MoE model with 30B total parameters and 3B active parameters. Specifically optimized for coding tasks and instruction-following scenarios, this model demonstrates strong performance in code generation, analysis, and debugging across multiple programming languages. Qwen3-235B-A22B-Instruct-2507 – This is an instruction-tuned MoE model with 235B total parameters and 22B active parameters. It delivers competitive performance across coding, math, and general reasoning tasks, balancing capability with efficiency. Qwen3-32B (Dense) – This is a dense model with 32B parameters. It is suitable for real-time or resource-constrained environments such as mobile devices and edge computing deployments where consistent performance is critical. Architectural and functional features in Qwen3 The Qwen3 models introduce several architectural and functional features:\nMoE compared with dense architectures – MoE models such as Qwen3-Coder-480B-A35B, Qwen3-Coder-30B-A3B-Instruct, and Qwen3-235B-A22B-Instruct-2507, activate only part of the parameters for each request, providing high performance with efficient inference. The dense Qwen3-32B activates all parameters, offering more consistent and predictable performance.\nAgentic capabilities – Qwen3 models can handle multi-step reasoning and structured planning in one model invocation. They can generate outputs that call external tools or APIs when integrated into an agent framework. The models also maintain extended context across long sessions. In addition, they support tool calling to allow standardized communication with external environments.\nHybrid thinking modes – Qwen3 introduces a hybrid approach to problem-solving, which supports two modes: thinking and non-thinking. The thinking mode applies step-by-step reasoning before delivering the final answer. This is ideal for complex problems that require deeper thought. Whereas the non-thinking mode provides fast and near-instant responses for less complex tasks where speed is more important than depth. This helps developers manage performance and cost trade-offs more effectively.\nLong-context handling – The Qwen3-Coder models support extended context windows, with up to 256K tokens natively and up to 1 million tokens with extrapolation methods. This allows the model to process entire repositories, large technical documents, or long conversational histories within a single task.\nWhen to use each model The four Qwen3 models serve distinct use cases. Qwen3-Coder-480B-A35B-Instruct is designed for complex software engineering scenarios. It\u0026rsquo;s suited for advanced code generation, long-context processing such as repository-level analysis, and integration with external tools. Qwen3-Coder-30B-A3B-Instruct is particularly effective for tasks such as code completion, refactoring, and answering programming-related queries. If you need versatile performance across multiple domains, Qwen3-235B-A22B-Instruct-2507 offers a balance, delivering strong general-purpose reasoning and instruction-following capabilities while leveraging the efficiency advantages of its MoE architecture. Qwen3-32B (Dense) is appropriate for scenarios where consistent performance, low latency, and cost optimization are important.\nGetting started with Qwen models in Amazon Bedrock To begin using Qwen models, in the Amazon Bedrock console, I can use the Chat/Text Playground section of the navigation pane to quickly test the new Qwen models with a few prompts.\nTo integrate Qwen3 models into my applications, I can use any AWS SDKs. The AWS SDKs include access to the Amazon Bedrock InvokeModel and Converse API. I can also use these model with any agentic framework that supports Amazon Bedrock and deploy the agents using Amazon Bedrock AgentCore. For example, here\u0026rsquo;s the Python code of a simple agent with tool access built using Strands Agents:\nfrom strands import Agent from strands_tools import calculator agent = Agent( model=\u0026#34;qwen.qwen3-coder-480b-a35b-v1:0\u0026#34;, tools=[calculator] ) agent(\u0026#34;Tell me the square root of 42 ^ 9\u0026#34;) with open(\u0026#34;function.py\u0026#34;, \u0026#39;r\u0026#39;) as f: my_function_code = f.read() agent(f\u0026#34;Help me optimize this Python function for better performance:\\n\\n{my_function_code}\u0026#34;) Now available Qwen models are available today in the following AWS Regions:\nQwen3-Coder-480B-A35B-Instruct is available in the US West (Oregon), Asia Pacific (Mumbai, Tokyo), and Europe (London, Stockholm) Regions.\nQwen3-Coder-30B-A3B-Instruct, Qwen3-235B-A22B-Instruct-2507, and Qwen3-32B are available in the US East (N. Virginia), US West (Oregon), Asia Pacific (Mumbai, Tokyo), Europe (Ireland, London, Milan, Stockholm), and South America (São Paulo) Regions.\nCheck the full Region list for future updates. You can start testing and building immediately without infrastructure setup or capacity planning. To learn more, visit the Qwen in Amazon Bedrock product page and the Amazon Bedrock pricing page.\nTry Qwen models on the Amazon Bedrock console now, and offer feedback through AWS re:Post for Amazon Bedrock or your typical AWS Support channels.\n— Danilo\nUpdated on September 18, 2025 — Removed the model access section. Amazon Bedrock will simplify access to all serverless foundation models, and any new models, by automatically enabling them for every AWS account, eliminating the need to manually activate access through the Bedrock console. The model access page will be retired in October 8, 2025. Account administrators retain full control over model access through AWS IAM policies and Service Control Policies (SCPs) to restrict model access as needed.\nDanilo Poccia\nDanilo works with startups and companies of any size to support their innovation. In his role as Chief Evangelist (EMEA) at Amazon Web Services, he leverages his experience to help people bring their ideas to life, focusing on serverless architectures and event-driven programming, and on the technical and business impact of machine learning and edge computing. He is the author of AWS Lambda in Action from Manning.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Summary Report: “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders” Event Objectives Highlight Vietnam–US tech cooperation and cloud-driven economic growth Showcase AI and blockchain innovations shaping Vietnam’s digital future Present AWS initiatives supporting builders, education, and workforce transformation Emphasize culture, skills, and responsible AI as foundations for sustainable innovation Speakers US Ambassador – Insights on 30 years of US–Vietnam cooperation through technology Eric Elock – CEO, AWS VN–Laos–Cambodia–Myanmar Chloe Phung – CEO, U2U Erick – CEO, AWS Jaime Valless – AWS Leadership Key Highlights Strengthening Vietnam–US Collaboration The US Ambassador emphasized the strong relationship between Vietnam and the United States. Highlighted 30 years of bilateral growth enabled through US technology companies such as AWS. Vision from Eric Elock (AWS Regional CEO) Banks play a major role in supporting IT modernization. U2U ecosystem: Enables interaction between businesses and users through blockchain. Insights from Chloe Phung (CEO U2U) Two years ago, partners told them their idea was impossible. Today, Vietnam is not only catching up with global revolutions but also shaping them. AI Shaping Vietnam’s Future Education: 60% of Vietnamese students use EdTech apps; AI helps break language barriers and creates engaging learning experiences. Economy: Over 765 AI startups, 2nd in ASEAN. Contributes $120–130B GDP impact. Social impact: More accessible and affordable healthcare. Doctors at Hospital 10A reduced exam time to 5 minutes per case using AI. AI improves traffic systems, energy efficiency, and even protects coastlines. Real-world Tech Momentum Nubila: AI-powered weather-related capabilities. Staex: Successfully deployed 1,000+ IoT devices across Asia and Europe. GenAI reduces hours of documentation searching; developers complete projects in hours/days instead of weeks. GenAI simplifies blockchain for beginners, improving accessibility. AI improves decision-making for businesses, policy makers, and daily workflows. Special thanks to AWS for enabling breakthroughs. Remarks from AWS CEO Erick AWS has trained 100,000+ builders in Vietnam. Expanding access to cloud services across the country. FJC program: A 6-month initiative providing secure job opportunities. Emphasized AWS culture as a key differentiator. Insights from Jaime Valless Reframed the message with focus on culture and skills. \u0026ldquo;We stand in a unique moment in history where AI will transform everything.\u0026rdquo; It’s not only about technology — skills, people, culture, and responsibility matter. Humanity is now in the best position to build a better, sustainable future. Shift from training models to secure, responsible inference. AWS provides access to secure, diverse models. Example: Nearmap uses AI to help customers make faster decisions. Let technology handle the boring tasks; humans focus on creativity and thinking. At the end, Erik delivered a message of happiness, health, and success.\nAI-Driven Development Lifecycle Even when giving AI more tasks, control must remain human:\nConfirm Clarify Review Three phases:\nInception: Idea generation, defining tasks Construction: Domain modeling, code generation, testing, IaC deployment Operation: Complete deployment, incident management Security for AI Applications Managing AI risks:\nAI governance policies AI hallucination mitigation Data poisoning prevention Prompt security Access control and permissioning Architectural safeguards:\nHuman-in-the-loop Secured prompts Supply-chain verification Data evaluation RAG systems for accuracy Amazon Q / QuickSight Simplifies dashboard creation Enables fast analytics with minimal setup Key Takeaways Design \u0026amp; Innovation Mindset Vietnam is actively shaping global AI innovation. Culture, skills, and responsibility are critical. GenAI accelerates development and lowers entry barriers. Technical Impact AI improves healthcare, education, economy, and logistics. Secure and responsible AI is essential. AWS tools empower builders with efficiency and scalability. Real-World Inspiration Success stories (U2U, Staex, Nearmap) show Vietnam’s rising influence. AI–Blockchain synergy is driving new business ecosystems. Event Experience Attending Vietnam Cloud Day 2025 provided deep insight into how AI, cloud, and blockchain are shaping Vietnam’s technological future.\n1. Learning from Global Experts The US Ambassador, AWS CEOs, and industry leaders shared high-level perspectives 2. Real-world Case Studies AI in healthcare, education, transportation, and energy Large-scale IoT and blockchain deployment in Asia and Europe 3. Human-centered Innovation Culture and skill development are at the core of sustainable innovation AI allows humans to focus on creativity instead of repetitive tasks Some Event Photos "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.1-workshop-overview/","title":"Introduction","tags":[],"description":"","content":"ONLINE PLATFORM FOR TRACKING AND FORECASTING HURRICANE TRAJECTORY In this workshop, we will present how we created an online platform that allows internet users to freely check, track, and even predict the path of ongoing storms in the West Pacific region. This platform helps users better prepare for upcoming natural disasters and reduces the potential damage they may cause.\nThe platform provides two main functionalities:\nShowing Recent Storms – Allows users to view the path, intensity, wind speed, and other characteristics of recent storms in the West Pacific region. Predicting Hurricane Trajectories – Allows users to input past storm locations (latitude and longitude; at least 9 data points) to obtain predictions about the storm’s near-future movement, intensity changes, and potential path. Following the flow of this workshop, we will discuss the datasets, pre-processing steps, model-training pipeline, and the process of building the online platform using AWS services. We will also demonstrate our proposed augmentation techniques—Stepwise Temporal Fading Augmentation (STFA) and Plausible Geodesic Bearing Augmentation (PGBA)—along with the use of physics-informed machine learning. These approaches enhance the realism of the training data and significantly improve prediction accuracy for storm trajectories, lifetime estimates, and total travel distance.\nFigure 1 : Model pipeline Once the model-training process is completed, we move to building the online platform using a serverless architecture. This architecture is cost-efficient, scalable, and easy to maintain/deploy—making it an ideal choice for our project. Below are the main AWS services used:\nAWS Lambda – Executes the ML models and handles backend logic Amazon S3 – Stores static files, trained models, and storm data Amazon API Gateway – Routes user requests to the appropriate Lambda functions depending on whether they are viewing recent storms or running predictions Amazon CloudFront – Speeds up content delivery through edge locations AWS Secrets Manager – Stores API keys and other sensitive information … – Additional supporting services as needed Figure 2 : Platform Architecture "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Nguyen Duy Son\nPhone Number: 0818400453\nEmail: yama27032005@gmail.com\nUniversity: FPTU - HCM\nMajor: Artificial Intelligent\nClass: AWS082025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 09/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations - Getting familiar with the other members of my group - Created an AWS account 09/08/2025 09/08/2025 https://000001.awsstudygroup.com/ 3 - Learn how to manage costs with AWS Budget + Create budget by template + Create cost budget + Create usage budget + Learn how to create RI budget + How to create saving plans budget - How to use AWS Support + AWS Support Packages + Types of Support Requests and how to change support package + How to create a support request and select its severity 09/09/2025 09/09/2025 https://000007.awsstudygroup.com/ https://000009.awsstudygroup.com/ 4 - Earned 100 credits through completing activities on the AWS console: + Launch an instance using EC2 + Create an Amazon RDS Database + Create a web app using AWS Lambda + Use a foundation model in the Amazon Bedrock playground + Set up a cost budget using AWS Budgets 09/10/2025 09/10/2025 5 - Learn about access management with AWS Identity and Access Management (IAM): + Create IAM Group and IAM User + Create IAM Role and IAM User + How to switch role 09/11/2025 09/11/2025 https://000002.awsstudygroup.com/ 6 - Learn about Firewall in VPC + Security Group + Network ACLs + VPC resource map - Learn how to build a complete Amazon VPC enviroment + Create VPC + Create Subnet + Create Internet Gateway + Create Route table + Create Secuirty Group + Enable VPC Flow Logs 09/12/2025 09/13/2025 https://000003.awsstudygroup.com/ Week 1 Achievements: Successfully created and configured an AWS Free Tier account. Became familiar with the AWS Management Console and learned how to find, access, and use services via the web interface. Gained proficiency in AWS Cost Management and Support: Learned to create and manage various AWS Budgets (Cost, Usage, RI, Savings Plans) to maintain financial control. Understood the different AWS Support packages and how to create and manage support requests based on severity. Acquired hands-on experience with core AWS services through practical console activities: Launched a virtual server using Amazon EC2. Created and configured a relational database with Amazon RDS. Built a serverless web application using AWS Lambda. Experimented with Generative AI using a foundation model in Amazon Bedrock. Applied cost control knowledge by setting up a budget with AWS Budgets. Established a foundation in AWS security and access management using IAM: Learned and applied the principles of granting least privilege access. Gained practical experience in creating and managing IAM Users, Groups, and Roles. Understood the process of switching roles to assume different permissions. Built and secured a custom network environment with Amazon VPC: Designed and implemented a complete, functional VPC including subnets, route tables, and an internet gateway. Learned to secure the VPC using Security Groups (stateful firewall) and Network ACLs (stateless firewall). Enabled operational visibility by configuring VPC Flow Logs to monitor network traffic. "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/","title":"Worklog","tags":[],"description":"","content":"Week 1: Gained foundational AWS skills by creating my AWS account, learning cost management and support, practicing IAM setup, completing hands-on EC2/RDS/Lambda/Bedrock tasks, and building a full VPC environment.\nWeek 2: Deployed and managed EC2 instances, configured NAT Gateway and monitoring, set up a full Site-to-Site VPN environment, troubleshot VPN tunnels, and attended Vietnam Cloud Day 2025.\nWeek 3: Strengthened EC2 administration, deployed applications on Amazon Linux 2, created custom AMIs, practiced backup/recovery, and implemented IAM policies for cost and usage governance.\nWeek 4: Configured IAM roles for application access, worked in Cloud9, built an S3 static website, accelerated it with CloudFront, and explored advanced S3 features.\nWeek 5: Built full-stack infrastructure with EC2 and RDS, deployed WordPress on Lightsail, prepared datasets and documentation for the group project, and completed technical translations for AWS Bedrock updates.\nWeek 6: Deployed business apps on Lightsail, built and managed containers with Docker, and implemented full Auto Scaling infrastructure with load balancers for high availability.\nWeek 7: Mastered AWS CloudWatch monitoring, implemented hybrid DNS with Route 53 Resolver and Active Directory, and strengthened AWS CLI proficiency for automating cloud operations.\nWeek 8: Mastered DynamoDB operations across console, CLI, and SDK; integrated Python with DynamoDB; and completed the OJT Midterm Exam with strong coverage of AWS architecture principles.\nWeek 9: Mastered ElastiCache cluster operations, implemented advanced VPC networking with VPN, TGW, endpoints, and peering, and strengthened DNS and connectivity management across AWS services.\nWeek 10: Mastered CloudFront and Lambda@Edge for CDN and edge computing, deployed Amazon WorkSpaces virtual desktops, and participated in the AWS Cloud Mastery Series #1 event.\nWeek 11: Implemented AWS Managed Microsoft AD, built a highly available WordPress architecture with autoscaling and load balancing, and participated in community and game day events.\nWeek 12: Completed VM migrations via VM Import/Export, performed database migrations with DMS and SCT, translated team workshop files, and participated in AWS Cloud Mastery Series #3.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Summary Report: “AWS Cloud Mastery Series #1” Event Objectives Provide practical insights into AWS Bedrock and modern AI development Introduce foundational model concepts and prompt engineering best practices Demonstrate RAG workflows and embedding-based search Present AWS AI services commonly used in real-world applications Explain AgentCore and production-ready GenAI system architecture Speakers Lam Tuan Kiet – Senior DevOps Engineer, FPT Software Dang Hoang Hieu Nghi – AI Engineer, Reonova Cloud Dinh Le Hoang Anh – Cloud Engineer Trainee, FCJ Kha – Shared advice on building product-oriented projects for CVs FPT Representative – Spoke on companies using AI on cloud for optimization and cost savings Key Highlights Foundation Models \u0026amp; Industry Direction Traditional ML models handle one task and require labeled data. Foundation models in Generative AI are trained on massive unlabeled datasets, enabling versatile multi-task capabilities. Bedrock now integrates models like OpenAI and DeepSeek. Companies increasingly build AI-driven products on cloud platforms to reduce operational cost. Insights from Lam Tuan Kiet Explained the evolution from traditional ML → foundation models. Emphasized the importance of prompt engineering for high-quality outputs. Demonstrated how Bedrock simplifies access to advanced models without complex DevOps. Highlighted that building AI products requires skill, iteration, and responsible deployment. Promp Engineering Zero-shot prompting – Minimal context; results may be simple or vague. Few-shot prompting – Provide examples inside the prompt for clearer responses. Chain-of-thought prompting – Guide the model with reasoning steps for improved accuracy and detail. Retrieval-Augmented Generation (RAG) The system retrieves relevant information from a data source. It automatically combines user prompts with retrieved context. Produces more accurate and relevant responses. Embeddings Text is converted into vectors representing meaning. Similar meanings cluster together in vector space. AWS Titan Text Embeddings support over 100 languages. AWS AI Services Rekognition – Image/video object detection Translate – Automatic translation Textract – Extracts text and layout structures Transcribe – Speech-to-text with speaker recognition Polly – Text-to-speech Comprehend – NLP, entity extraction, relationship understanding Kendra – Intelligent document search Lookout Family – Anomaly detection for metrics, equipment, and vision Personalize – Recommendation systems Pipecat – AI agent pipeline framework Developers can use these services directly via APIs.\nAmazon Bedrock AgentCore Allows building AI applications without heavy DevOps and infrastructure management. Supports modern frameworks like LangGraph and LangChain. Designed to help teams move from prototype → production efficiently. Key Mechanisms\nRuntime Memory Identity Gateway Code Interpreter Browser Tool Observability Key Takeaways AI Development Mindset Real-world product creation is more valuable than passing academic requirements. Foundation models allow rapid experimentation and deployment. Prompt engineering significantly affects output quality. Technical Impact RAG enhances accuracy by grounding responses in real data. Embeddings improve semantic search and information retrieval. AWS AI services cover end-to-end workflows—from speech to vision to NLP. Real-World Relevance Companies increasingly adopt cloud-based AI to reduce costs and accelerate product development. Skills in prompt engineering, embeddings, and Bedrock services are becoming essential. Event Experience Attending the AWS Cloud Mastery Series #1 provided practical understanding of how modern AI systems operate on AWS.\n1. Direct Learning from Engineers Speakers shared real working experience from DevOps, AI, and cloud engineering roles. 2. Hands-on Technical Knowledge Examples of prompt engineering RAG demonstrations Use cases for each AWS AI service 3. Building for the Future Encouragement to build real products Cloud + AI skills are becoming core requirements Strong focus on practical deployment rather than theory Some Event Photos "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Master EC2 instance deployment and management Implement AWS networking and VPN connectivity Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn how to deploy Amazon EC2 instances + Create EC2 Server + Connect to EC2 instances + Create NAT Gateway + Used Reachability Analyzer + Create EC2 Instance Connect Endpoint + Secure Shell Access with AWS Systems Manager Session Manager + Implementing CloudWatch Monitoring and alerting for VPC Resources 09/15/2025 09/15/2025 https://000003.awsstudygroup.com/ 3 - Setting Up Site-to-Site VPN Connection in AWS + Create a VPN environment (VPC for VPN) + Create an EC2 instance to act as a Customer Gateway + Create a Virtual Private Gateway + Create a Customer Gateway 09/16/2025 09/16/2025 https://000003.awsstudygroup.com/ 4 - Configure VPN Connection + Create the VPN Connection + Perform Customer Gateway Configuration + Modify AWS VPN Tunnel settings + Review Alternative VPN Configurations 09/17/2025 09/17/2025 https://000003.awsstudygroup.com/ 5 - Participated in the Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders event 09/18/2025 09/18/2025 6 - VPN Troubleshooting \u0026amp; Advanced Configuration + Follow the VPN Troubleshooting Guide + Review the AWS Official VPN Troubleshooting Guide + VPN Connection using Strongswan with Transit Gateway 09/19/2025 09/19/2025 https://000003.awsstudygroup.com/ Week 2 Achievements: Successfully deployed and managed EC2 instances:\nCreated and launched EC2 servers using the AWS Management Console. Connected to instances via EC2 Instance Connect and Systems Manager Session Manager. Configured NAT Gateway for private subnet internet access. Used Reachability Analyzer to verify network connectivity. Implemented CloudWatch monitoring and alerting for VPC and EC2 resources. Set up and configured a Site-to-Site VPN connection:\nCreated a VPN environment including a dedicated VPC for VPN setup. Deployed an EC2 instance to act as a Customer Gateway. Created and attached a Virtual Private Gateway. Configured the VPN connection between AWS and the Customer Gateway. Modified VPN tunnel settings and reviewed alternative VPN configurations. Conducted VPN troubleshooting and advanced configuration:\nFollowed AWS VPN troubleshooting guides to identify and resolve common connectivity issues. Tested VPN connectivity using Strongswan integrated with AWS Transit Gateway. Verified secure communication between on-premises and AWS VPC resources. Improved understanding of AWS networking components and connectivity management, including EC2 networking, NAT Gateways, VPNs, and monitoring tools.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.2-data-preparation/","title":"Data Preparation","tags":[],"description":"","content":"Data Collection and Preparation Data is a critical component of our project. It not only powers the machine learning model but is also directly displayed to end users so they can monitor the most recent storms in the West Pacific region. Because of this dual purpose—model training and real-time visualization—we carefully investigated multiple reliable and authoritative sources before selecting a single dataset that met all of our requirements: Hurricane Data from NOAA.\nThe National Oceanic and Atmospheric Administration (NOAA) is a scientific agency under the U.S. Department of Commerce. NOAA provides highly accurate, research-grade environmental data, including global weather observations, satellite imagery, and tropical cyclone records. With decades of investment in advanced technologies such as geostationary satellites, ocean buoys, radar systems, and climate monitoring networks, NOAA is widely regarded as one of the most trustworthy providers of hurricane information in the world.\nFor this project, we specifically use data from the International Best Track Archive for Climate Stewardship (IBTrACS)—a NOAA-led project and the world’s most comprehensive tropical cyclone dataset. IBTrACS consolidates and unifies historical and modern storm-track data from multiple meteorological agencies (e.g., JTWC, JMA, CMA, NHC). By merging these sources into a single consistent format, it improves inter-agency comparability and ensures researchers worldwide have access to the best available storm-track information.\nThe version of the dataset we use contains 226,153 rows of hurricane observations. Each row includes a variety of valuable fields such as:\nsid – storm ID number – storm number basin / subbasin – regional classification nature – storm type (e.g., tropical storm, typhoon) iso_time – timestamp lat / lon – storm center coordinates … and many additional meteorological properties However, for our machine learning model, we focus only on four key columns: sid, iso_time, lat, and lon. These form the essential time-series trajectory used to predict storm movement.\nThe dataset spans storms recorded from 1870 up to 2025, filtered to include only those within the West Pacific region—our geographical focus. The raw dataset can be accessed publicly here: https://data.humdata.org/dataset/vnm-ibtracs-tropical-storm-tracks#\nCleaning and Physics-Informed Feature Engineering One advantage of IBTrACS is that it is already well-maintained and consistent. Only minimal preprocessing is needed, primarily the removal of missing values.\nAfter cleaning, we apply our first step of physics-informed machine learning—a technique that injects physical knowledge directly into the data pipeline. From the latitude–longitude coordinates, we compute two additional features using the Haversine formula:\nDistance between consecutive storm points Bearing (direction of movement) These features are physically meaningful: they represent real-world movement patterns instead of arbitrary transformations. They enrich the dataset by giving the model more context about the storm’s momentum and direction, thereby improving learning efficiency and prediction accuracy.\nFigure 1 : Dataset Description Data for Display The data used for display on the platform is different from the data used for training, even though both originate from NOAA. The training dataset is static and historical, but the display dataset must always reflect the current storm conditions.\nTo achieve this, we implement a scheduled AWS Lambda function that automatically retrieves the latest storm-track updates at the end of each day. This ensures that the platform always presents the most recent and accurate information to users.\nThe processed display data is stored as a JSON file in an Amazon S3 bucket. When a user accesses the website:\nThe frontend sends a request to API Gateway API Gateway triggers the appropriate Lambda function The Lambda function fetches the JSON from S3 The resulting data is returned to the user for visualization This pipeline guarantees real-time, serverless, cost-effective data delivery.\nThe live dataset used for display can be accessed here: https://ncics.org/ibtracs/\nFigure 2 : Web to crawl data "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/2-proposal/","title":"Proposal","tags":[],"description":"","content":"Proposal Document View Proposal Document\nONLINE PLATFORM FOR TRACKING AND FORECASTING HURRICANE TRAJECTORY Geodesic-Aware Deep Learning for Hurricane Trajectory Prediction: A Physics-Informed and Augmentation-Driven Approach 1. Executive Summary Time-series data serves as one of the most fundamental representations of information in modern scientific and industrial applications. It is essential for understanding dynamic processes such as economic trends, energy consumption patterns, and meteorological changes over time. In particular, weather forecasting heavily relies on time-series data to predict future atmospheric conditions, hurricane trajectories, and seasonal anomalies based on historical records.\nWith the rapid progress in deep learning and neural network research, our project aims to develop an advanced forecasting model capable of accurately predicting the future path, intensity, and total travel distance of moving storms within the next few days. The model’s predictions can support early warning systems, allowing authorities and residents in affected regions to take precautionary measures well before a hurricane reaches their area.\nTo move beyond the limitations of current technologies and existing research, this study introduces several novel techniques and algorithms, including two new augmentation methods for geodesic time-series data and a spatial encoding mechanism designed to enhance the predictive performance of convolutional computing. The final system will be integrated into a cloud-based, serverless architecture on AWS, ensuring scalability, high availability, and cost efficiency for real-time storm tracking and analysis.\nThe system architecture leverages several AWS services to form a fully managed data processing and deployment pipeline. AWS Lambda functions serve as the backbone for serverless computation, automatically triggered by Amazon EventBridge to crawl and process new storm data from open meteorological sources on a scheduled basis. Processed data is stored securely in Amazon S3, while AWS CodePipeline and CodeBuild automate the continuous integration and deployment of new model versions. The trained model is hosted and exposed via Amazon API Gateway, enabling lightweight, real-time inference requests from the online forecasting platform. All system activities are monitored through Amazon CloudWatch, providing operational visibility, fault detection, and performance metrics.\nThe first proposed method, Stepwise Temporal Fading Augmentation (STFA), is a new time-series augmentation framework that models the natural decline in the influence of past observations. Unlike traditional approaches based on random perturbation or noise injection, STFA applies fading weights to earlier time steps while preserving recent information. This process generates realistic and diverse synthetic sequences, improving model robustness and generalization. The technique will be evaluated on hurricane trajectory prediction tasks that rely on sequential latitude–longitude data.\nThe second proposed technique, Plausible Geodesic Bearing Augmentation (PGBA), introduces an augmentation strategy based on the feasible range of storm bearings and distances. By analyzing the geodesic bearing and distance between consecutive storm locations, PGBA defines a realistic motion boundary within which new synthetic trajectories are generated. This approach enhances the model’s capacity to capture natural spatial variability and directional uncertainty in storm movements.\nAdditionally, this study explores a spatial–temporal representation of time-series data, enabling the application of convolutional neural networks (CNNs) to capture both spatial and temporal dependencies. This representation leverages the strengths of convolutional computing to model local interactions across space and time. It will serve as a baseline for comparison with Temporal Convolutional Network (TCN) models trained using the proposed augmentation methods.\nTraditional neural networks, whether used for sequential or image-based modeling, primarily learn statistical patterns from data. However, in many real-world physical systems, such purely data-driven models may fail to adhere to natural constraints, such as gravitational or geodesic relationships. To address this limitation, we incorporate the principles of Physics-Informed Machine Learning (PIML) into our approach. Specifically, geodesic distance and bearing are derived from the latitude–longitude data and integrated into the model’s training process as physically meaningful features. Furthermore, we employ the Haversine formula—which computes the spherical distance between two points—as an auxiliary loss term, complementing standard error metrics such as MSE, RMSE, MAE, and MAPE.\nBy combining the proposed augmentation methods, physics-informed learning principles, and a serverless deep learning infrastructure powered by AWS services, this research aims to develop a scalable, robust, and accurate framework for hurricane trajectory forecasting. The resulting system not only advances the state of geodesic time-series modeling but also demonstrates the practicality of deploying AI-driven environmental prediction systems as resilient, cloud-native applications that enhance preparedness and safety in hurricane-prone regions.\n2. Problem Statement What’s the Problem? To develop a reliable platform for tracking and issuing alerts on future hurricane movements, it is essential to construct a machine learning model that is both accurate and capable of producing dependable predictions. The tracking component can be addressed by continuously collecting and updating data from publicly available meteorological sources. However, these datasets are often geographically constrained and contain redundant or incomplete information.\nIn contrast, the predictive component presents greater complexity. Achieving accurate time-series forecasting in this context typically faces two primary challenges: (1) the limited diversity and coverage of available data, and (2) the absence of physical grounding, which restricts the model’s ability to reflect the underlying geophysical dynamics of hurricane behavior.\nData scarcity: Many time-series forecasting tasks suffer from limited training data. While there are various augmentation methods, few approaches directly focus on the declining importance of past values over time.\nPhysics ignorance: Most neural networks only learn from raw data, without considering real-world physical constraints. In trajectory prediction tasks (e.g., hurricanes), this often leads to unrealistic predictions.\nWe aim to:\nDevelop a new time-series augmentation method (STFA and PGBA) to improve robustness and generalization. Incorporate physics-based constraints into model training, bridging the gap between data-driven learning and real-world dynamics. Testing the strength of convolution network (convol2D) in term of forecasting trajectory Creating an online platform that provide latest information about currents storm and precisely predictions on their trajectory The Solution A - Stepwise Temporal Fading Augumentation STFA generates synthetic time-series sequences by gradually reducing the influence of earlier values. Unlike random noise injection, it systematically applies stepwise fading multipliers across bands of older data.\nLet a univariate sequence be:\n$$ X = [x_0, x_1, \\ldots, x_{T-1}] $$\nwhere $T$ is the sequence length of $X$.\nParameters:\n$n$: number of most steps to remain unchanged. $S$: number of step-bands to apply fading, each band is assigned a constant multiplier. $L = T - n$: length of the fading region. $k = \\frac{L}{S}$: values per band. $I_b$: index set of the $b$-th band. \\[ I_b = {\\ {i \\mid L - b \\cdot k ;\\leq; i ;\\leq; L - (b-1)\\cdot k - 1} ,} \\]\nTransformation:\nWe denote the augmented series as:\n$$ X = [x_0, \\ldots, x_{T-1}] $$\nwith the transformation rules:\n$$ x_t = \\begin{cases} x_t, \u0026amp; t \\in {T-n, \\ldots, T-1}, \\\\ m_b , x_t, \u0026amp; t \\in I_b, \\\\ m_{S+1} , x_t, \u0026amp; t \u0026lt; \\min(I_S), \\end{cases} $$\nwhere multipliers $m_b \\in (0,1)$ decrease monotonically from recent to older bands.\nThis formulation preserves the fidelity of recent history while exerting stronger control on the long-range influence of the sequence. The augmentation forces the model to focus on robust patterns beyond the raw data, while increasing diversity according to the chosen parameters.\nB - Plausible Geodesic Bearing Augmentation The Plausible Geodesic Bearing Augmentation (PGBA) technique enhances the realism and control of synthetic trajectory generation in geospatial time-series forecasting tasks. Unlike conventional random perturbation methods, PGBA introduces stochasticity that remains plausible within the physical constraints of the underlying motion. The generated trajectories are derived from the geometric relationships of past observations rather than from purely random steps, resulting in smoother paths and meaningful variability in the training dataset. This technique apply on every four locations in a data sequence.\nPGBA serves as a complementary augmentation to STFA, enriching the diversity of training samples while preserving the original dynamical structure. Its objective is to create redundant yet physically consistent trajectories that capture potential variations in storm movements or similar geospatial phenomena.\nCore Mechanism\nConsider a storm trajectory represented by a sequence of $n$ ordered geographical points:\n$$ P = [P_1, P_2, \\ldots, P_n] $$\nWe split this sequence into small blocks of 4 points, with $P_i$ as the starting point of each block, defined by its latitude and longitude:\n$$ P_i = (\\phi_i, \\lambda_i) $$\nHere, $\\phi_i$ and $\\lambda_i$ denote latitude and longitude in radians, respectively.\nThe geodesic distance $d_i$ and bearing $\\theta_i$ between consecutive points $P_i$ and $P_{i+1}$ are defined as:\n$$ d_i = \\text{Distance}(P_i, P_{i+1}), \\qquad \\theta_i = \\text{Bearing}(P_i, P_{i+1}) $$\nTo introduce plausible variability, PGBA perturbs the bearing by adding a small, uniformly distributed random noise $\\epsilon_i$:\n$$ \\theta_i^{\\text{aug}} = \\theta_i + \\epsilon_i, \\qquad \\epsilon_i \\sim \\text{Uniform}(-\\delta, \\delta) $$\nwhere $\\delta$ is a tunable angular bound controlling the range of deviation.\nThe first two points always remain unchanged and are used to compute distance and bearing. The subsequent augmented point is then computed using the geodesic destination formula, keeping the distance constant while allowing the bearing to vary within the range of the random noise:\n$$ P_{i+2}^{\\text{aug}} = \\text{Destination}(P_i, d_i, \\theta_i^{\\text{aug}}) $$\nThis process preserves the inter-point distance $d_i$ while slightly perturbing the direction to produce physically plausible deviations.\nMulti-Step Smoothing and Correction\nTo enhance spatial smoothness and generate curvilinear trajectories, PGBA applies a secondary correction at every fourth point. Let $P_{i+3}^{\\text{aug}}$ denote the fourth point. It is recomputed such that its bearing $\\theta_{i+3}^{\\text{corr}}$ minimizes the deviation from the original point $P_{i+3}$:\n$$ \\theta_{i+3}^{\\text{corr}} = \\arg\\min_{\\theta}, \\text{Distance}\\Big( \\text{Destination}(P_{i+2}^{\\text{aug}}, d_{i+2}, \\theta),; P_{i+3} \\Big) $$\nThen, the corrected augmented point is obtained as:\n$$ P_{i+3}^{\\text{aug}} = \\text{Destination}(P_{i+2}^{\\text{aug}}, d_{i+2}, \\theta_{i+3}^{\\text{corr}}) $$\nThis step ensures smooth transitions across multiple points while maintaining physical plausibility.\nNote that the first two and last locations in every geodesic time-series sequence always remain unchanged.\nC - Physics-Informed Machine Learning Neural network models such as RNNs, CNNs, and Transformers do not require explicit formulas or task-specific rules to perform well, provided that they are trained with sufficient data. For example, in machine translation tasks such as German-to-English translation using an RNN, no explicit grammar rules are provided during training. Nevertheless, the model is capable of producing coherent translations, which demonstrates one of the major strengths of deep learning: the ability to learn complex patterns directly from data. In contrast, traditional approaches—such as early versions of rule-based translation systems (e.g., Google Translate prior to the 2000s)—relied heavily on grammar rules and dictionaries. While precise, such systems often lacked flexibility and failed when encountering words with multiple meanings or when handling context-dependent structures.\nInspired by this, our goal is to combine the strengths of deep learning with human-defined formulas in order to achieve better performance. Specificly in this geography field, we will try to add the benefit from Haversine formula into training for distance and beering calculation between two location on a sphere. These provide the model with additional structure and inductive bias, guiding learning beyond purely statistical correlations.\nHaversine Formula\nFor distance calculation\nThe Haversine formula is used to calculate the great-circle distance between two points on the surface of a sphere — that is, the shortest path over the Earth’s surface.\n$$ d = 2r , \\arcsin!\\left( \\sqrt{ \\sin^2!\\left(\\frac{\\Delta \\varphi}{2}\\right) + \\cos(\\varphi_1)\\cos(\\varphi_2) \\sin^2!\\left(\\frac{\\Delta \\lambda}{2}\\right) } \\right) $$\nWhere:\n$\\varphi_1, \\lambda_1$ and $\\varphi_2, \\lambda_2$ are the latitudes and longitudes of the two points (in radians). $\\Delta \\varphi = \\varphi_2 - \\varphi_1$ $\\Delta \\lambda = \\lambda_2 - \\lambda_1$ $r$ is the Earth’s radius (≈ 6,371 km). In our framework, instead of relying solely on standard loss functions such as MSE, RMSE, or MAPE, we propose using the Haversine formula for distance calculation as the primary loss function. As the model outputs latitude and longitude coordinates for the next hurricane location, the Haversine formula directly measures the distance between predicted and ground-truth points. A distance close to 0 indicates a highly accurate prediction, while a large distance signals a significant error.\nFor beering calculation\nThe Bearing calculation is dereived from Haversine Formula gives the direction from one geographic point to another along the great-circle path:\n$$\\theta = \\text{atan2}!\\left(\\sin(\\Delta \\lambda)\\cos(\\varphi_2),, \\cos(\\varphi_1)\\sin(\\varphi_2) - \\sin(\\varphi_1)\\cos(\\varphi_2)\\cos(\\Delta \\lambda)\\right)$$\nWhere:\n$(\\varphi_1, \\lambda_1)$ is the start point. $(\\varphi_2, \\lambda_2)$ is the end point. $\\Delta \\lambda$ is the difference in longitude. The result $\\theta$ represents the initial bearing (azimuth) measured clockwise from true north.\nIn our implementation, we fully exploit the use of Haversine Formula to compute two additional features — “distance” and “bearing” — which are appended to the dataset.\nThese features provide the model with richer information about hurricane trajectories while maintaining the core objective of predicting the next geographic location.\nD - Short overview of misconceptions in Common Approaches to Sequence Modeling In the field of sequence modeling within deep learning, recurrent architectures such as RNNs, LSTMs, and GRUs are often considered the default solutions. This perception has led many practitioners and researchers to overlook alternative architectures, particularly convolutional neural networks (CNNs), which are traditionally associated with image processing tasks. Textbooks and courses frequently categorize tasks such as language modeling, translation, or other sequential predictions as the domain of recurrent networks, while convolutional networks are presented primarily in the context of spatial data like images. As a result, the potential of CNNs for sequence modeling is frequently underestimated or ignored.\nConvolutional networks offer several intrinsic advantages that make them well-suited for sequential data. Their inherent parallelism allows for significantly faster training compared to strictly sequential models. Additionally, CNNs are highly effective at capturing local spatial and temporal dependencies, a property that can be leveraged in time-series forecasting and other sequential tasks. Despite these benefits, CNNs are often misunderstood as being unsuitable for sequences due to their lack of explicit memory mechanisms and the absence of intrinsic temporal ordering.\nIn our study, we focus on hurricane trajectory prediction, where the data consists of time-series records of latitude and longitude coordinates. We demonstrate that this type of sequential data can be effectively modeled using CNNs, leveraging their computational efficiency and ability to capture local spatiotemporal patterns. To facilitate this, we encode the locations into a 2D matrix representation, enabling the convolutional network to more effectively extract and learn patterns from the data. Each entry in the matrix corresponds to a “pixel” of an image, an approach we refer to as Trajectory-as-Image. Our methodology employs a standard CNN as a baseline, which is then compared with more specialized sequence models, including TCNs, LSTMs, and RNNs, while incorporating various data augmentation techniques, including two novel methods proposed in this work.\nThrough systematic experimentation and evaluation, we aim to challenge the prevailing notion that convolutional architectures are ill-suited for sequential data. By highlighting the effectiveness of CNNs in sequence modeling, we hope to broaden the perspective of researchers and practitioners, encouraging them to explore convolutional computing as a viable and competitive approach in time-series forecasting and other sequential prediction tasks.\nBenefits and Return on Investment Performance Boost: STFA + PGBA generates structured synthetic sequences that enhance model robustness, reduce overfitting, and improve generalization on unseen storm trajectories.\nPhysics Awareness: Incorporating geographical principles such as distance and bearing increases interpretability and ensures physically consistent predictions.\nNew Research Direction: Establishes two novel paradigms for time-series augmentation based on temporal relevance fading, expanding the methodological toolkit for sequence learning.\nScalability and Reusability: The combined STFA + PGBA + PIML framework can be extended to other sequential forecasting domains such as energy demand, traffic flow, and financial trends.\nOverall Impact: By improving predictive stability and interpretability while maintaining scalability, the proposed approach delivers both scientific value and practical return on computational investment.\n3. Solution Architecture The online platform provides users with up-to-date information on recent storms and a powerful tool for hurricane trajectory predictions. Visitors can either view recent storm data or run predictions using the ML models. The results are displayed interactively on a map, showing storm location, time, and predicted path.\nThe platform is built using a serverless AWS architecture to reduce operational costs while maintaining scalability and reliability. Frontend content is hosted on Amazon S3 and delivered globally via CloudFront, ensuring low-latency access. Users’ requests are routed through API Gateway to Lambda functions, which handle prediction computations and data retrieval. Pre-trained ML models and recent storm datasets are securely stored in S3, with weekly updates managed automatically by EventBridge-triggered crawler Lambdas. Sensitive API keys are stored in Secrets Manager, and system performance is monitored through CloudWatch logs and metrics. IAM enforces least-privilege access for all services.\nThe predictive models leverage the proposed STFA (Stepwise Temporal Fading Augmentation) and PGBA (Plausible Geodesic Bearing Augmentation) techniques. These methods generate realistic synthetic time-series trajectories, preserving temporal relevance and spatial consistency, which significantly improves the robustness and accuracy of the models. By integrating STFA and PGBA, the platform delivers more precise hurricane path predictions, helping users better understand storm behavior and make informed decisions.\nThis architecture enables a responsive, cost-efficient, and secure platform where users can visualize real-time storm information and explore hurricane trajectory forecasts with interactive maps, supported by advanced augmentation methods to boost model performance.\nFigure 1 : Model pipeline Figure 2 : Platform Architecture AWS Services Used Amazon S3: Stores static frontend files, pre-trained ML models, and recent storm data. AWS Lambda: Runs prediction models, fetches storm data, and executes web crawling automation. Amazon API Gateway: Handles frontend requests for predictions and storm data. Amazon CloudFront: Delivers static content globally with low latency. Amazon Route 53: Routes user traffic to CloudFront. Amazon EventBridge: Schedules weekly data crawling. AWS Secrets Manager: Stores external API keys securely. Amazon CloudWatch: Monitors Lambda logs, performance metrics, and system health. AWS IAM: Assigns least-privilege access to all services. Component Design Frontend Layer: Hosted on S3 and delivered through CloudFront. Backend Layer: Handles prediction and data retrieval using API Gateway and Lambda. Data Storage: ML models stored in S3, recent storm data updated weekly by the crawler. Automation: EventBridge triggers a weekly Crawler Lambda to fetch external storm data. Security \u0026amp; Monitoring: Secrets stored in Secrets Manager, metrics and logs collected via CloudWatch. 4. Technical Implementation Implementation Phases This project has three main parts: building the prediction pipeline, setting up data crawling, and deploying the web platform. Each part follows four phases:\nDesign Architecture: Plan AWS serverless stack, Lambda functions, S3 structure. (Weak 1) Estimate Costs: Use AWS Pricing Calculator to assess feasibility and adjust design (Weak 1-2). Optimize Architecture: Fine-tune Lambda memory, S3 usage, and caching to reduce cost (Weak 2-4). Develop, Test, Deploy: Implement Lambda functions, event scheduling, ML model integration, and web frontend with Next.js (Weak 4-8). Technical Requirements\nML Models: Pre-trained trajectory models stored in S3 (.h5/.pth), loaded by prediction Lambda. Storm Data: Weekly updated JSON files, stored in S3, used for frontend display and prediction validation. Serverless Infrastructure: Lambda for prediction, fetching, and crawling; API Gateway for frontend requests; CloudFront/S3 for content delivery. Security: Secrets Manager for API keys, IAM for least-privilege access. Monitoring: CloudWatch for logging and Lambda Insights metrics. 5. Timeline \u0026amp; Milestones Project Timeline\nPre-Internship (Weak 1): Planning, research on external weather APIs, and ML model preparation.\nInternship (Weak 1-8):\nWeak 1-2: AWS study, architecture design, and cost estimation. Weak 2-4: Optimize architecture, configure serverless workflow, and integrate ML models. Weak 4-8: Implement Lambda functions, set up frontend, test system, and deploy to production. Post-Launch: Continuous data collection and monitoring for up to 1 year.\n6. Budget Estimation Region: ap-southeast-1 (Singapore)\nThe estimated monthly costs for running the hurricane prediction platform on AWS are as follows:\nA. Frontend \u0026amp; Content Delivery\nAmazon S3 (Static Files): Hosts 5 GB of frontend files (HTML, CSS, JS) and handles 10 GB of data transfer per month. Cost ≈ $0.54/month. Amazon CloudFront: Handles 50 GB of data transfer and up to 1 million requests (within free tier). Cost ≈ $6.00/month. Amazon Route 53: 1 hosted zone and 1 million DNS queries per month. Cost ≈ $0.90/month. AWS Certificate Manager (ACM): Provides TLS certificate for secure HTTPS access. Free of charge. Subtotal for Frontend \u0026amp; CDN: ≈ $7.4/month\nB. Backend (API \u0026amp; ML Processing)\nAmazon API Gateway: Handles 1 million HTTP API requests per month, each request approximately 1 MB in size. Cost ≈ $2.5/month. Lambda (Storm Prediction): Predicts hurricane trajectories using ML models. Runs ~1,000 times per day with 512 MB memory allocated and 1 GB ephemeral storage. Each execution lasts ~5 seconds. Cost ≈ $2.54/month. Lambda (Fetch Recent Storm Data): Fetches storm data from S3 for the frontend. Runs ~20,000 times per day with 512 MB memory and 512 MB ephemeral storage for 1 second per execution. Cost ≈ $0.00/month (covered by free tier). Subtotal for Backend: ≈ $4.54/month\nC. Automation \u0026amp; Data Crawling\nAmazon EventBridge: Schedules weekly crawling of storm data (1 cron trigger per day). Free under AWS free tier. Lambda (Web Crawler): Fetches data from external APIs weekly. Uses 128 MB memory and 512 MB ephemeral storage, ~30 seconds per execution. Cost ≈ $0.00/month (free tier). AWS Secrets Manager: Stores 5 API keys for secure access to external weather services. Cost ≈ $2.00/month. Subtotal for Automation \u0026amp; Data Crawling: ≈ $2.0/month\nD. Monitoring \u0026amp; Logging\nAmazon CloudWatch Logs: Collects logs from all Lambda functions and delivers to S3 with 1-month retention. Approximately 2 GB of logs per month. Cost ≈ $0.57/month. CloudWatch Metrics (Lambda Insights): Monitors 8 metrics across Lambda functions. First 10 metrics are free, and only record for predictions and crawl data. Cost ≈ $0.00/month. Subtotal for Monitoring \u0026amp; Logging: ≈ $0.57/month\nE. Storage \u0026amp; Data Transfer\nS3 (Model Bucket): Stores ML models (~1 GB) and handles ~60,000 GET requests per month. Cost ≈ $0.05/month. S3 (Recent Storms Bucket): Stores recent storm data (~1 GB) with ~60,000 GET requests and 30 PUT requests per month. Cost ≈ $0.27/month. F. Tooling \u0026amp; Migration\nAWS CodePipeline and CodeBuild for 10 minutes fixing ≈ $0.90/month. Subtotal for Storage \u0026amp; Data Transfer: ≈ $0.32/month\nTotal Estimated Monthly Cost\nFrontend \u0026amp; CDN: $7.4 Backend (API + ML): $4.54 Automation (Crawler + Secrets): $2.0 Monitoring \u0026amp; Logging: $0.57 Storage \u0026amp; Data Transfer: $0.32 Tooling \u0026amp; Migration: $0.9 TOTAL ≈ $15.73/month\n7. Risk Assessment Risk Matrix\nNetwork Outages: Medium impact, medium probability. Data Source Unavailability: Medium impact, low probability. ML Model Errors: High impact, low probability. Cost Overruns: Medium impact, low probability. Mitigation Strategies\nNetwork: Cache recent storm data in S3 to allow frontend display during outages. Data Sources: Store historical storm data for fallback. ML Model: Regular model validation and testing. Cost: Monitor AWS usage and set budget alerts. Contingency Plans\nSwitch to manual updates if external API fails. Rollback to previous ML model using S3 versioning if new model fails. 8. Expected Outcomes Technical Improvements:\nReal-time hurricane trajectory predictions with visualized paths. Scalable serverless system capable of handling thousands of requests/day. Long-term Value:\nCentralized hurricane data for research and analysis. Framework reusable for other geospatial prediction tasks. Low monthly operational cost (\u0026lt; $20/month). "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"Blog 1 - Scale visual production using Stability AI Image Services in Amazon Bedrock This blog introduces how to use Stability AI Image Services within Amazon Bedrock to perform professional-grade visual editing at scale. It explains 13 tools across three categories — Edit, Upscale, and Control — enabling object removal, color replacement, style transfer, outpainting, sketch-to-image conversion, and high-quality upscaling. The article also provides a full walkthrough of setting up the environment using SageMaker AI, configuring IAM roles, running the sample notebook, and cleaning up resources. These tools help creative and marketing teams produce high-quality visual content faster, reduce costs, and unlock new creative possibilities.\nBlog 2 - DeepSeek-V3.1 model now available in Amazon Bedrock This blog announces that DeepSeek-V3.1 is now available as a fully managed foundation model in Amazon Bedrock. DeepSeek-V3.1 introduces a hybrid “thinking” and “non-thinking” mode, offering stronger multi-step reasoning, faster responses, and improved tool-use performance compared to DeepSeek-R1. The post highlights major gains across benchmarks, multilingual support for 100+ languages, and key use cases such as code generation, agentic tools, and enterprise applications. It also explains how to test the model inside the Bedrock console, toggle reasoning mode, run examples, and use the model via AWS CLI or SDKs. The model is available in multiple AWS Regions and automatically enabled for all AWS accounts starting October 2025.\nBlog 3 - Qwen models are now available in Amazon Bedrock This blog announces the arrival of Qwen3 models from Alibaba in Amazon Bedrock, expanding the platform’s selection of open-weight, fully managed foundation models. The release includes four models—two coding-focused MoE models, one general-purpose MoE model, and one dense model—each optimized for different performance and cost requirements. The article highlights key capabilities such as multi-step reasoning, tool calling, hybrid reasoning modes (thinking vs. non-thinking), and long-context handling up to 1M tokens. It also explains when to use each model based on workload needs, how to test them in the Bedrock console, and how to integrate them using AWS SDKs or agent frameworks like AgentCore. The Qwen3 models are available across multiple AWS Regions and automatically enabled for all AWS accounts starting October 2025.\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Master EC2 instance deployment and management Deploy applications on Amazon Linux 2 Implement cost governance with IAM policies Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get started on learning about Amazon EC2 - Preparation for EC2 Deployment * Create a Linux VPC * Create VPC for Windows Instance * Create a Security Group for Linux Instance * Create a Security Group for Windows Instance 09/22/2025 09/22/2025 https://000004.awsstudygroup.com/ 3 - Launch and Connect to EC2 Instances * Launch Microsoft Windows Server 2022 Instance * Connect from Computer to Microsoft Windows Server 2022 Instance * Launch Amazon Linux Instance * Connect to Amazon Linux Instance 09/23/2025 09/24/2025 https://000004.awsstudygroup.com/ 4 - Practice Amazon EC2 Basics: + Modify EC2 Instance Type + Create and Manage EBS Snapshots + Create Custom AMI + Launch an Instance from a Custom AMI + Recovering Access to Windows/Linux Instances + Remote Desktop to EC2-Ubuntu 08/24/2025 08/25/2025 https://000004.awsstudygroup.com/ 5 - Deploy User Management Application: + Install LAMP Web Server on Amazon Linux 2 + Install Node.js on Amazon Linux 2 + Deploy application on Linux Instance 08/25/2025 08/25/2025 https://000004.awsstudygroup.com/ 6 - Cost \u0026amp; Usage Governance with IAM: + Restricting Service Usage by AWS Region + Limiting EC2 Usage by Instance Family + Controlling EC2 Deployment by Instance Type + Managing EBS Volume Storage Types + Limit permission to delete resources by Company\u0026rsquo;s IP address + Limit permission to delete resources by time period 08/26/2025 08/28/2025 https://000004.awsstudygroup.com/ Week 3 Achievements: Mastered Amazon EC2 fundamentals including:\nInstance types and modification EBS snapshots creation and management Custom AMI creation and deployment Access recovery for Windows and Linux instances Remote desktop connections to EC2 instances Successfully deployed a User Management Application on Amazon Linux 2:\nInstalled and configured LAMP web server Set up and tested database server Installed Node.js runtime environment Deployed and managed application on Linux instance Implemented Cost \u0026amp; Usage Governance with IAM:\nRestricted service usage by AWS region Limited EC2 usage by instance family and type Managed EBS volume storage types Configured resource deletion permissions by IP address and time period Gained hands-on experience with AWS networking:\nCreated and configured VPCs for Linux and Windows instances Set up security groups for different instance types Launched and connected to both Windows Server 2022 and Amazon Linux instances Developed comprehensive EC2 management skills:\nInstance deployment and configuration Connection methods and remote access Resource monitoring and optimization Backup and recovery strategies "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.3-ml-model/","title":"Machine Learning Model","tags":[],"description":"","content":"MODEL TRAINING PROCESS This work presents the development of a predictive model designed to estimate a storm’s next geographical position using historical observational data from its previous path. To put it simply, we use a sequence of past latitude and longitude values to predict the next latitude and longitude in the future.\nFeature Engineering After completing the data preprocessing stage, we split the dataset into 70% training, 10% validation, and 20% testing. This is done by storm ID, ensuring that no storm appearing in the validation or test set is included in the training set. This prevents data leakage and ensures the reliability of evaluation results.\nFor model training, each input consists of a sequence of 4 consecutive time steps, where each step represents an observation interval of 3 hours. Thus, one input sequence covers a total of 9 hours of storm movement.\nFigure 1 : Dataset Distribution Applying Stepwise Temporal Fading Augmentation (STFA) To enhance the diversity of the training data, we apply our proposed method—Stepwise Temporal Fading Augmentation (STFA)—to 50% of the training set, selected based on unique storm IDs. The original sequences from these storms are replaced by their augmented counterparts, ensuring the final size of the training set remains unchanged (approximately 100% of the original size).\nAs introduced earlier in the proposal section, STFA modifies the older points in a sequence while keeping the most recent observations unchanged. For each 4-step sequence:\nThe latest 2 time steps remain the same The older 2 time steps are scaled using fading coefficients: [0.98,; 0.99] Although these values appear small, latitude and longitude are extremely sensitive features. Even a tiny change—such as from 6.7 to 6.8—can correspond to tens of kilometers of displacement in the real world. Therefore, using modest fading values is both logical and physically meaningful, ensuring the augmented data remains realistic.\nExample of STFA on a 4-Step Sequence Here is a simple example showing how a 4-step time-series sequence is transformed after applying STFA:\nRow Original (lat, lon) Augmented (lat, lon) Operation 1 [-6.8 , 107.5] [-6.66 , 105.35] multiplied by 0.98 2 [-7.0 , 107.1] [-6.93 , 106.03] multiplied by 0.99 3 [-7.3 , 106.7] [-7.3 , 106.7] unchanged 4 [-7.5 , 106.4] [-7.5 , 106.4] unchanged This process reduces the magnitude of older observations while keeping the recent ones intact. The augmentation introduces controlled variability, helping the model generalize better for trajectory forecasting.\nEarlier, we used physics-informed machine learning to compute distance and bearing between time steps using the Haversine formula. After STFA is applied, these values are recomputed based on the augmented coordinates. This guarantees that all physical features remain accurate and consistent with the updated trajectory.\nFigure 2 : Comparison of Augmentation Techniques on Storm Trajectories Model Setting 1.Physics-Informed Loss Our use of the Haversine formula does not end at feature engineering. In addition to generating distance and bearing values, we also incorporate the Haversine distance as a custom loss function, alongside traditional losses such as MSE, RMSE, and MAPE.\nBecause the Haversine formula computes the true geodesic distance between two geographical points, it serves as a natural metric for evaluating the error in the model’s predicted storm location. A larger Haversine distance indicates that the prediction is far from the true position, whereas a smaller value means the model is performing well. The optimal Haversine loss, ideally, is 0 km.\nThe formula was previously introduced in Section 2: Proposal, so we do not rewrite it here.\nExample:\nModel prediction: [-6.72, 107.1] True location: [-6.8, 107.5] Haversine loss: 45.06 km The value 45.06 km directly reflects the real-world positional error, making the loss physically interpretable.\nThis is what we refer to as physics-informed machine learning loss, where physical laws and domain knowledge guide the model’s optimization.\n2.Model Architect Sequence modeling tasks are traditionally handled by recurrent architectures such as RNNs, LSTMs, or GRUs. However, recent research has shown that convolution-based approaches can outperform these methods in many time-series applications.\nWhile CNNs do not inherently model sequence order, they excel at:\nextracting local spatial/temporal features parallel processing faster training stable gradients efficient scaling For our project, we adopt a convolution-based architecture as the foundation. Specifically, our main model is a Temporal Convolutional Network (TCN).\nTemporal Convolutional Network (TCN) A TCN uses 1D dilated convolutions, enabling the model to have a receptive field that expands over time, allowing it to “see” far into the past without requiring recurrence.\nExample (sequence = [a, b, c, d]):\nLayer 1 (dilation = 1): model sees [d] Layer 2 (dilation = 2): model sees [b, d] Layer 3 (dilation = 4): model can see [a, b, c, d] By stacking dilated convolutions, the network learns long-range dependencies while retaining all the benefits of fast convolution operations. Thus, TCNs combine memory of the past with computational efficiency, making them an ideal choice for storm trajectory forecasting.\n3. Model Hyperparameters Below are the key hyperparameters used in our training configuration:\nInput dimensions: 4 (latitude, longitude, distance, bearing) Hidden units: 1024 Number of TCN layers: 2 Learning rate: 1e-4 Epochs: 80 Optimizer: Adam Early stopping: patience = 6 (based on overall loss) 4. Composite Loss Function Our main training loss is a weighted combination of multiple components:\nMSE on latitude and longitude MSE on distance and bearing (auxiliary features) Haversine loss (physics-informed component) The contribution of each auxiliary loss is controlled by weighting factors:\nλ_aux = 0.5 (for distance and bearing MSE) λ_hav = 0.3 (for the Haversine loss) This design ensures that the model:\nlearns to minimize coordinate errors, respects physical displacement, and does not overfit to any single feature. By integrating physics-informed loss terms with data-driven learning, the model becomes more stable, consistent, and aligned with real-world storm dynamics.\nFigure 3 : Training Process Evaluation After the training process concludes and the model triggers early stopping, performing an evaluation on the test set is necessary to determine whether the model generalizes well and is ready for real-world deployment. We evaluate the model using Overall Loss, MSE, RMSE, MAPE, and Haversine distance to gain deeper insight into its performance:\nTotal Loss: 74.3849 MSE: 0.0832 RMSE: 0.2772 MAPE: 0.60% Haversine (km): 30.75 From these results, we observe that the average positional error is approximately 30 km from the true location. This level of error is acceptable because hurricanes are extremely large systems, often spanning hundreds to thousands of kilometers. The MSE of only 0.08 for latitude and longitude also indicates strong predictive accuracy, suggesting that the model can effectively estimate realistic future storm trajectories with minimal error.\nThese results further demonstrate that convolutional computations can perform very well on sequence-modeling tasks, and should be considered a strong alternative to traditional sequential architectures such as RNNs, LSTMs, or GRUs—not only for images but also for structured spatiotemporal data.\nWith the model validated, the next step is to upload the trained model to an Amazon S3 bucket and use an AWS Lambda function to load and execute it in response to user inference requests.\nThe following sections will focus on how we design and deploy our online prediction platform, making the hurricane trajectory model accessible for public use.\nFigure 4 : Evaluation Metrics "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Master IAM roles for application authorization Learn AWS Cloud9 development environment Implement S3 static websites with CloudFront Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn how to grant authorization for an application to access AWS services with an IAM role - Preparation + Create EC2 instance + Create S3 bucket - Create an IAM user with access keys for Python application S3 uploads - Create an IAM role with permissions for the application to upload files to S3bucket 09/29/2025 09/29/2025 https://000048.awsstudygroup.com/ 3 - Create Cloud9 Instance - Learn basic features of Cloud9: + Using command line + Working with text files + Back to Dashboard interface - Using AWS CLI in Cloud9 09/30/2025 09/30/2025 https://000049.awsstudygroup.com/ 4 - Learn some info about Amazon S3 + Understanding the difference between S3 Buckets and Object + Key features (storage classes, security and compliance, management and analytics, performance and availability) + Common use cases - Create S3 bucket and then upload the data to prepare the host static website - Configure static website: + Enable static website feature + Configure public access block + Configure public objects + Test website - Accelerate with CloudFront: + Block all public access + Configure Amazon CloudFront + Test Amazon CloudFront - Advanced S3 features: + Configure bucket versioning + Move objects between buckets + Set up cross-region replication 10/01/2025 10/04/2025 https://000057.awsstudygroup.com/ 5 - Participate in the [AWS GenAI Builder Club] AI-Driven Development Life Cycle: Reimagining Software Engineering event 10/03/2025 10/03/2025 Week 4 Achievements: Mastered IAM role configuration for application authorization:\nCreated IAM users with access keys for S3 uploads Configured IAM roles with S3 permissions Set up EC2 instances and S3 buckets for application testing Gained proficiency with AWS Cloud9 development environment:\nCreated and managed Cloud9 instances Used command line interface and text editing features Executed AWS CLI commands within Cloud9 Implemented comprehensive S3 static website hosting:\nConfigured S3 buckets for static website hosting Managed public access blocks and object permissions Tested website functionality and performance Deployed CloudFront for content delivery acceleration:\nConfigured CloudFront distributions for S3 websites Implemented security measures by blocking public access Tested CloudFront performance and caching Applied advanced S3 features:\nEnabled bucket versioning for data protection Managed object movement between buckets Set up cross-region replication for disaster recovery "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.1-ai-model-integration/","title":"AI-Model-Integration","tags":[],"description":"","content":"Actions to Integrate Hurricane Prediction Model from Lambda Overview Below here we will represent how did we integrate our model from lambda to use step-by-step.\nFiles Currently Using Mock Data 1. WeatherOverlay.tsx (IMPORTANT) Location: frontend/src/components/WeatherOverlay.tsx Mock data: Temperature and Wind overlay data Function: generateWeatherData() Required change: Replace with an API call to Lambda 2. WeeklyForecast.tsx Location: frontend/src/components/WeeklyForecast.tsx Mock data: mockForecast array Required change: Fetch from the backend API 3. windData.ts Location: frontend/src/lib/windData.ts Mock data: mockWindData Required change: Fetch from OpenWeatherMap or Lambda 4. WindFieldManager.ts Location: frontend/src/components/wind/WindFieldManager.ts Mock data: Fallback when there is no API key Status: OK — it already fetches from OpenWeatherMap; you just need to configure the API key How to Integrate the AI Model from Lambda Step 1: Add API endpoints for Storm Prediction In frontend/src/api/weatherApi.ts, add:\nexport interface StormPrediction { stormId: string; name: string; nameVi: string; currentPosition: { lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; }; historicalTrack: Array\u0026lt;{ lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; }\u0026gt;; forecastTrack: Array\u0026lt;{ lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; confidence?: number; // Confidence score from the AI model }\u0026gt;; } export const weatherApi = { // ... existing methods ... // Get storm predictions from the Lambda AI model getStormPredictions: async (): Promise\u0026lt;StormPrediction[]\u0026gt; =\u0026gt; { const response = await api.get\u0026lt;StormPrediction[]\u0026gt;(\u0026#39;/storms/predictions\u0026#39;); return response.data; }, // Get details for a specific storm getStormById: async (stormId: string): Promise\u0026lt;StormPrediction\u0026gt; =\u0026gt; { const response = await api.get\u0026lt;StormPrediction\u0026gt;(`/storms/${stormId}`); return response.data; }, }; Step 2: Update the Backend to call Lambda In the C# backend (backend/Controllers/WeatherController.cs), add an endpoint:\n[HttpGet(\u0026#34;storms/predictions\u0026#34;)] public async Task\u0026lt;IActionResult\u0026gt; GetStormPredictions() { try { // Call the Lambda function var lambdaClient = new AmazonLambdaClient(); var request = new InvokeRequest { FunctionName = \u0026#34;storm-prediction-function\u0026#34;, InvocationType = InvocationType.RequestResponse, Payload = \u0026#34;{}\u0026#34; // Or parameters if needed }; var response = await lambdaClient.InvokeAsync(request); using var reader = new StreamReader(response.Payload); var result = await reader.ReadToEndAsync(); return Ok(JsonSerializer.Deserialize\u0026lt;List\u0026lt;StormPrediction\u0026gt;\u0026gt;(result)); } catch (Exception ex) { return StatusCode(500, new { error = ex.Message }); } } Step 3: Update the Frontend to use the real API In frontend/src/pages/Index.tsx (or wherever storm data is fetched):\nimport { weatherApi } from \u0026#39;../api/weatherApi\u0026#39;; import { useQuery } from \u0026#39;@tanstack/react-query\u0026#39;; // Instead of using mock data const { data: storms, isLoading } = useQuery({ queryKey: [\u0026#39;storms\u0026#39;], queryFn: () =\u0026gt; weatherApi.getStormPredictions(), refetchInterval: 5 * 60 * 1000, // Refresh every 5 minutes }); Step 4: Configure Environment Variables Frontend (.env.production):\nVITE_API_BASE_URL=https://your-backend-api.com/api/weather Backend (appsettings.json):\n{ \u0026#34;AWS\u0026#34;: { \u0026#34;Region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;LambdaFunctionName\u0026#34;: \u0026#34;storm-prediction-function\u0026#34; } } Deployment Checklist Deploy the AI model to Lambda Test the Lambda function with sample input Add the API endpoint in the C# backend Test the backend endpoint Update weatherApi.ts with the new endpoints Replace mock data with real API calls Test the frontend with real data Update .env.production with the production URL Build and deploy the frontend Monitor logs and errors Notes Caching: You should cache results from Lambda to reduce cost Error handling: Handle Lambda timeouts or errors gracefully Loading states: Show loading indicators while fetching Fallback: You can keep mock data as a fallback when the API fails Files You Don’t Need to Change (Examples Only) These files are demos/examples and do not affect production:\n*.example.tsx */__tests__/* */GUIDE.md "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"During my internship, I participated in two events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nDate \u0026amp; Time: 09:00, September 18, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: AWS Cloud Mastery Series #1\nDate \u0026amp; Time: 08:30, August 13, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.2-fix-unicode-error-solution/","title":"Fix-Unicode-Error","tags":[],"description":"","content":"Fixing UnicodeDecodeError in Lambda There is a series error we want to talk about during the process of development, and this section will talk about it.\nIssue UnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 64: invalid start byte Root Cause The PyTorch model uses the .pth extension (a binary file). The Python runtime also uses .pth files for path configuration (text files). If the model .pth is placed directly in LAMBDA_TASK_ROOT, Python may try to read it as text → causing the error. Applied Fix 1. Update Dockerfile Move the model into a subdirectory models/:\n# Copy model file to subdirectory to avoid Python .pth file confusion RUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ 2. Update app.py Update the model search paths:\npossible_paths = [ \u0026#39;/var/task/models/cropping_storm_7304_2l.pth\u0026#39;, # Primary location in Lambda \u0026#39;models/cropping_storm_7304_2l.pth\u0026#39;, tcn_path ] Rebuild \u0026amp; Deploy Steps Step 1: Build the Docker image cd storm_prediction docker build --provenance=false --platform linux/amd64 -t storm-prediction-model . Note: --provenance=false helps reduce image size for pushing to ECR.\nStep 2: Tag the image docker tag storm-prediction-model:latest 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Step 3: Login to ECR aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com Step 4: Push to ECR docker push 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Step 5: Update Lambda AWS Console → Lambda → storm-prediction Open the Image tab Click Deploy new image Select the latest image Click Save Step 6: Test curl -X POST \u0026#34;https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 14.5, \u0026#34;lng\u0026#34;: 121.0}, {\u0026#34;lat\u0026#34;: 14.6, \u0026#34;lng\u0026#34;: 121.1}, {\u0026#34;lat\u0026#34;: 14.7, \u0026#34;lng\u0026#34;: 121.2}, {\u0026#34;lat\u0026#34;: 14.8, \u0026#34;lng\u0026#34;: 121.3}, {\u0026#34;lat\u0026#34;: 14.9, \u0026#34;lng\u0026#34;: 121.4}, {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 121.5}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 121.6}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 121.7}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 121.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; }\u0026#39; Check Logs After Deploy aws logs tail /aws/lambda/storm-prediction --region ap-southeast-1 --follow Summary Before: The .pth model file was in the root → Python mistook it for a config .pth file → UnicodeDecodeError After: The .pth model file is inside models/ → Python ignores it → Lambda works ✅ "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.4-frontback-end/5.4.1-frontend-architecture/","title":"Frontend Architecture","tags":[],"description":"","content":"Frontend Architecture - Storm Prediction Web Application Overview Below is the detailed documentation of our front-end development: a React + TypeScript web application for tracking and predicting typhoon trajectories.\nAWS Services Architecture ┌─────────────────────────────────────────────────────────────┐ │ USER BROWSER │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ CloudFront CDN │ │ - Distribution: d3lj47ilp0fgxy.cloudfront.net │ │ - SSL/TLS: HTTPS │ │ - Cache: Static assets + JSON data │ │ - Origin Access: OAI/OAC (Secure) │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ S3 Bucket (Private) │ │ - Bucket: storm-frontend-hosting-duc-2025 │ │ - Static Website Hosting: DISABLED │ │ - Access: CloudFront only via REST API │ │ - Content: HTML, CSS, JS, Images, recent_storms.json │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Functions │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ Lambda #1: Storm Prediction │ │ │ │ - URL: vill3povlzqxdyxm7ubldizobu0kdgbi... │ │ │ │ - Method: POST /predict │ │ │ │ - Auth: NONE (public) │ │ │ │ - Container: ECR (Docker) │ │ │ │ - Models: LSTM + TCN │ │ │ └─────────────────────────────────────────────────────┘ │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ Lambda #2: Storm Data Crawler (New) │ │ │ │ - Trigger: EventBridge (Weekly) │ │ │ │ - Function: Crawl IBTrACS data │ │ │ │ - Output: recent_storms.json → S3 │ │ │ └─────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ EventBridge │ │ - Rule: storm-data-crawler-weekly-trigger │ │ - Schedule: Every Sunday 00:00 UTC (7AM Vietnam) │ │ - Target: Lambda #2 (Storm Data Crawler) │ └─────────────────────────────────────────────────────────────┘ Frontend Directory Structure frontend/ ├── src/ │ ├── components/ # React components │ │ ├── ui/ # shadcn/ui components (button, card, input, etc.) │ │ ├── storm/ # Storm-specific components │ │ ├── timeline/ # Timeline controls │ │ ├── wind/ # Wind visualization │ │ ├── StormPredictionForm.tsx # Storm coordinate input form │ │ ├── WeatherMap.tsx # Main Leaflet map │ │ ├── StormTracker.tsx # Storm list │ │ ├── StormInfo.tsx # Storm details │ │ ├── StormAnimation.tsx # Animated markers │ │ ├── WeatherOverlay.tsx # Temperature/Wind overlay │ │ ├── WeatherLayerControl.tsx # Satellite/Radar layers │ │ ├── WeatherLayerControlPanel.tsx # Control panel UI │ │ ├── WeatherValueTooltip.tsx # Hover tooltip │ │ ├── WindyLayer.tsx # Windy.com integration │ │ ├── ProvinceLayer.tsx # Vietnam provinces │ │ ├── OptimizedTemperatureLayer.tsx │ │ ├── TemperatureHeatMapLayer.tsx │ │ ├── ThemeToggle.tsx # Dark/Light mode │ │ ├── PreferencesModal.tsx # User preferences │ │ ├── RightSidebar.tsx # Right panel │ │ └── WeeklyForecast.tsx # 7-day forecast │ │ │ ├── pages/ │ │ ├── Index.tsx # Main page │ │ └── NotFound.tsx # 404 page │ │ │ ├── lib/ # Business logic \u0026amp; utilities │ │ ├── api/ # API clients │ │ ├── __tests__/ # Unit tests │ │ ├── stormData.ts # Types \u0026amp; interfaces │ │ ├── stormAnimations.ts # Animation logic │ │ ├── stormIntensityChanges.ts │ │ ├── stormPerformance.ts │ │ ├── stormValidation.ts │ │ ├── windData.ts │ │ ├── windStrengthCalculations.ts │ │ ├── windyStatePersistence.ts │ │ ├── windyUrlState.ts │ │ ├── mapUtils.ts # Map helpers │ │ ├── openWeatherMapClient.ts │ │ ├── dataWorker.ts # Web Worker │ │ ├── utils.ts │ │ └── colorInterpolation.ts │ │ │ ├── hooks/ # Custom React hooks │ │ ├── use-toast.ts │ │ ├── use-theme.tsx │ │ ├── use-mobile.tsx │ │ ├── useTimelineState.ts │ │ ├── useWindyStateSync.ts │ │ └── useSimplifiedTooltip.ts │ │ │ ├── contexts/ # React Context │ │ └── WindyStateContext.tsx │ │ │ ├── api/ │ │ └── weatherApi.ts # API calls │ │ │ ├── utils/ │ │ └── colorInterpolation.ts │ │ │ ├── styles/ │ │ └── accessibility.css # WCAG compliance styles │ │ │ ├── test/ # Test suite │ │ ├── accessibility.test.ts │ │ ├── accessibility-audit.test.ts │ │ ├── wcag-compliance.test.ts │ │ ├── performance.test.ts │ │ ├── cross-browser.test.ts │ │ └── setup.ts │ │ │ ├── assets/ # Images, icons │ ├── App.tsx │ ├── main.tsx │ └── index.css │ ├── public/ # Static assets ├── dist/ # Build output (after npm run build) ├── .env.production # Production config ├── .env.example ├── package.json ├── vite.config.ts ├── vitest.config.ts # Test config ├── tailwind.config.ts ├── tsconfig.json └── components.json # shadcn/ui config Environment Variables .env.production # OpenWeather API VITE_OPENWEATHER_API_KEY=8ff7f009d2bd420c86845c6bcf6de4a9 # CloudFront URL - Fetch storm data VITE_CLOUDFRONT_URL=https://d3lj47ilp0fgxy.cloudfront.net # Lambda Function URL - Storm prediction API VITE_PREDICTION_API_URL=https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws ** Screenshots needed:**\nAWS CloudFront → Distributions → Distribution domain name AWS Lambda → storm-prediction → Function URL Build \u0026amp; Deploy Process 1. Build Production cd frontend npm run build Output: dist/ folder contains:\nindex.html assets/index-[hash].js assets/index-[hash].css 2. Upload to S3 aws s3 sync dist/ s3://storm-frontend-hosting-duc-2025/ --delete Important Notes:\nS3 bucket is PRIVATE (no public access) CloudFront uses REST API endpoint, not website endpoint Origin: storm-frontend-hosting-duc-2025.s3.ap-southeast-1.amazonaws.com\n3. Invalidate CloudFront Cache aws cloudfront create-invalidation \\ --distribution-id E1234567890ABC \\ --paths \u0026#34;/*\u0026#34; Data Flow A. Load Storm Data (Startup) Browser → CloudFront → S3 ↓ GET /recent_storms.json ↓ Parse JSON → Display on map File: src/pages/Index.tsx (line ~40)\nconst CLOUDFRONT_URL = import.meta.env.VITE_CLOUDFRONT_URL; const FETCH_URL = `${CLOUDFRONT_URL}/recent_storms.json?t=${Date.now()}`; B. Storm Prediction (User Action) User fills form → Click \u0026#34;Run Prediction\u0026#34; ↓ POST /predict to Lambda Function URL ↓ { \u0026#34;history\u0026#34;: [{lat, lng}, ...], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } ↓ Lambda processes → Returns forecast ↓ Display predicted path on map File: src/components/StormPredictionForm.tsx (line ~80)\nconst API_URL = `${import.meta.env.VITE_PREDICTION_API_URL}/predict`; const response = await fetch(API_URL, { method: \u0026#34;POST\u0026#34;, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify({ history, storm_name }) }); Key Components 1. Core Components StormPredictionForm File: src/components/StormPredictionForm.tsx\nFeatures:\nForm for inputting storm coordinates (min 9 points) Input validation (valid lat/lng) Calls Lambda API for prediction Displays results on map Scrollable list with Add/Remove positions Props:\ninterface StormPredictionFormProps { onPredictionResult: (result: PredictionResult) =\u0026gt; void; setIsLoading: (isLoading: boolean) =\u0026gt; void; } WeatherMap File: src/components/WeatherMap.tsx\nFeatures:\nDisplays Leaflet map Renders storm tracks (historical + forecast) Renders prediction path (purple, dashed) Weather overlays (temperature, wind, radar) Multiple storm rendering Auto-zoom to selected storm Custom panes for z-index layering Props:\ninterface WeatherMapProps { storms: Storm[]; selectedStorm?: Storm; customPrediction?: PredictionResult | null; mapFocusBounds?: LatLngBounds | null; onMapFocusComplete?: () =\u0026gt; void; } Index (Main Page) File: src/pages/Index.tsx\nFeatures:\nMain layout with header/footer State management (storms, selectedStorm, customPrediction) Sidebar with tabs (Current Storms / Predict Storm) Timeline state synchronization Loading \u0026amp; error handling Skip links for accessibility 2. Storm Components StormTracker File: src/components/StormTracker.tsx\nList of current storms Filter by status (active/developing/dissipated) Click to select storm StormInfo File: src/components/StormInfo.tsx\nDetailed storm information Wind speed, pressure, category Historical data Forecast timeline StormAnimation File: src/components/StormAnimation.tsx\nAnimated markers for storm positions Pulsing effect Category-based colors 3. Weather Layer Components WeatherOverlay File: src/components/WeatherOverlay.tsx\nTemperature heatmap overlay Wind speed visualization Real-time data from OpenWeather API Hover to view values WeatherLayerControl File: src/components/WeatherLayerControl.tsx\nSatellite imagery layer Radar layer Temperature layer Tile layer management WeatherLayerControlPanel File: src/components/WeatherLayerControlPanel.tsx\nUI controls for weather layers Opacity slider Layer toggle buttons Temperature animation toggle OptimizedTemperatureLayer \u0026amp; TemperatureHeatMapLayer Files: src/components/OptimizedTemperatureLayer.tsx, TemperatureHeatMapLayer.tsx\nPerformance-optimized temperature rendering Color interpolation Grid-based heatmap 4. Wind Components WindyLayer File: src/components/WindyLayer.tsx\nWindy.com iframe integration Wind animation overlay Synchronized state with main map Context: src/contexts/WindyStateContext.tsx\nGlobal state for Windy layer URL state persistence Sync across components 5. Map Enhancement Components ProvinceLayer File: src/components/ProvinceLayer.tsx\nVietnam provinces boundaries GeoJSON rendering Province labels WeatherValueTooltip File: src/components/WeatherValueTooltip.tsx\nTooltip displaying weather values on hover Temperature, wind speed, pressure Positioned tooltip 6. UI Components ThemeToggle File: src/components/ThemeToggle.tsx\nDark/Light mode switch Persisted preference System theme detection PreferencesModal File: src/components/PreferencesModal.tsx\nUser preferences settings Map options Display preferences RightSidebar File: src/components/RightSidebar.tsx\nAdditional info panel Collapsible sidebar WeeklyForecast File: src/components/WeeklyForecast.tsx\n7-day weather forecast Temperature trends Weather icons 7. Timeline Components Folder: src/components/timeline/\nTimeline controls for storm animation Play/Pause functionality Time scrubbing Speed controls Data Types PredictionResult File: src/lib/stormData.ts\nexport interface PredictionResult { storm_id: string; storm_name: string; prediction_time: string; totalDistance: number; // km actualDistance: number; // km lifespan: number; // hours forecastHours: number; // hours forecast: StormPoint[]; // Predicted positions path?: StormPoint[]; // Legacy support } StormPoint export interface StormPoint { timestamp: number; // Unix timestamp (ms) lat: number; lng: number; windSpeed: number; // km/h pressure: number; // hPa category: string; // \u0026#34;Typhoon\u0026#34;, \u0026#34;Super Typhoon\u0026#34;, etc. } AWS Permissions Required S3 Bucket Policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::storm-frontend-hosting-duc-2025/*\u0026#34; } ] } CloudFront Origin Access Origin: S3 bucket Origin Access: Public (or OAI if used) Testing Local Development npm run dev # Open http://localhost:5173 Production Build Test npm run build npm run preview # Open http://localhost:4173 📸 Screenshots needed:\nBrowser DevTools → Network tab → API calls Browser DevTools → Console → No errors Common Issues 1. CORS Error when calling Lambda Symptom: Access-Control-Allow-Origin error\nSolution: Lambda must return CORS headers:\nreturn { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } 2. CloudFront stale cache Symptom: New code not showing\nSolution: Invalidate cache\naws cloudfront create-invalidation --distribution-id E... --paths \u0026#34;/*\u0026#34; 3. Environment variables not loading Symptom: undefined when accessing import.meta.env.VITE_*\nSolution:\nEnsure .env.production file exists Rebuild: npm run build Variables must start with VITE_ Deployment Checklist Update .env.production with correct URLs npm run build succeeds Upload dist/ to S3 Invalidate CloudFront cache Test on production URL Verify Lambda API works Verify storm data loads Test prediction form with 9+ positions API Endpoints 1. Get Storm Data GET https://d3lj47ilp0fgxy.cloudfront.net/recent_storms.json Response: Array of Storm objects\n2. Predict Storm Path POST https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict Body: { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } Response: { \u0026#34;storm_id\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34;, \u0026#34;totalDistance\u0026#34;: 500.5, \u0026#34;lifespan\u0026#34;: 72, \u0026#34;forecast\u0026#34;: [...] } Performance Optimization 1. Code Optimization Code Splitting: Vite automatically splits chunks by routes Tree Shaking: Remove unused code Minification: Production build auto-minifies JS/CSS Lazy Loading: Components load on demand 2. Data Optimization Web Workers: Heavy computations run in worker (dataWorker.ts) Memoization: React.memo for expensive components Debouncing: Input handlers are debounced Caching: LocalStorage cache for preferences 3. Rendering Optimization Virtual Scrolling: Large lists use virtual scrolling Optimized Layers: OptimizedTemperatureLayer for performance Canvas Rendering: Heatmap uses canvas instead of DOM Pane Management: Custom Leaflet panes for z-index optimization 4. Network Optimization CDN Caching: CloudFront caches static assets Image Optimization: WebP format, lazy loading API Caching: Cache storm data with timestamp Compression: Gzip/Brotli compression 5. Accessibility Performance Skip Links: Keyboard navigation shortcuts ARIA Labels: Proper semantic HTML Focus Management: Logical tab order Screen Reader: Optimized for screen readers Libraries \u0026amp; Utilities Business Logic (lib/) Storm Management stormData.ts: Types, interfaces, Storm/StormPoint definitions stormAnimations.ts: Animation logic for storm markers stormIntensityChanges.ts: Storm intensity change calculations stormPerformance.ts: Performance optimization for rendering stormValidation.ts: Storm data validation Wind System windData.ts: Wind data structures windStrengthCalculations.ts: Wind strength calculations windyStatePersistence.ts: Windy layer state persistence windyUrlState.ts: URL state management for Windy Map \u0026amp; Weather mapUtils.ts: Map helpers (center, zoom, bounds calculations) openWeatherMapClient.ts: OpenWeather API client colorInterpolation.ts: Color gradient calculations Performance dataWorker.ts: Web Worker for heavy computations utils.ts: General utilities Custom Hooks (hooks/) use-toast.ts: Toast notification system use-theme.tsx: Dark/Light theme management use-mobile.tsx: Mobile device detection useTimelineState.ts: Timeline state synchronization useWindyStateSync.ts: Windy layer state sync useSimplifiedTooltip.ts: Simplified tooltip logic Context (contexts/) WindyStateContext.tsx: Global state for Windy layer integration Testing (test/) accessibility.test.ts: Accessibility testing accessibility-audit.test.ts: WCAG audit wcag-compliance.test.ts: WCAG 2.1 compliance performance.test.ts: Performance benchmarks cross-browser.test.ts: Cross-browser compatibility setup.ts: Test environment setup Dependencies Core React 18 TypeScript Vite (build tool) Vitest (testing) UI Framework Tailwind CSS shadcn/ui (component library) Lucide Icons Radix UI (primitives) Map \u0026amp; Visualization Leaflet React-Leaflet GeoJSON support API \u0026amp; Data Fetch API (native) OpenWeather API AWS Lambda Function URL State Management React Context API URL state (query params) LocalStorage persistence Performance Web Workers Code splitting (Vite) Lazy loading Screenshots Cloudfront Distribution Figure 1 Origin Settings Figure 1 Invalidations Figure 2 storm-frontend-hosting-duc-2025 Figure 3 Permissions Figure 4 storm-ai-models-2025 Figure 5 storm-data-store-2025 Figure 6 Main Page Figure 7 Storm Tracking Features Figure 8 Storm Details Figure 9 Predict Feature Figure 10 Figure 11 Figure 12 "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/","title":"Lambda Architecture","tags":[],"description":"","content":"Lambda Architecture - Storm Prediction AI Service Overview Lambda functions are an important component of a serverless architecture. They are especially useful due to their cost-effectiveness and ease of deployment—both of which are valuable for our hurricane prediction platform.\nThis section presents the details of how we designed and built our Lambda architecture.\nOur Lambda functions run PyTorch models for typhoon trajectory prediction and are deployed using a Docker container image.\nAWS Services Architecture ┌─────────────────────────────────────────────────────────────┐ │ Frontend (Browser) │ └────────────────────────┬────────────────────────────────────┘ │ POST /predict ▼ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Function URL (Public) │ │ URL: https://vill3povlzqxdyxm7ubldizobu0kdgbi... │ │ Auth: NONE │ │ Method: POST │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Function │ │ Name: storm-prediction │ │ Runtime: Python 3.10 (Container) │ │ Memory: 3008 MB │ │ Timeout: 120 seconds │ │ Architecture: x86_64 │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ ECR Repository │ │ Account: 339570693867 │ │ Region: ap-southeast-1 │ │ Repo: storm-prediction │ │ Image: latest │ │ Size: ~2 GB │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ S3 Buckets │ │ 1. storm-frontend-hosting-duc-2025 │ │ - models/lstm_totald_256_4.pt (optional) │ │ - predictions/[storm_id]_[timestamp].json │ │ │ │ 2. storm-ai-models (recommended) │ │ - models/lstm_totald_256_4.pt │ │ - models/tcn_model.pth (backup) │ └─────────────────────────────────────────────────────────────┘ storm_prediction/ Directory Structure storm_prediction/ ├── app.py # Lambda handler (main code) ├── Dockerfile # Container definition ├── requirements.txt # Python dependencies ├── cropping_storm_7304_2l.pth # TCN model (included in image) │ ├── DEPLOY_NOW.md # Quick deploy guide ├── DEPLOY_CONSOLE_STEP_BY_STEP.md # AWS Console guide ├── LAMBDA_DEPLOYMENT_GUIDE.md # Detailed deployment ├── AWS_CONSOLE_DEPLOYMENT_GUIDE.md ├── FIX_ECR_PUSH_ERROR.md # Troubleshooting ├── FIX_UNICODE_ERROR.md # UnicodeDecodeError fix ├── FIX_UNICODE_ERROR_SOLUTION.md # Solution details └── REBUILD_AND_DEPLOY.sh # Automated script Docker Image Structure Dockerfile FROM public.ecr.aws/lambda/python:3.10 # Install dependencies COPY requirements.txt . RUN pip3 install -r requirements.txt \\ --target \u0026#34;${LAMBDA_TASK_ROOT}\u0026#34; \\ --extra-index-url https://download.pytorch.org/whl/cpu # Copy Lambda handler COPY app.py ${LAMBDA_TASK_ROOT} # Copy TCN model to subdirectory (avoid .pth confusion) RUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ # Set handler CMD [ \u0026#34;app.handler\u0026#34; ] Image Layers Layer 1: AWS Lambda Python 3.10 base (~500 MB) Layer 2: PyTorch CPU + dependencies (~1.2 GB) Layer 3: app.py + TCN model (~300 MB) ───────────────────────────────────────────── Total: ~2 GB AI Models 1. TCN Model (Trajectory Prediction) File: cropping_storm_7304_2l.pth Location: Inside Docker image at /var/task/models/ Size: ~300 MB Purpose: Predict next step (lat, lng) of typhoon trajectory\nArchitecture:\nclass StormTCN(nn.Module): def __init__(self, input_dim=4, hidden_units=1024, num_layers=2): self.tcn = TCN(...) self.head_latlon = nn.Linear(hidden_units, 2) # Predict lat, lng self.head_aux = nn.Linear(hidden_units, 2) # Predict aux features Input: [batch, sequence, 4] - (lat, lng, distance, bearing) Output:\npred_latlon: Next (lat, lng) pred_aux: Auxiliary features 2. LSTM Model (Total Distance Prediction) File: lstm_totald_256_4.pt Location: S3 bucket (downloaded on first use) Size: ~50 MB Purpose: Predict total distance typhoon will travel\nArchitecture:\nclass StormLSTM(nn.Module): def __init__(self, input_size=4, hidden_size=256, num_layers=2): self.lstm = nn.LSTM(...) self.fc = nn.Sequential( nn.Linear(hidden_size, hidden_size // 2), nn.ReLU(), nn.Linear(hidden_size // 2, 1) # Predict total distance ) Input: Daily summary [batch, days, 4] - (day, daily_dist, avg_speed, motion_type) Output: Total distance (km)\nRequest Flow 1. Receive Request POST /predict Content-Type: application/json { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... // Min 9 points ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34;, \u0026#34;storm_id\u0026#34;: \u0026#34;TEST001\u0026#34; // Optional } 2. Load Models (First Invocation Only) def load_models(): global LSTM_MODEL, TCN_MODEL # Load LSTM from S3 (if available) if not os.path.exists(\u0026#39;/tmp/lstm_model.pt\u0026#39;): s3_client.download_file( MODEL_BUCKET, \u0026#39;models/lstm_totald_256_4.pt\u0026#39;, \u0026#39;/tmp/lstm_model.pt\u0026#39; ) LSTM_MODEL = StormLSTM(...) LSTM_MODEL.load_state_dict(torch.load(\u0026#39;/tmp/lstm_model.pt\u0026#39;)) # Load TCN from local (already in image) TCN_MODEL = StormTCN(...) TCN_MODEL.load_state_dict( torch.load(\u0026#39;/var/task/models/cropping_storm_7304_2l.pth\u0026#39;) ) 3. Preprocess Input def preprocess_history(history): # Convert to tensor [1, sequence_length, 4] # Features: [lat, lng, distance, bearing] processed = [] for i in range(len(history)): if i == 0: processed.append([lat, lng, 0.0, 0.0]) else: dist = haversine(prev_lat, prev_lng, lat, lng) brng = bearing(prev_lat, prev_lng, lat, lng) processed.append([lat, lng, dist, brng]) return torch.tensor(processed).unsqueeze(0) 4. Predict Total Distance (LSTM) def predict_total_distance(record_tensor): if LSTM_MODEL is None: # Fallback: avg_distance * 24 steps return fallback_distance # Group by day (9 points/day) # Run LSTM prediction with torch.no_grad(): pred = LSTM_MODEL(summary_tensor, lengths) return pred.item() # km 5. Predict Path (TCN) def predict_storm_path(record_tensor, total_distance, history): seq = record_tensor.clone() gone_distance = 0 predicted_points = [] while gone_distance \u0026lt; total_distance: # Predict next position pred_latlon, pred_aux = TCN_MODEL(seq) new_lat = pred_latlon[0, -1, 0].item() new_lng = pred_latlon[0, -1, 1].item() # Calculate distance \u0026amp; bearing step_distance = haversine(last_lat, last_lng, new_lat, new_lng) # Estimate windspeed (decay over time) estimated_wind = max(avg_wind * (0.98 ** step), 30) predicted_points.append({ \u0026#39;lat\u0026#39;: new_lat, \u0026#39;lng\u0026#39;: new_lng, \u0026#39;timestamp\u0026#39;: base_timestamp + (step * 3 * 3600 * 1000), \u0026#39;windSpeed\u0026#39;: estimated_wind, \u0026#39;pressure\u0026#39;: 980.0, \u0026#39;category\u0026#39;: calculate_category(estimated_wind) }) # Update sequence (sliding window) seq = torch.cat([seq[:, 1:, :], next_point.unsqueeze(1)], dim=1) gone_distance += step_distance step += 1 return predicted_points 6. Return Response result = { \u0026#39;storm_id\u0026#39;: storm_id, \u0026#39;storm_name\u0026#39;: storm_name, \u0026#39;prediction_time\u0026#39;: datetime.now().isoformat(), \u0026#39;totalDistance\u0026#39;: 500.5, \u0026#39;actualDistance\u0026#39;: 520.3, \u0026#39;lifespan\u0026#39;: 72, \u0026#39;forecastHours\u0026#39;: 72, \u0026#39;forecast\u0026#39;: [ { \u0026#39;lat\u0026#39;: 15.1, \u0026#39;lng\u0026#39;: 106.99, \u0026#39;timestamp\u0026#39;: 1765015351626, \u0026#39;windSpeed\u0026#39;: 65, \u0026#39;pressure\u0026#39;: 980, \u0026#39;category\u0026#39;: \u0026#39;Typhoon\u0026#39; }, ... ] } return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } Build \u0026amp; Deploy Process Step 1: Build Docker Image cd storm_prediction docker build \\ --provenance=false \\ --platform linux/amd64 \\ -t storm-prediction-model . Flags:\n--provenance=false: Reduce image size (no build metadata) --platform linux/amd64: Lambda only supports x86_64 -t storm-prediction-model: Tag name Step 2: Tag for ECR docker tag storm-prediction-model:latest \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Step 3: Login to ECR aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com Step 4: Push to ECR docker push \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Time: ~5-10 minutes (2GB upload)\nStep 5: Update Lambda Function AWS Console:\nLambda → storm-prediction Tab Image → Deploy new image Select latest image Click Save Lambda Configuration Function Settings Name: storm-prediction Runtime: Container image Architecture: x86_64 Memory: 3008 MB Timeout: 120 seconds Ephemeral storage: 512 MB Environment Variables MODEL_BUCKET=storm-frontend-hosting-duc-2025 DATA_BUCKET=storm-frontend-hosting-duc-2025 Function URL URL: https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws Auth type: NONE CORS: Enabled - Allow origins: * - Allow methods: POST, OPTIONS - Allow headers: Content-Type IAM Role Permissions { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::storm-frontend-hosting-duc-2025/*\u0026#34;, \u0026#34;arn:aws:s3:::storm-ai-models/*\u0026#34; ] } ] } Monitoring \u0026amp; Logs CloudWatch Logs Log Group: /aws/lambda/storm-prediction\nKey Log Messages:\nLoading LSTM model... Downloaded LSTM from S3 LSTM loaded successfully Loading TCN model... Checking: /var/task/models/cropping_storm_7304_2l.pth Found TCN at /var/task/models/cropping_storm_7304_2l.pth TCN loaded successfully Processing: Test Storm (TEST001) Input points: 9 Predicted total distance: 500.50 km Generated 24 predictions (72 hours) Saved to S3: predictions/TEST001_1733486400.json Screenshots needed:\nCloudWatch → Log groups → /aws/lambda/storm-prediction Log stream → Recent logs with emojis Logs → Duration, Memory used Metrics CloudWatch Metrics:\nInvocations Duration (avg ~5-10 seconds) Errors Throttles Memory used (~500-800 MB) Screenshots needed:\nLambda → Monitor → Metrics CloudWatch → Metrics → Lambda → Function metrics Common Issues \u0026amp; Solutions 1. UnicodeDecodeError: \u0026lsquo;utf-8\u0026rsquo; codec can\u0026rsquo;t decode byte 0x80 Symptom:\nUnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 64 Cause: Model .pth file at root mistaken as Python config file\nSolution: Move model to subdirectory\nRUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ 2. 502 Bad Gateway Symptom: Frontend receives 502 error\nCauses:\nLambda timeout (exceeds 120s) Lambda crash (out of memory) Model failed to load Solutions:\nCheck CloudWatch Logs Increase memory if needed Increase timeout if needed 3. LSTM Fallback Symptom: Log shows \u0026ldquo;⚠️ Using fallback distance\u0026rdquo;\nCause: LSTM model not on S3\nSolution: Upload lstm_totald_256_4.pt to S3:\naws s3 cp lstm_totald_256_4.pt \\ s3://storm-frontend-hosting-duc-2025/models/ 4. ECR Push 403 Forbidden Symptom: 403 Forbidden when pushing image\nCauses:\nECR login expired Wrong account ID Repository doesn\u0026rsquo;t exist Solutions:\n# Re-login aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com # Create repository if needed aws ecr create-repository \\ --repository-name storm-prediction \\ --region ap-southeast-1 Testing Local Test (if possible) # Run locally python app.py # Test event test_event = { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } result = handler(test_event, None) print(result) Lambda Test AWS Console:\nLambda → Test tab Create test event: { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 120.2}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 120.3}, {\u0026#34;lat\u0026#34;: 15.4, \u0026#34;lng\u0026#34;: 120.4}, {\u0026#34;lat\u0026#34;: 15.5, \u0026#34;lng\u0026#34;: 120.5}, {\u0026#34;lat\u0026#34;: 15.6, \u0026#34;lng\u0026#34;: 120.6}, {\u0026#34;lat\u0026#34;: 15.7, \u0026#34;lng\u0026#34;: 120.7}, {\u0026#34;lat\u0026#34;: 15.8, \u0026#34;lng\u0026#34;: 120.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } Click Test Check response cURL Test curl -X POST \\ \u0026#34;https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 120.2}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 120.3}, {\u0026#34;lat\u0026#34;: 15.4, \u0026#34;lng\u0026#34;: 120.4}, {\u0026#34;lat\u0026#34;: 15.5, \u0026#34;lng\u0026#34;: 120.5}, {\u0026#34;lat\u0026#34;: 15.6, \u0026#34;lng\u0026#34;: 120.6}, {\u0026#34;lat\u0026#34;: 15.7, \u0026#34;lng\u0026#34;: 120.7}, {\u0026#34;lat\u0026#34;: 15.8, \u0026#34;lng\u0026#34;: 120.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; }\u0026#39; Deployment Checklist Model file cropping_storm_7304_2l.pth exists (Optional) Upload LSTM model to S3 Build Docker image successfully Tag image with correct account ID (339570693867) Login to ECR successfully Push image to ECR Update Lambda function with new image Check Lambda configuration (memory, timeout) Test Lambda with test event Test via Function URL with cURL Test from frontend Check CloudWatch Logs Verify prediction results on map Screenshots Function Figure 1 Configuration Figure 2 Environment Variables Figure 3 ECR Repository Figure 4 Figure 5 "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.3-lambda-deployment/","title":"Lamda-Deployment","tags":[],"description":"","content":"Step to deploy our PyTorch Model on storm prediction on AWS Lambda AWS Lambda deployment plays a critical role in our website development pipeline. In this section, we document the process we followed to successfully complete the deployment.\nStep 1: Prepare the Code 1.1. Update app.py import json import torch import numpy as np from typing import List, Dict MODEL_PATH = \u0026#34;model.pth\u0026#34; device = torch.device(\u0026#34;cpu\u0026#34;) model = None def load_model(): global model if model is None: print(f\u0026#34;Loading model from {MODEL_PATH}...\u0026#34;) model = torch.load(MODEL_PATH, map_location=device) model.eval() print(\u0026#34;Model loaded successfully!\u0026#34;) return model def prepare_features(history: List[Dict]) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34; Convert history into a tensor for the model history: [{\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 107.0}, ...] \u0026#34;\u0026#34;\u0026#34; # TODO: Implement feature engineering based on your model lats = [p[\u0026#34;lat\u0026#34;] for p in history] lngs = [p[\u0026#34;lng\u0026#34;] for p in history] features = np.array([lats + lngs]) # Shape: (1, 18) return torch.tensor(features, dtype=torch.float32) def format_predictions(predictions: torch.Tensor, storm_name: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34; Format output to match what the frontend expects \u0026#34;\u0026#34;\u0026#34; pred_array = predictions.detach().cpu().numpy()[0] forecast = [] base_timestamp = int(time.time() * 1000) for i in range(0, len(pred_array), 2): if i + 1 \u0026lt; len(pred_array): forecast.append({ \u0026#34;lat\u0026#34;: float(pred_array[i]), \u0026#34;lng\u0026#34;: float(pred_array[i + 1]), \u0026#34;timestamp\u0026#34;: base_timestamp + (i // 2) * 3600000, # +1 hour each \u0026#34;windSpeed\u0026#34;: 120.0, # TODO: Predict from model \u0026#34;pressure\u0026#34;: 980.0, # TODO: Predict from model \u0026#34;category\u0026#34;: \u0026#34;Category 3\u0026#34;, # TODO: Classify from windSpeed \u0026#34;confidence\u0026#34;: 0.85 }) return { \u0026#34;storm_name\u0026#34;: storm_name, \u0026#34;forecast\u0026#34;: forecast } def handler(event, context): \u0026#34;\u0026#34;\u0026#34; Lambda handler function \u0026#34;\u0026#34;\u0026#34; try: # Parse input body = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) history = body.get(\u0026#39;history\u0026#39;, []) storm_name = body.get(\u0026#39;storm_name\u0026#39;, \u0026#39;Unknown Storm\u0026#39;) # Validate input if len(history) \u0026lt; 9: return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: f\u0026#39;Need at least 9 positions, got {len(history)}\u0026#39; }) } # Load model model = load_model() # Prepare features X = prepare_features(history) # Predict with torch.no_grad(): predictions = model(X) # Format output result = format_predictions(predictions, storm_name) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: str(e) }) } 1.2. Update Dockerfile FROM public.ecr.aws/lambda/python:3.11 # Copy requirements and install COPY requirements.txt ${LAMBDA_TASK_ROOT} RUN pip install --no-cache-dir -r requirements.txt # Copy model (rename to model.pth) COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/model.pth # Copy code COPY app.py ${LAMBDA_TASK_ROOT} # Set handler CMD [\u0026#34;app.handler\u0026#34;] 1.3. Verify requirements.txt torch==2.1.0 numpy==1.24.3 Step 2: Build the Docker Image cd storm_prediction # Build image docker build -t storm-prediction-model . # Test locally (optional) docker run -p 9000:8080 storm-prediction-model # Test with curl curl -X POST \u0026#34;http://localhost:9000/2015-03-31/functions/function/invocations\u0026#34; \\ -d \u0026#39;{ \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;history\\\u0026#34;: [{\\\u0026#34;lat\\\u0026#34;: 15.0, \\\u0026#34;lng\\\u0026#34;: 107.0}, {\\\u0026#34;lat\\\u0026#34;: 15.1, \\\u0026#34;lng\\\u0026#34;: 107.1}, {\\\u0026#34;lat\\\u0026#34;: 15.2, \\\u0026#34;lng\\\u0026#34;: 107.2}, {\\\u0026#34;lat\\\u0026#34;: 15.3, \\\u0026#34;lng\\\u0026#34;: 107.3}, {\\\u0026#34;lat\\\u0026#34;: 15.4, \\\u0026#34;lng\\\u0026#34;: 107.4}, {\\\u0026#34;lat\\\u0026#34;: 15.5, \\\u0026#34;lng\\\u0026#34;: 107.5}, {\\\u0026#34;lat\\\u0026#34;: 15.6, \\\u0026#34;lng\\\u0026#34;: 107.6}, {\\\u0026#34;lat\\\u0026#34;: 15.7, \\\u0026#34;lng\\\u0026#34;: 107.7}, {\\\u0026#34;lat\\\u0026#34;: 15.8, \\\u0026#34;lng\\\u0026#34;: 107.8}], \\\u0026#34;storm_name\\\u0026#34;: \\\u0026#34;Test Storm\\\u0026#34;}\u0026#34; }\u0026#39; Step 3: Upload to AWS ECR # 1. Create ECR repository aws ecr create-repository \\ --repository-name storm-prediction-model \\ --region ap-southeast-1 # 2. Login Docker to ECR aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com # 3. Tag image docker tag storm-prediction-model:latest \\ \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest # 4. Push image docker push \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest Step 4: Create the Lambda Function 4.1. Create Lambda from Console Open AWS Lambda Console Click “Create function” Choose “Container image” Function name: storm-prediction Container image URI: select the image you pushed to ECR Architecture: x86_64 Click “Create function” 4.2. Configure Lambda # Or use AWS CLI aws lambda create-function \\ --function-name storm-prediction \\ --package-type Image \\ --code ImageUri=\u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest \\ --role arn:aws:iam::\u0026lt;account-id\u0026gt;:role/lambda-execution-role \\ --timeout 60 \\ --memory-size 3008 \\ --region ap-southeast-1 Important configuration:\nMemory: 3008 MB (PyTorch models need RAM) Timeout: 60 seconds (inference can take 10–30s) Ephemeral storage: 512 MB (default; increase if needed) 4.3. Create IAM Role Lambda needs a role with permissions:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Step 5: Create API Gateway # 1. Create REST API aws apigateway create-rest-api \\ --name storm-prediction-api \\ --region ap-southeast-1 # 2. Get API ID and Root Resource ID API_ID=\u0026lt;your-api-id\u0026gt; ROOT_ID=\u0026lt;your-root-resource-id\u0026gt; # 3. Create resource /predict aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $ROOT_ID \\ --path-part predict # 4. Create POST method RESOURCE_ID=\u0026lt;predict-resource-id\u0026gt; aws apigateway put-method \\ --rest-api-id $API_ID \\ --resource-id $RESOURCE_ID \\ --http-method POST \\ --authorization-type NONE # 5. Integrate with Lambda aws apigateway put-integration \\ --rest-api-id $API_ID \\ --resource-id $RESOURCE_ID \\ --http-method POST \\ --type AWS_PROXY \\ --integration-http-method POST \\ --uri arn:aws:apigateway:ap-southeast-1:lambda:path/2015-03-31/functions/arn:aws:lambda:ap-southeast-1:\u0026lt;account-id\u0026gt;:function:storm-prediction/invocations # 6. Deploy API aws apigateway create-deployment \\ --rest-api-id $API_ID \\ --stage-name prod API URL: https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/prod/predict\nStep 6: Update the Frontend 6.1. Update .env.production VITE_PREDICTION_API_URL=https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/prod 6.2. Build \u0026amp; deploy frontend cd frontend npm run build # Deploy dist/ to S3/CloudFront Optimizations 1. Reduce Cold Start Provisioned Concurrency:\naws lambda put-provisioned-concurrency-config \\ --function-name storm-prediction \\ --provisioned-concurrent-executions 1 \\ --qualifier $LATEST 2. Reduce Image Size Use PyTorch CPU-only:\n# requirements.txt torch==2.1.0+cpu --extra-index-url https://download.pytorch.org/whl/cpu numpy==1.24.3 Multi-stage build:\n# Stage 1: Build FROM python:3.11-slim as builder COPY requirements.txt . RUN pip install --target /packages -r requirements.txt # Stage 2: Runtime FROM public.ecr.aws/lambda/python:3.11 COPY --from=builder /packages ${LAMBDA_RUNTIME_DIR} COPY model.pth ${LAMBDA_TASK_ROOT}/ COPY app.py ${LAMBDA_TASK_ROOT}/ CMD [\u0026#34;app.handler\u0026#34;] 3. Cache the Model in /tmp import os MODEL_PATH = \u0026#34;/tmp/model.pth\u0026#34; if os.path.exists(\u0026#34;/tmp/model.pth\u0026#34;) else \u0026#34;model.pth\u0026#34; def load_model(): global model if model is None: # Copy to /tmp for faster access if not os.path.exists(\u0026#34;/tmp/model.pth\u0026#34;): import shutil shutil.copy(\u0026#34;model.pth\u0026#34;, \u0026#34;/tmp/model.pth\u0026#34;) model = torch.load(\u0026#34;/tmp/model.pth\u0026#34;, map_location=device) model.eval() return model Monitoring CloudWatch Logs `bash\nView logs aws logs tail /aws/lambda/storm-prediction \u0026ndash;follow `\nCloudWatch Metrics Invocations: number of calls Duration: runtime Errors: error count Throttles: throttled invocations Alerts # Create an alarm for errors aws cloudwatch put-metric-alarm \\ --alarm-name storm-prediction-errors \\ --alarm-description \u0026#34;Alert when Lambda has errors\u0026#34; \\ --metric-name Errors \\ --namespace AWS/Lambda \\ --statistic Sum \\ --period 300 \\ --threshold 5 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=FunctionName,Value=storm-prediction Troubleshooting Error: \u0026ldquo;Task timed out after 3.00 seconds\u0026rdquo;\nFix: Increase timeout to 60s\nError: \u0026ldquo;Runtime exited with error: signal: killed\u0026rdquo;\nFix: Increase memory to 3008 MB\nError: \u0026ldquo;No module named \u0026rsquo;torch\u0026rsquo;\u0026rdquo;\nFix: Check requirements.txt and rebuild the image\nError: Model cannot be loaded\nFix: Verify the model filename in Dockerfile and app.py match\nEstimated Cost Lambda: Free tier: 1M requests/month, 400,000 GB-seconds After that: $0.20 per 1M requests + $0.0000166667 per GB-second Example: 10,000 requests/month, each request 10s, 3GB RAM Compute: 10,000 × 10s × 3GB × $0.0000166667 = ~$5/month Requests: 10,000 × $0.20/1M = ~$0.002/month Total: ~$5/month API Gateway: $3.50 per million requests 10,000 requests = ~$0.035/month ECR: $0.10 per GB/month storage Image ~2GB = ~$0.20/month Estimated total: ~$5.25/month for 10,000 predictions\nFinal Checklist Fix the model filename mismatch in app.py or Dockerfile Test the Docker image locally Push the image to ECR Create Lambda with 3008MB memory, 60s timeout Create API Gateway and integrate with Lambda Test the API with Postman/curl Update VITE_PREDICTION_API_URL in the frontend Build and deploy the frontend Test the prediction form on the web UI Set up CloudWatch alerts Monitor logs and performance "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Deploy full-stack applications with EC2 and RDS Implement AWS Lightsail for WordPress hosting Contribute to group project development and documentation Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Prepare infrastructure for application deployment: + Create VPC for application environment + Create EC2 Security Group + Create RDS Security Group + Create DB Subnet Group - Deploy application components: + Create EC2 Instance + Create RDS database instance - Application deployment and management: + Deploy application to EC2 instance + Implement backup and restore procedures 10/06/2025 10/06/2025 https://000005.awsstudygroup.com/ 3 - Create a dataset of storm coordinates with a 3-hour timestep for our group project\u0026rsquo;s model training 10/07/2025 10/08/2025 4 - Work on the Vietnamese version of our group project proposal Markdown file - Deploy database on AWS Lightsail - Deploy WordPress instance: + Launch WordPress instance on Lightsail + Configure Ubuntu server settings + Set up networking configuration + Complete WordPress setup and configuration 10/09/2025 10/09/2025 https://000045.awsstudygroup.com/ 5 - Work on the Vietnamese translation of 3 blog posts as requested by my mentors: + Qwen models are now available in Amazon Bedrock + DeepSeek-V3.1 model now available in Amazon Bedrock + Scale visual production using Stability AI Image Services in Amazon Bedrock 10/10/2025 10/10/2025 Week 5 Achievements: Deployed complete application infrastructure using EC2 and RDS:\nCreated VPC with proper security groups and subnet groups Configured EC2 instances and RDS databases for application hosting Implemented backup and restore procedures for data protection Successfully deployed WordPress using AWS Lightsail:\nLaunched and configured WordPress instances on Lightsail Set up Ubuntu server and networking configurations Deployed databases and completed WordPress setup Contributed to group project development:\nCreated storm coordinate datasets for model training Translated project proposal documentation to Vietnamese Enhanced project accessibility for Vietnamese team members Completed technical translation work:\nTranslated AWS Bedrock blog posts about AI models Covered Qwen, DeepSeek-V3.1, and Stability AI services Supported knowledge sharing within the Vietnamese community Gained experience with multiple AWS deployment approaches:\nTraditional EC2+RDS architecture Simplified Lightsail deployment model Database and application hosting best practices "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/","title":"Workshop","tags":[],"description":"","content":"ONLINE PLATFORM FOR TRACKING AND FORECASTING HURRICANE TRAJECTORY Overview Hurricanes are powerful natural disasters that cause severe damage to infrastructure and pose significant risks to human life. Early detection and timely warnings are essential so that people in affected areas have enough time to prepare and evacuate safely.\nTo address this need, our project aims to build an online platform that allows users to freely access information about the most recent storms in the Western Pacific, using data sourced from the trusted NOAA (National Oceanic and Atmospheric Administration). In addition, students, meteorologists, or anyone interested in hurricane dynamics can interact with our system by providing their own input trajectories and receiving predictions generated by our machine learning model.\nThis workshop presents the complete process of building such a model for hurricane forecasting, including several novel time-series techniques—Stepwise Temporal Fading and Plausible Geodesic-Aware Augmentation—as well as a step-by-step explanation of how we built and deployed the platform from scratch.\nWith the support of AWS services such as Amazon S3, AWS Lambda, API Gateway, and CloudFront, we construct a fully serverless architecture. This offers simplicity, scalability, and long-term cost efficiency while ensuring reliable and responsive performance.\nPlatform Architecture The final platform delivers two core functionalities:\nStorm Viewing Users can explore up-to-date information on recent Western Pacific storms, including their historical path, wind speed, temperature, and other relevant parameters.\nHurricane Trajectory Prediction Users can input their own partial storm trajectory and receive a predicted future path generated by our trained model.\nContent Workshop overview Data Preparation ML Model Training Front\u0026amp;Back-End Architect API "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/5-workshop/5.5-platform-api/","title":"Platform API","tags":[],"description":"","content":"BACK-END API DETAIL DESCRIPTION Table of Contents Introduction System Architecture Core Features Technology Stack Project Structure API Endpoints 1. Introduction Weather Backend API is a RESTful service that provides weather information by integrating with OpenWeatherMap API. The backend serves as a middleware layer between frontend applications and external weather data sources.\nFigure 1 2. System Architecture High-Level Architecture ┌─────────────────────────────────────────────────────────────┐ │ Frontend Applications │ │ (React, Mobile, Web Clients) │ └─────────────────────────────────────────────────────────────┘ │ │ HTTPS / REST API ▼ ┌─────────────────────────────────────────────────────────────┐ │ Weather Backend API │ │ (.NET 9.0 - ASP.NET Core) │ ├─────────────────────────────────────────────────────────────┤ │ ┌────────────────┐ ┌────────────────┐ ┌────────────────┐ │ │ Controllers │ │ Services │ │ Program.cs │ │ │ │ │ │ │ - App Startup │ │ │ - WeatherCtrl │ │ - WeatherSvc │ │ - Logging │ │ │ - ForecastCtrl │ │ - Cache Layer │ │ - DI Setup │ │ └────────────────┘ └────────────────┘ └────────────────┘ └─────────────────────────────────────────────────────────────┘ │ │ HTTPS / REST API (External) ▼ ┌─────────────────────────────────────────────────────────────┐ │ External Weather Services │ ├─────────────────────────────────────────────────────────────┤ │ • OpenWeatherMap API │ │ • Redis Caching Layer │ │ • Rate Limiting \u0026amp; Monitoring │ └─────────────────────────────────────────────────────────────┘ 3. Core Features Description: Retrieve current weather conditions for any city worldwide.\nFeatures:\nSearch by city name (e.g., \u0026ldquo;Hanoi\u0026rdquo;, \u0026ldquo;Ho Chi Minh City\u0026rdquo;) Optional country code for precise location Multiple unit systems support (metric, imperial, standard) Multi-language weather descriptions Cached responses for performance API Parameters:\ncityName (required): Name of the city countryCode (optional): ISO 3166 country code units (optional): metric, imperial, or standard language (optional): en, vi, fr, etc. Response Example:\nResponse body Download { \u0026#34;localDate\u0026#34;: \u0026#34;2025-12-06 19:57:02\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Hà Nội\u0026#34;, \u0026#34;coord\u0026#34;: { \u0026#34;lon\u0026#34;: 105.8412, \u0026#34;lat\u0026#34;: 21.0245 }, \u0026#34;weather\u0026#34;: [ { \u0026#34;id\u0026#34;: 804, \u0026#34;main\u0026#34;: \u0026#34;Clouds\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;mây đen u ám\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;04n\u0026#34; } ], \u0026#34;main\u0026#34;: { \u0026#34;temp\u0026#34;: 22, \u0026#34;feels_like\u0026#34;: 22.11, \u0026#34;temp_min\u0026#34;: 22, \u0026#34;temp_max\u0026#34;: 22, \u0026#34;pressure\u0026#34;: 1018, \u0026#34;humidity\u0026#34;: 71, \u0026#34;sea_level\u0026#34;: 1018, \u0026#34;grnd_level\u0026#34;: 1017 }, \u0026#34;wind\u0026#34;: { \u0026#34;speed\u0026#34;: 4.14, \u0026#34;deg\u0026#34;: 136, \u0026#34;gust\u0026#34;: 6.84 }, \u0026#34;sys\u0026#34;: { \u0026#34;type\u0026#34;: 1, \u0026#34;id\u0026#34;: 9308, \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;sunrise\u0026#34;: 1764976827, \u0026#34;sunset\u0026#34;: 1765016103 } } Figure 2 4. Technology Stack Backend Framework .NET 9.0 – Latest .NET runtime ASP.NET Core – Web API framework C# 12 – Primary programming language API Integration HttpClientFactory – Managed HTTP client usage Polly – Retry policies \u0026amp; transient fault handling Newtonsoft.Json / System.Text.Json – JSON serialization Caching \u0026amp; Performance MemoryCache – In-memory caching Redis (optional) – Distributed caching ResponseCompression – Gzip / Brotli compression Development Tools Visual Studio 2022 / VS Code – IDE / Code editor Swagger / OpenAPI – API documentation Git – Version control Docker – Containerization 5. Project Structure WeatherBackend/ │ ├── WeatherBackend.csproj # Project file ├── Program.cs # Application entry point ├── WeatherBackend.http # HTTP request testing file │ ├── appsettings.json # Configuration settings │ ├── Controllers/ # API Controllers │ └── WeatherController.cs # Main weather endpoints │ ├── Services/ # Business logic services │ └── WeatherService/ # Service contracts \u0026amp; implementation 6. API Endpoints Base URL https://localhost:7042/swagger/index.html 6.1 GET /api/weather/current Description: Retrieve the current weather by city name.\nCURL Example:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather?city=hanoi\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; Request URL:\nhttps://localhost:7042/api/Weather?city=hanoi 6.2 GET /api/weather/forecast Description: Get the 5-day weather forecast for a selected city.\nCURL Example:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/forecast?city=hochiminh\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; Request URL:\nhttps://localhost:7042/api/Weather/forecast?city=hochiminh 6.3 GET /api/weather/coordinates Description: Retrieve weather data using latitude and longitude.\nCURL Example:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/by-coord?lat=21.0245\u0026amp;lon=105.8412\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; Request URL:\nhttps://localhost:7042/api/Weather/by-coord?lat=21.0245\u0026amp;lon=105.8412 6.4 GET /api/weather/location Description: Retrieve weather data for the user\u0026rsquo;s current location (requires coordinates from client device).\nCURL Example:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/global\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; Request URL:\nhttps://localhost:7042/api/Weather/global Figure 3 Last Updated: 2025-12-09\nVersion: 1.0.0\nMaintained by: SKYNET\n"},{"uri":"https://nguyenduyson2005.github.io/fcj-report/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"During my internship at Amazon Web Services from 08/09/2025 to 24/12/2025, I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment. I actively engaged in a variety of technical hands-on labs and talk events, while also contributing to my group’s main project: an online platform for tracking and forecasting hurricane trajectories. Through these experiences, I significantly improved my skills in collaborative teamwork, reporting, hands-on AWS console operations, and gained a broader perspective on the current state of Cloud and AI technologies.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ☐ ✅ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ✅ ☐ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ☐ ☐ ✅ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ✅ ☐ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ✅ ☐ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ☐ ✅ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ✅ ☐ ☐ 12 Overall General evaluation of the entire internship period ✅ ☐ ☐ Needs Improvement Enhance the speed and application of learning new information in a practical context. Build confidence in articulating ideas and concerns within a group setting. Improve the clarity and professionalism of written reports. "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Deploy business applications on AWS Lightsail Master container deployment and management Implement auto scaling for high availability Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Deploy Prestashop E-Commerce Instance on Lightsail: + Launch Prestashop instance + Configure networking settings + Complete Prestashop deployment - Implement application security measures - Create instance snapshots for backup 10/13/2025 10/13/2025 https://000045.awsstudygroup.com/ 3 - Deploy Akaunting Instance on Lightsail: + Launch Akaunting application instance + Configure networking configuration + Complete Akaunting app deployment - Perform instance management: + Upgrade to larger instance size + Create alarms for monitoring 10/14/2025 10/14/2025 https://000045.awsstudygroup.com/ 4 - Create and configure container service on AWS - Deploy public container images - Build and deploy custom container images: + Create Lightsail instance for container deployment + Configure AWS CLI for container management + Install Docker on Ubuntu instance + Build custom container images + Push container images to registry + Implement new container deployments 10/15/2025 10/15/2025 https://000046.awsstudygroup.com/ 5 - Deploy FCJ Management Infrastructure: + Setup network infrastructure + Launch EC2 instance + Launch RDS database instance + Setup database data + Deploy web server + Prepare metrics for predictive scaling - Create launch template - Setup load balancer: + Create target group + Create load balancer 10/16/2025 10/16/2025 https://000006.awsstudygroup.com/ 6 - Complete Auto Scaling Deployment: + Create Auto Scaling Group - Test scaling solutions: + Test manual scaling + Test scheduled scaling + Test dynamic scaling + Read predictive scaling metrics 10/17/2025 10/17/2025 https://000006.awsstudygroup.com/ Week 6 Achievements: Successfully deployed business applications on AWS Lightsail:\nLaunched and configured Prestashop e-commerce platform Deployed Akaunting accounting application with proper networking Implemented security measures and backup snapshots Mastered container deployment and management:\nCreated and configured AWS container services Built custom container images using Docker Pushed images to registry and implemented deployments Configured AWS CLI for container management Implemented comprehensive auto scaling solutions:\nBuilt complete infrastructure with EC2, RDS, and load balancers Created launch templates and target groups Configured Auto Scaling Groups for high availability Tested multiple scaling strategies (manual, scheduled, dynamic) Advanced instance management skills:\nPerformed instance upgrades to larger sizes Created monitoring alarms for performance tracking Prepared metrics for predictive scaling analysis Gained expertise in application deployment across multiple AWS services:\nLightsail for simplified application hosting Container services for modern application deployment Auto Scaling for enterprise-grade availability "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Master AWS CloudWatch for monitoring and observability Implement hybrid DNS with Route 53 Resolver Develop advanced AWS CLI skills Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - AWS CloudWatch Workshop - Metrics: + Complete preparatory steps + View and analyze CloudWatch metrics + Use search expressions for metric filtering + Apply math expressions for metric calculations + Configure dynamic labels for metrics 10/20/2025 10/20/2025 https://000008.awsstudygroup.com/ 3 - AWS CloudWatch Workshop - Logs \u0026amp; Monitoring: + Work with CloudWatch Logs + Use CloudWatch Logs Insights for log analysis + Configure CloudWatch Metric Filters + Create and manage CloudWatch Alarms + Build and customize CloudWatch Dashboards 10/21/2025 10/21/2025 https://000008.awsstudygroup.com/ 4 - Set up Hybrid DNS with Route 53 Resolver: + Generate key pair for secure access + Initialize CloudFormation template + Configure security groups + Connect to RD Gateway + Deploy Microsoft Active Directory - Setup DNS configuration: + Create Route 53 Outbound Endpoint + Create Route 53 Resolver Rules + Create Route 53 Inbound Endpoint + Test DNS resolution results 10/22/2025 10/23/2025 https://000010.awsstudygroup.com/ 5 - AWS CLI Mastery: + Install and configure AWS CLI + View AWS resources via CLI commands + Manage Amazon S3 operations + Work with Amazon SNS services + Handle IAM users and policies + Configure VPC and Internet Gateway + Create EC2 instances using CLI + Troubleshoot common CLI issues 10/23/2025 10/24/2025 https://000011.awsstudygroup.com/ Week 7 Achievements: Mastered AWS CloudWatch monitoring capabilities:\nAnalyzed metrics with search and math expressions Configured dynamic labels for enhanced visualization Utilized CloudWatch Logs Insights for log analysis Created metric filters and configured alarms Built custom dashboards for comprehensive monitoring Implemented hybrid DNS solution with Route 53 Resolver:\nDeployed Microsoft Active Directory infrastructure Configured Route 53 inbound and outbound endpoints Created resolver rules for hybrid DNS resolution Tested and validated DNS functionality across environments Advanced AWS CLI proficiency:\nManaged multiple AWS services (S3, SNS, IAM, VPC) via CLI Configured VPC components including Internet Gateway Created and managed EC2 instances using command line Developed troubleshooting skills for CLI operations Gained expertise in infrastructure automation:\nUsed CloudFormation templates for resource deployment Implemented secure access with key pairs and security groups Connected to RD Gateway for remote management Automated DNS and networking configurations Enhanced operational monitoring and management skills:\nEstablished comprehensive observability with CloudWatch Implemented hybrid cloud connectivity solutions Developed command-line automation capabilities "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment\nThe working environment at the company is both friendly and highly conducive to productivity. The office location being located on the higher floors significantly reduces traffic noises, allowing for better concentration. Furthermore, the workspace is quite spacious, creating a comfortable and open atmosphere. The FCJ members have also been exceptionally supportive, consistently providing helpful guidance whenever I encounter challenging tasks.\n2. Support from Mentor / Team Admin\nMy mentor provided excellent guidance and was consistently responsive to my questions. The admin team also offered strong support by supplying all essential documents, such as program rules and grading criteria, and by promptly addressing specific requests, including my query regarding the group project\u0026rsquo;s infrastructure diagram.\n3. Relevance of Work to Academic Major\nThe assigned tasks provided an excellent opportunity to apply the knowledge I gained at university to a real-world project and bringing our group\u0026rsquo;s concept to life. This experience also exposed me to new and practical domains I had not previously explored, such as utilizing the AWS platform to build and deploy our project solution.\n4. Learning \u0026amp; Skill Development Opportunities\nThis internship has provided significant opportunities for my professional and personal growth. I developed a deeper understanding and practical skill set in utilizing the AWS platform. I also gained valuable insight into the current state of the technology landscape relevant to my academic major, which has greatly enhanced my perspective on real-world applications. Furthermore, I have been able to improved my ability to communicate ideas clearly and collaborate effectively within a team setting.\n5. Company Culture \u0026amp; Team Spirit\nThe company fosters a very positive and inclusive culture where everyone respects each other, works seriously but still keeps things enjoyable. The team spirit is particularly strong, with everyone proactively completing their tasks and readily collaborating to solve problems. Decisions are made collectively, as team members consistently share ideas and gather input from the entire group before reaching a consensus.\n6. Internship Policies / Benefits\nThe internship policies are supportive, including a fair allowance and the flexibility to adjust working days when necessary. A key benefit was access to structured training labs. These guided, hands-on sessions on the AWS console and platform provided practical, foundational learning that complemented the core project work.\nAdditional Questions What did you find most satisfying during your internship? The most rewarding aspect of my internship was the opportunity to experience a genuine professional work environment for the first time. It was deeply satisfying to apply my academic knowledge in a real-world company setting and become part of a professional team. What do you think the company should improve for future interns? For future interns, i believe it would be beneficial to have more often access to the workspace on the 26th floor than the one on floor 46th, as it allows for easier full gathering of their own respective team . Additionally, having access to a drinking water station in the workplace would certainly improve daily convenience. If recommending to a friend, would you suggest they intern here? Why or why not? Yes, I would confidently recommend this internship. It effectively bridges the gap between theory and practice, offering exposure to new technologies and professional workflows I hadn\u0026rsquo;t encountered before. Coupled with a supportive and comfortable work environment, it provides a solid foundation for professional growth. Suggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience?\nOutside of the points already mentioned, I do not have any specific suggestions. My overall experience was positive and well-structured. Would you like to continue this program in the future?\nAbsolutely. If given the opportunity and time, I would gladly continue. Working with AWS, one of the world\u0026rsquo;s leading cloud platforms, has been an exceptional opportunity. The comprehensive experience has contributed significantly to both my personal and professional development. Any other comments (free sharing):\nNone. "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Master Amazon DynamoDB fundamentals and operations Prepare for and complete OJT Midterm Exam Develop AWS SDK integration skills Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Amazon DynamoDB Fundamentals: + Learn core components and architecture + Understand primary keys and secondary indexes + Study naming rules and data types + Explore read consistency models + Compare read/write capacity modes - DynamoDB Management: + Create access keys for programmatic access + Create tables using AWS Management Console + Perform CRUD operations (Create, Read, Update) + Query data and create Global Secondary Indexes 10/27/2025 10/27/2025 https://000060.awsstudygroup.com/ 3 - OJT Midterm Exam Preparation: + Review AWS Well-Architected Framework + Study secure architecture principles + Practice resilient and high-performing architectures + Prepare for cost-optimized design scenarios 10/28/2025 10/31/2025 4 - Advanced DynamoDB Operations: + Use AWS CloudShell for DynamoDB management + Create tables and perform operations via CLI + Query Global Secondary Indexes in CloudShell - AWS SDK Integration: + Configure AWS CLI for DynamoDB access + Get started with Python and DynamoDB SDK + Perform comprehensive table operations: • Create, read, update, and delete data • Load sample datasets • Query and scan operations • Clean up by deleting tables 10/29/2025 11/1/2025 https://000060.awsstudygroup.com/ 5 - FPTU OJT Midterm Exam - Exam 4: + Complete AWS knowledge assessment + Demonstrate understanding of Well-Architected Framework + Apply knowledge across architecture domains: • Secure Architectures • Resilient Architectures • High-Performing Architectures • Cost-Optimized Architectures 10/31/2025 10/31/2025 Week 8 Achievements: Mastered Amazon DynamoDB NoSQL database service:\nUnderstood core components including tables, items, and attributes Implemented primary keys and Global Secondary Indexes Performed comprehensive CRUD operations via console and CLI Configured read consistency and capacity modes Developed advanced database management skills:\nUsed AWS Management Console for DynamoDB operations Leveraged AWS CloudShell for command-line database management Created and queried Global Secondary Indexes for efficient data access Gained AWS SDK programming experience:\nConfigured AWS CLI for DynamoDB access Integrated Python with DynamoDB using AWS SDK Performed table operations including creation, querying, and deletion Managed data lifecycle with load, scan, and cleanup operations Successfully prepared for and completed OJT Midterm Exam:\nMastered AWS Well-Architected Framework principles Applied knowledge across four architecture domains Demonstrated understanding of secure, resilient, and cost-optimized designs Validated high-performing architecture implementation skills Enhanced technical proficiency across multiple interfaces:\nWeb console for visual management CLI for command-line operations SDK for programmatic integration Comprehensive database administration capabilities "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Master Amazon ElastiCache for in-memory data storage Implement advanced AWS networking and connectivity solutions Develop comprehensive VPC and DNS configuration skills Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - ElastiCache Preparation \u0026amp; Cluster Creation: + Generate AWS Access Key for programmatic access + Install and configure AWS CLI + Create subnet groups using Console and CLI + Create ElastiCache clusters (cluster mode disabled) + Create ElastiCache clusters (cluster mode enabled) + Configure cluster access permissions 11/03/2025 11/03/2025 https://000061.awsstudygroup.com/ 3 - ElastiCache Connection \u0026amp; Data Operations: + Connect to cluster nodes (both cluster modes) + Test endpoints using AWS CLI + Test user group functionality + Perform basic string operations (Set and Get) + Work with hash data structures (multiple items) 11/04/2025 11/04/2025 https://000061.awsstudygroup.com/ 4 - Advanced VPC Networking: + Deploy VPC infrastructure components + Review Cisco CSR agreement for VPN setup + Deep dive into VPC components architecture + Implement Transit Gateway deployment + Access Cisco CSR Router using Cloud9 11/05/2025 11/05/2025 https://000092.awsstudygroup.com/ 5 - VPN, Endpoints \u0026amp; Peering: + Setup site-to-site VPN connections + Configure additional ECMP paths for redundancy + Deploy VPC Endpoints for AWS Services + Perform NP2 endpoint testing + Create VPC peering requests + Configure peering routing tables 11/06/2025 11/06/2025 https://000092.awsstudygroup.com/ 6 - DNS \u0026amp; Network Management: + Deploy Route53 DNS endpoints and internal hosted zones + Perform comprehensive DNS testing + Deploy VPC Endpoint Services + Setup Transit Gateway Network Manager + Configure network sites and topology + Utilize Network Insights for monitoring + Final testing of VPC peering connectivity 11/07/2025 11/07/2025 https://000092.awsstudygroup.com/ Week 9 Achievements: Mastered Amazon ElastiCache in-memory data store:\nCreated and configured Redis clusters in both cluster modes Established secure access permissions and user groups Performed data operations including strings, hashes, and key-value pairs Connected to cluster nodes and tested endpoints via AWS CLI Implemented comprehensive AWS networking solutions:\nDeployed advanced VPC infrastructure with multiple components Configured Transit Gateway for centralized network management Established site-to-site VPN connections with Cisco CSR routers Set up ECMP paths for network redundancy and load balancing Developed expertise in AWS connectivity services:\nDeployed VPC Endpoints for private AWS service access Created VPC peering connections and configured routing tables Implemented Route53 DNS endpoints and internal hosted zones Performed comprehensive network testing and validation Advanced network management and monitoring:\nConfigured Transit Gateway Network Manager for global network visibility Set up network sites and topology mapping Utilized Network Insights for performance monitoring and troubleshooting Accessed network devices using Cloud9 for remote management Enhanced cross-service integration skills:\nConnected ElastiCache with application data patterns Integrated VPC networking with DNS and endpoint services Combined Transit Gateway with VPN and peering solutions Implemented end-to-end network connectivity architectures "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Master Amazon CloudFront for content delivery and edge computing Implement advanced CDN configurations with Lambda@Edge Deploy and manage virtual desktops with Amazon WorkSpaces Participate in AWS Cloud Mastery Series #1 event. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Content Delivery with Amazon CloudFront: + Create and configure S3 bucket for static hosting + Upload example index.html file + Configure Amazon CloudFront distribution with S3 bucket origin + Validate distribution access via CloudFront URL + Perform resource teardown and cleanup 11/10/2025 11/10/2025 https://000094.awsstudygroup.com/ 3 - Edge Computing with CloudFront and Lambda@Edge: + Create EC2 instance for application hosting + Create S3 bucket for static content storage + Configure CloudFront distribution with EC2 origin + Test application delivery through CloudFront + Test distribution invalidations + Configure custom error pages 11/11/2025 11/11/2025 https://000130.awsstudygroup.com/ 4 - Advanced CloudFront Configuration: + Create origin groups for failover scenarios + Configure response headers policies + Create custom cache behaviors + Creating Lambda@Edge functions + Deploy Lambda@Edge to CloudFront distribution + Configure metrics and access logs + Perform resource cleanup and teardown 11/12/2025 11/13/2025 https://000130.awsstudygroup.com/ 5 - Windows Workloads on AWS: + Prepare deployment environment for Amazon WorkSpaces + Deploy and configure Amazon WorkSpaces + Access WorkSpaces through web browser + Access WorkSpaces using WorkSpaces client application + Perform service cleanup and resource termination 11/14/2025 11/14/2025 https://000093.awsstudygroup.com/ 6 - Participate in the AWS Cloud Mastery Series #1 event 11/15/2025 11/15/2025 Week 10 Achievements: Established comprehensive CloudFront expertise:\nCreated and configured S3 buckets for static content hosting Uploaded and managed static website files (index.html) Configured CloudFront distributions with S3 bucket origins Deployed EC2 instances for application hosting Set up CloudFront distributions with EC2 origins Tested application delivery through CloudFront CDN Advanced edge computing capabilities:\nImplemented custom error page configurations Tested distribution invalidations for cache management Created origin groups for failover scenarios Configured response headers policies Created custom cache behaviors Developed and deployed Lambda@Edge functions Mastered virtual desktop infrastructure:\nPrepared deployment environments for Amazon WorkSpaces Deployed and configured Amazon WorkSpaces Accessed WorkSpaces through web browser interface Accessed WorkSpaces using native client application Performed service cleanup and resource termination Enhanced monitoring and optimization skills:\nConfigured CloudFront metrics and access logs Performed comprehensive resource cleanup and teardown Validated distribution access via CloudFront URLs "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives: Implement enterprise directory services with AWS Managed Microsoft AD Build highly available web applications with auto-scaling capabilities Master WordPress deployment on AWS cloud infrastructure Participate in AWS community event and game day Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Participate in the AWS Cloud Mastery Series #2 event 11/17/2025 11/17/2025 3 - Directory Services with AWS Managed Microsoft AD: + Deploy AWS Managed Microsoft AD directory service + Deploy and configure EC2 instances + Edit computer names for domain joining + Configure EC2 instances for domain services + Test server communication within the domain + Perform service cleanup and resource termination 11/18/2025 11/18/2025 https://000095.awsstudygroup.com/ 4 - Building Highly Available Web Applications: + Prepare VPC and subnet infrastructure + Create security groups for EC2 instances + Create security groups for database instances + Launch and configure EC2 instances + Deploy and configure database instances + Install and configure WordPress on EC2 11/19/2025 11/19/2025 https://000101.awsstudygroup.com/ 5 - Building Highly Available Web Applications: + Create AMI from web server instance + Configure launch templates for auto scaling + Create application load balancer + Set up auto scaling group + Implement database backup with snapshots + Restore database from snapshot + Configure CloudFront for web server + Perform resource cleanup 11/20/2025 11/20/2025 https://000101.awsstudygroup.com/ 6 - Participate in the [AWS GenAI Builders Club] Game Day - Secret Agent(ic) Unicorns event 11/21/2025 11/21/2025 Week 11 Achievements: Established enterprise directory services expertise:\nDeployed AWS Managed Microsoft AD directory service Configured EC2 instances for domain joining and management Edited computer names and configured domain services Tested server communication within Active Directory domain Managed directory service lifecycle from deployment to cleanup Built highly available web application architecture:\nDesigned and implemented VPC and subnet infrastructure Created security groups for EC2 instances and databases Deployed and configured database instances for WordPress Installed and configured WordPress on EC2 instances Created AMI images from web server instances Implemented auto-scaling and load balancing solutions:\nConfigured launch templates for auto-scaling groups Deployed application load balancers for traffic distribution Set up auto-scaling groups for high availability Configured CloudFront distributions for web server acceleration Mastered database management and disaster recovery:\nImplemented database backup strategies with snapshots Performed database restoration from snapshots Managed database instances for WordPress applications "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Objectives: Master VM migration techniques using AWS VM Import/Export Implement database migrations with AWS Database Migration Service (DMS) Utilize Schema Conversion Tool (SCT) for database schema transformations Participate in AWS Cloud Mastery Series #3 event Support team collaboration through translation of workshop materials Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - VM Migration with AWS VM Import/Export + Prepare VMWare Workstation environment + Export virtual machine from on-premises infrastructure + Upload virtual machine files to AWS S3 + Import virtual machine to AWS cloud + Deploy EC2 instances from imported AMI 11/24/2025 11/24/2025 https://000014.awsstudygroup.com/ 3 - VM Migration with AWS VM Import/Export + Configure S3 bucket ACL for VM export + Export virtual machine from running EC2 instance + Export virtual machine from existing AMI + Reference migration guide videos + Perform resource cleanup on AWS cloud 11/25/2025 11/25/2025 https://000014.awsstudygroup.com/ 4 - Database Migration with AWS Database Migration Service (DMS) and Schema Conversion Tool (SCT): + Get started with AWS DMS configuration + Select and configure DMS source database + Select and configure DMS target database + Implement serverless replication setup + Monitor DMS migration progress and performance + Troubleshoot migration issues with AWS DMS + Perform environment cleanup and resource termination 11/26/2025 11/26/2025 https://000043.awsstudygroup.com/ 5 - Create Vietnamese versions of my group\u0026rsquo;s English workshop files 11/27/2025 11/28/2025 6 - Participate in the AWS Cloud Mastery Series #3 event 11/29/2025 11/29/2025 Week 12 Achievements: Mastered virtual machine migration workflows:\nPrepared VMWare Workstation environments for migration Exported virtual machines from on-premises infrastructure Uploaded VM files to AWS S3 storage Imported virtual machines to AWS cloud environment Deployed EC2 instances from imported AMI images Configured S3 bucket ACLs for VM export operations Exported virtual machines from running EC2 instances Exported virtual machines from existing AMIs Implemented comprehensive database migration solutions:\nConfigured AWS Database Migration Service (DMS) Selected and configured source databases for migration Selected and configured target databases for migration Implemented serverless replication setups Monitored DMS migration progress and performance Troubleshot migration issues using AWS DMS tools Managed database migration lifecycle from setup to cleanup Advanced cloud migration expertise:\nEstablished end-to-end VM migration capabilities Built database migration proficiency across platforms Implemented comprehensive resource management strategies Developed troubleshooting skills for migration challenges "},{"uri":"https://nguyenduyson2005.github.io/fcj-report/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://nguyenduyson2005.github.io/fcj-report/tags/","title":"Tags","tags":[],"description":"","content":""}]